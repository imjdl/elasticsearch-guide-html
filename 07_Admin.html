<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.6.2">
<title>placeholder7</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Remove comment around @import statement below when using as a custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.spread{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
*:not(pre)>code.nobreak{word-wrap:normal}
*:not(pre)>code.nowrap{white-space:nowrap}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:initial}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px 0}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:.4em .75em 0 .75em;line-height:1;vertical-align:top}
.colist>table tr>td:first-of-type img{max-width:initial}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;text-indent:-1.05em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
</style>
</head>
<body class="article">
<div id="header">
<h1>placeholder7</h1>
</div>
<div id="content">
<h1 id="administration" class="sect0">管理、监控和部署</h1>

<div class="sect1">
<h2 id="cluster-admin">监控</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Elasticsearch 经常以多节点集群的方式部署。有多种 API 让你可以管理和监控集群本身，而不用和集群里存储的数据打交道。</p>
</div>
<div class="paragraph">
<p>和 Elasticsearch 里绝大多数功能一样，我们有一个总体的设计目标，即任务应该通过 API 执行，而不是通过修改静态的配置文件。这一点在你的集群扩容时尤为重要。即便通过配置管理系统（比如 Puppet，Chef 或者 Ansible），一个简单的 HTTP API 调用，也比往上百台物理设备上推送新配置文件简单多了。</p>
</div>
<div class="paragraph">
<p>因此，本章将介绍各种可以让你动态调整、调优和调配集群的 API。同时，还会介绍一系列提供集群自身统计数据的 API，你可以用这些接口来监控集群健康状态和性能。</p>
</div>
<div class="sect2">
<h3 id="marvel">Marvel 监控</h3>
<div class="paragraph">
<p><a href="https://www.elastic.co/guide/en/marvel/current/index.html">Marvel</a> 让你可以很简单的通过 Kibana 监控 Elasticsearch。你可以实时查看你的集群健康状态和性能，也可以分析过去的集群、索引和节点指标。</p>
</div>
<div class="paragraph">
<p>虽然你可以通过本章介绍的 API 查看大量的指标数据，但是它们展示的都是当前时间点的即时情况。了解这个瞬间的内存占用比当然很有用，但是了解内存占用比 <em>随时间轴的趋势</em> 更加有用。Marvel 会查询并聚合这些数据，你可以通过可视化效果看到自己集群随时间的变化，这样可以很容易的发现发展的趋势。</p>
</div>
<div class="paragraph">
<p>随着你集群规模的发展，统计 API 的输出内容会复杂得让人完全没法看。当你有一大把节点，比如说一百个，再阅读这个输出的 JSON 就非常乏味了。而 Marvel 可以让你交互式的探索这些数据，更容易于集中关注特定节点或者索引上发生了什么。</p>
</div>
<div class="paragraph">
<p>Marvel 使用公开的 API，和你自己能找到的一样&#8201;&#8212;&#8201;它没有暴露任何你通过 API 访问不到的统计信息。但是，Marvel 极大的简化了这些统计信息的采集和可视化工作。</p>
</div>
<div class="paragraph">
<p>Marvel 可以免费使用（包括生产环境上！），所以你现在就开始用起来吧！安装介绍，参阅
<a href="https://www.elastic.co/guide/en/marvel/current/getting-started.html">Marvel 入门</a>。</p>
</div>
</div>
<div class="sect2">
<h3 id="_cluster_health">集群健康</h3>
<div class="paragraph">
<p>一个 Elasticsearch 集群至少包括一个节点和一个索引。或者它可能有一百个数据节点、三个单独的主节点，以及一小打客户端节点——这些共同操作一千个索引（以及上万个分片）。</p>
</div>
<div class="paragraph">
<p>不管集群扩展到多大规模，你都会想要一个快速获取集群状态的途径。<code>Cluster Health</code> API 充当的就是这个角色。你可以把它想象成是在一万英尺的高度鸟瞰集群。它可以告诉你安心吧一切都好，或者警告你集群某个地方有问题。</p>
</div>
<div class="paragraph">
<p>让我们执行一下 <code>cluster-health</code> API 然后看看响应体是什么样子的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">GET _cluster/health</code></pre>
</div>
</div>
<div class="paragraph">
<p>和 Elasticsearch 里其他 API 一样，<code>cluster-health</code> 会返回一个 JSON 响应。这对自动化和告警系统来说，非常便于解析。响应中包含了和你集群有关的一些关键信息：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "cluster_name": "elasticsearch_zach",
   "status": "green",
   "timed_out": false,
   "number_of_nodes": 1,
   "number_of_data_nodes": 1,
   "active_primary_shards": 10,
   "active_shards": 10,
   "relocating_shards": 0,
   "initializing_shards": 0,
   "unassigned_shards": 0
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>响应信息中最重要的一块就是 <code>status</code> 字段。状态可能是下列三个值之一：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>green</code></dt>
<dd>
<p>所有的主分片和副本分片都已分配。你的集群是 100% 可用的。</p>
</dd>
<dt class="hdlist1"><code>yellow</code></dt>
<dd>
<p>所有的主分片已经分片了，但至少还有一个副本是缺失的。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果 <em>更多的</em> 分片消失，你就会丢数据了。把 <code>yellow</code> 想象成一个需要及时调查的警告。</p>
</dd>
<dt class="hdlist1"><code>red</code></dt>
<dd>
<p>至少一个主分片（以及它的全部副本）都在缺失中。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p><code>green</code>/<code>yellow</code>/<code>red</code> 状态是一个概览你的集群并了解眼下正在发生什么的好办法。剩下来的指标给你列出来集群的状态概要：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>number_of_nodes</code> 和 <code>number_of_data_nodes</code> 这个命名完全是自描述的。</p>
</li>
<li>
<p><code>active_primary_shards</code> 指出你集群中的主分片数量。这是涵盖了所有索引的汇总值。</p>
</li>
<li>
<p><code>active_shards</code> 是涵盖了所有索引的_所有_分片的汇总值，即包括副本分片。</p>
</li>
<li>
<p><code>relocating_shards</code> 显示当前正在从一个节点迁往其他节点的分片的数量。通常来说应该是 0，不过在 Elasticsearch 发现集群不太均衡时，该值会上涨。比如说：添加了一个新节点，或者下线了一个节点。</p>
</li>
<li>
<p><code>initializing_shards</code> 是刚刚创建的分片的个数。比如，当你刚创建第一个索引，分片都会短暂的处于 <code>initializing</code> 状态。这通常会是一个临时事件，分片不应该长期停留在 <code>initializing</code> 状态。你还可能在节点刚重启的时候看到 <code>initializing</code> 分片：当分片从磁盘上加载后，它们会从 <code>initializing</code> 状态开始。</p>
</li>
<li>
<p><code>unassigned_shards</code> 是已经在集群状态中存在的分片，但是实际在集群里又找不着。通常未分配分片的来源是未分配的副本。比如，一个有 5 分片和 1 副本的索引，在单节点集群上，就会有 5 个未分配副本分片。如果你的集群是 <code>red</code> 状态，也会长期保有未分配分片（因为缺少主分片）。</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_钻更深点_找到问题索引">钻更深点：找到问题索引</h4>
<div class="paragraph">
<p>想象一下某天碰到问题了， 而你发现你的集群健康状态看起来像是这样：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "cluster_name": "elasticsearch_zach",
   "status": "red",
   "timed_out": false,
   "number_of_nodes": 8,
   "number_of_data_nodes": 8,
   "active_primary_shards": 90,
   "active_shards": 180,
   "relocating_shards": 0,
   "initializing_shards": 0,
   "unassigned_shards": 20
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>好了，从这个健康状态里我们能推断出什么来？嗯，我们集群是 <code>red</code> ，意味着我们缺数据（主分片 + 副本分片）了。我们知道我们集群原先有 10 个节点，但是在这个健康状态里列出来的只有 8 个数据节点。有两个数据节点不见了。我们看到有 20 个未分配分片。</p>
</div>
<div class="paragraph">
<p>这就是我们能收集到的全部信息。那些缺失分片的情况依然是个谜。我们是缺了 20 个索引，每个索引里少 1 个主分片？还是缺 1 个索引里的 20 个主分片？还是 10 个索引里的各 1 主 1 副本分片？具体是哪个索引？</p>
</div>
<div class="paragraph">
<p>要回答这个问题，我们需要使用 <code>level</code> 参数让 <code>cluster-health</code> 答出更多一点的信息：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">GET _cluster/health?level=indices</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个参数会让 <code>cluster-health</code> API 在我们的集群信息里添加一个索引清单，以及有关每个索引的细节（状态、分片数、未分配分片数等等）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "cluster_name": "elasticsearch_zach",
   "status": "red",
   "timed_out": false,
   "number_of_nodes": 8,
   "number_of_data_nodes": 8,
   "active_primary_shards": 90,
   "active_shards": 180,
   "relocating_shards": 0,
   "initializing_shards": 0,
   "unassigned_shards": 20
   "indices": {
      "v1": {
         "status": "green",
         "number_of_shards": 10,
         "number_of_replicas": 1,
         "active_primary_shards": 10,
         "active_shards": 20,
         "relocating_shards": 0,
         "initializing_shards": 0,
         "unassigned_shards": 0
      },
      "v2": {
         "status": "red", <b class="conum">(1)</b>
         "number_of_shards": 10,
         "number_of_replicas": 1,
         "active_primary_shards": 0,
         "active_shards": 0,
         "relocating_shards": 0,
         "initializing_shards": 0,
         "unassigned_shards": 20 <b class="conum">(2)</b>
      },
      "v3": {
         "status": "green",
         "number_of_shards": 10,
         "number_of_replicas": 1,
         "active_primary_shards": 10,
         "active_shards": 20,
         "relocating_shards": 0,
         "initializing_shards": 0,
         "unassigned_shards": 0
      },
      ....
   }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>我们可以看到 <code>v2</code> 索引就是让集群变 <code>red</code> 的那个索引。</p>
</li>
<li>
<p>由此明确了，20 个缺失分片全部来自这个索引。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>一旦我们询问要索引的输出，哪个索引有问题立马就很清楚了：<code>v2</code> 索引。我们还可以看到这个索引曾经有 10 个主分片和一个副本，而现在这 20 个分片全不见了。可以推测，这 20 个索引就是位于从我们集群里不见了的那两个节点上。</p>
</div>
<div class="paragraph">
<p><code>level</code> 参数还可以接受其他更多选项：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">GET _cluster/health?level=shards</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>shards</code> 选项会提供一个详细得多的输出，列出每个索引里每个分片的状态和位置。这个输出有时候很有用，但是由于太过详细会比较难用。如果你知道哪个索引有问题了，本章讨论的其他 API 显得更加有用一点。</p>
</div>
</div>
<div class="sect3">
<h4 id="_阻塞等待状态变化">阻塞等待状态变化</h4>
<div class="paragraph">
<p>当构建单元和集成测试时，或者实现和 Elasticsearch 相关的自动化脚本时，<code>cluster-health</code> API 还有另一个小技巧非常有用。你可以指定一个 <code>wait_for_status</code> 参数，它只有在状态达标之后才会返回。比如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">GET _cluster/health?wait_for_status=green</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个调用会 <em>阻塞</em> （不给你的程序返回控制权）住直到 <code>cluster-health</code> 变成 <code>green</code> ，也就是说所有主分片和副本分片都分配下去了。这对自动化脚本和测试非常重要。</p>
</div>
<div class="paragraph">
<p>如果你创建一个索引，Elasticsearch 必须在集群状态中向所有节点广播这个变更。那些节点必须初始化这些新分片，然后响应给主节点说这些分片已经 <code>Started</code> 。这个过程很快，但是因为网络延迟，可能要花 10&#x2013;20ms。</p>
</div>
<div class="paragraph">
<p>如果你有个自动化脚本是 (a) 创建一个索引然后 (b) 立刻写入一个文档，这个操作会失败。因为索引还没完全初始化完成。在 (a) 和 (b) 两步之间的时间可能不到 1ms —— 对网络延迟来说这可不够。</p>
</div>
<div class="paragraph">
<p>比起使用 <code>sleep</code> 命令，直接让你的脚本或者测试使用 <code>wait_for_status</code> 参数调用 <code>cluster-health</code> 更好。当索引完全创建好，<code>cluster-health</code> 就会变成 <code>green</code> ，然后这个调用就会把控制权交还给你的脚本，然后你就可以开始写入了。</p>
</div>
<div class="paragraph">
<p>有效的选项是： <code>green</code> 、 <code>yellow</code> 和 <code>red</code> 。这个调回会在达到你要求（或者『更高』）的状态时返回。比如，如果你要求的是 <code>yellow</code> ，状态变成 <code>yellow</code> 或者 <code>green</code> 都会打开调用。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_monitoring_individual_nodes">监控单个节点</h3>
<div class="paragraph">
<p><code>集群健康</code> 就像是光谱的一端——对集群的所有信息进行高度概述。而 <code>节点统计值</code> API 则是在另一端。它提供一个让人眼花缭乱的统计数据的数组，包含集群的每一个节点统计值。</p>
</div>
<div class="paragraph">
<p><code>节点统计值</code> 提供的统计值如此之多，在完全熟悉它之前，你可能都搞不清楚哪些指标是最值得关注的。我们将会高亮那些最重要的监控指标（但是我们鼓励你记录接口提供的所有指标——或者用 Marvel ——因为你永远不知道何时需要某个或者另一个值）。</p>
</div>
<div class="paragraph">
<p><code>节点统计值</code> API 可以通过如下命令执行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">GET _nodes/stats</code></pre>
</div>
</div>
<div class="paragraph">
<p>在输出内容的开头，我们可以看到集群名称和我们的第一个节点：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "cluster_name": "elasticsearch_zach",
   "nodes": {
      "UNr6ZMf5Qk-YCPA_L18BOQ": {
         "timestamp": 1408474151742,
         "name": "Zach",
         "transport_address": "inet[zacharys-air/192.168.1.131:9300]",
         "host": "zacharys-air",
         "ip": [
            "inet[zacharys-air/192.168.1.131:9300]",
            "NONE"
         ],
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>节点是排列在一个哈希里，以节点的 UUID 作为键名。还显示了节点网络属性的一些信息（比如传输层地址和主机名）。这些值对调试诸如节点未加入集群这类自动发现问题很有用。通常你会发现是端口用错了，或者节点绑定在错误的 IP 地址/网络接口上了。</p>
</div>
<div class="sect3">
<h4 id="_索引部分">索引部分</h4>
<div class="paragraph">
<p><code>索引(indices)</code> 部分列出了这个节点上所有索引的聚合过的统计值：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">    "indices": {
        "docs": {
           "count": 6163666,
           "deleted": 0
        },
        "store": {
           "size_in_bytes": 2301398179,
           "throttle_time_in_millis": 122850
        },</code></pre>
</div>
</div>
<div class="paragraph">
<p>返回的统计值被归入以下部分：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>docs</code> 展示节点内存有多少文档，包括还没有从段里清除的已删除文档数量。</p>
</li>
<li>
<p><code>store</code> 部分显示节点耗用了多少物理存储。这个指标包括主分片和副本分片在内。如果限流时间很大，那可能表明你的磁盘限流设置得过低（在<a href="#segments-and-merging">段和合并</a>里讨论过）。</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">        "indexing": {
           "index_total": 803441,
           "index_time_in_millis": 367654,
           "index_current": 99,
           "delete_total": 0,
           "delete_time_in_millis": 0,
           "delete_current": 0
        },
        "get": {
           "total": 6,
           "time_in_millis": 2,
           "exists_total": 5,
           "exists_time_in_millis": 2,
           "missing_total": 1,
           "missing_time_in_millis": 0,
           "current": 0
        },
        "search": {
           "open_contexts": 0,
           "query_total": 123,
           "query_time_in_millis": 531,
           "query_current": 0,
           "fetch_total": 3,
           "fetch_time_in_millis": 55,
           "fetch_current": 0
        },
        "merges": {
           "current": 0,
           "current_docs": 0,
           "current_size_in_bytes": 0,
           "total": 1128,
           "total_time_in_millis": 21338523,
           "total_docs": 7241313,
           "total_size_in_bytes": 5724869463
        },</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><code>indexing</code> 显示已经索引了多少文档。这个值是一个累加计数器。在文档被删除的时候，数值不会下降。还要注意的是，在发生内部 <em>索引</em> 操作的时候，这个值也会增加，比如说文档更新。</p>
<div class="paragraph">
<p>还列出了索引操作耗费的时间，正在索引的文档数量，以及删除操作的类似统计值。</p>
</div>
</li>
<li>
<p><code>get</code> 显示通过 ID 获取文档的接口相关的统计值。包括对单个文档的 <code>GET</code> 和 <code>HEAD</code> 请求。</p>
</li>
<li>
<p><code>search</code> 描述在活跃中的搜索（ <code>open_contexts</code> ）数量、查询的总数量、以及自节点启动以来在查询上消耗的总时间。用 <code>query_time_in_millis / query_total</code> 计算的比值，可以用来粗略的评价你的查询有多高效。比值越大，每个查询花费的时间越多，你应该要考虑调优了。</p>
<div class="paragraph">
<p>fetch 统计值展示了查询处理的后一半流程（query-then-fetch 里的 <em>fetch</em> ）。如果 fetch 耗时比 query 还多，说明磁盘较慢，或者获取了太多文档，或者可能搜索请求设置了太大的分页（比如， <code>size: 10000</code> ）。</p>
</div>
</li>
<li>
<p><code>merges</code> 包括了 Lucene 段合并相关的信息。它会告诉你目前在运行几个合并，合并涉及的文档数量，正在合并的段的总大小，以及在合并操作上消耗的总时间。</p>
<div class="paragraph">
<p>在你的集群写入压力很大时，合并统计值非常重要。合并要消耗大量的磁盘 I/O 和 CPU 资源。如果你的索引有大量的写入，同时又发现大量的合并数，一定要去阅读<a href="#indexing-performance">索引性能技巧</a>。</p>
</div>
<div class="paragraph">
<p>注意：文档更新和删除也会导致大量的合并数，因为它们会产生最终需要被合并的段 <em>碎片</em> 。</p>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">        "filter_cache": {
           "memory_size_in_bytes": 48,
           "evictions": 0
        },
        "fielddata": {
           "memory_size_in_bytes": 0,
           "evictions": 0
        },
        "segments": {
           "count": 319,
           "memory_in_bytes": 65812120
        },
        ...</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><code>filter_cache</code> 展示了已缓存的过滤器位集合所用的内存数量，以及过滤器被驱逐出内存的次数。过多的驱逐数 <em>可能</em> 说明你需要加大过滤器缓存的大小，或者你的过滤器不太适合缓存（比如它们因为高基数而在大量产生，就像是缓存一个 <code>now</code> 时间表达式）。</p>
<div class="paragraph">
<p>不过，驱逐数是一个很难评定的指标。过滤器是在每个段的基础上缓存的，而从一个小的段里驱逐过滤器，代价比从一个大的段里要廉价的多。有可能你有很大的驱逐数，但是它们都发生在小段上，也就意味着这些对查询性能只有很小的影响。</p>
</div>
<div class="paragraph">
<p>把驱逐数指标作为一个粗略的参考。如果你看到数字很大，检查一下你的过滤器，确保他们都是正常缓存的。不断驱逐着的过滤器，哪怕都发生在很小的段上，效果也比正确缓存住了的过滤器差很多。</p>
</div>
</li>
<li>
<p><code>field_data</code> 显示 fielddata 使用的内存，用以聚合、排序等等。这里也有一个驱逐计数。和 <code>filter_cache</code> 不同的是，这里的驱逐计数是很有用的：这个数应该或者至少是接近于 0。因为 fielddata 不是缓存，任何驱逐都消耗巨大，应该避免掉。如果你在这里看到驱逐数，你需要重新评估你的内存情况，fielddata 限制，请求语句，或者这三者。</p>
</li>
<li>
<p><code>segments</code> 会展示这个节点目前正在服务中的 Lucene 段的数量。这是一个重要的数字。大多数索引会有大概 50&#x2013;150 个段，哪怕它们存有 TB 级别的数十亿条文档。段数量过大表明合并出现了问题（比如，合并速度跟不上段的创建）。注意这个统计值是节点上所有索引的汇聚总数。记住这点。</p>
<div class="paragraph">
<p><code>memory</code> 统计值展示了 Lucene 段自己用掉的内存大小。这里包括底层数据结构，比如倒排表，字典，和布隆过滤器等。太大的段数量会增加这些数据结构带来的开销，这个内存使用量就是一个方便用来衡量开销的度量值。</p>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_操作系统和进程部分">操作系统和进程部分</h4>
<div class="paragraph">
<p><code>OS</code> 和 <code>Process</code> 部分基本是自描述的，不会在细节中展开讲解。它们列出来基础的资源统计值，比如 CPU 和负载。<code>OS</code> 部分描述了整个操作系统，而 <code>Process</code> 部分只显示 Elasticsearch 的 JVM 进程使用的资源情况。</p>
</div>
<div class="paragraph">
<p>这些都是非常有用的指标，不过通常在你的监控技术栈里已经都测量好了。统计值包括下面这些：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>CPU</p>
</li>
<li>
<p>负载</p>
</li>
<li>
<p>内存使用率</p>
</li>
<li>
<p>Swap 使用率</p>
</li>
<li>
<p>打开的文件描述符</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jvm_部分">JVM 部分</h4>
<div class="paragraph">
<p><code>jvm</code> 部分包括了运行 Elasticsearch 的 JVM 进程一些很关键的信息。最重要的，它包括了垃圾回收的细节，这对你的 Elasticsearch 集群的稳定性有着重大影响。</p>
</div>
<div id="garbage_collector_primer" class="sidebarblock">
<div class="content">
<div class="title">垃圾回收入门</div>
<div class="paragraph">
<p>在我们描述统计值之前，先上一门速成课程讲解垃圾回收以及它对 Elasticsearch 的影响是非常有用的。如果你对 JVM 的垃圾回收很熟悉，请跳过这段。</p>
</div>
<div class="paragraph">
<p>Java 是一门 <em>垃圾回收</em> 语言，也就是说程序员不用手动管理内存分配和回收。程序员只管写代码，然后 Java 虚拟机（JVM）按需分配内存，然后在稍后不再需要的时候清理这部分内存。</p>
</div>
<div class="paragraph">
<p>当内存分配给一个 JVM 进程，它是分配到一个大块里，这个块叫做 <em>堆</em> 。JVM 把堆分成两组，用 <em>代</em> 来表示：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">新生代（或者伊甸园）</dt>
<dd>
<p>新实例化的对象分配的空间。新生代空间通常都非常小，一般在 100 MB&#x2013;500 MB。新生代也包含两个 <em>幸存</em> 空间。</p>
</dd>
<dt class="hdlist1">老生代</dt>
<dd>
<p>较老的对象存储的空间。这些对象预计将长期留存并持续上很长一段时间。老生代通常比新生代大很多。Elasticsearch 节点可以给老生代用到 30 GB。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>当一个对象实例化的时候，它被放在新生代里。当新生代空间满了，就会发生一次新生代垃圾回收（GC）。依然是"存活"状态的对象就被转移到一个幸存区内，而"死掉"的对象被移除。如果一个对象在多次新生代 GC 中都幸存了，它就会被"终身"置于老生代了。</p>
</div>
<div class="paragraph">
<p>类似的过程在老生代里同样发生：空间满的时候，发生一次垃圾回收，死掉的对象被移除。</p>
</div>
<div class="paragraph">
<p>不过，天下没有免费的午餐。新生代、老生代的垃圾回收都有一个阶段会“停止时间”。在这段时间里，JVM 字面意义上的停止了程序运行，以便跟踪对象图，收集死亡对象。在这个时间停止阶段，一切都不会发生。请求不被服务，ping 不被回应，分片不被分配。整个世界都真的停止了。</p>
</div>
<div class="paragraph">
<p>对于新生代，这不是什么大问题；那么小的空间意味着 GC 会很快执行完。但是老生代大很多，而这里面一个慢 GC 可能就意味着 1 秒乃至 15 秒的暂停——对于服务器软件来说这是不可接受的。</p>
</div>
<div class="paragraph">
<p>JVM 的垃圾回收采用了 <em>非常</em> 精密的算法，在减少暂停方面做得很棒。而且 Elasticsearch 非常努力的变成对 <em>垃圾回收友好</em> 的程序，比如内部智能的重用对象，重用网络缓冲，以及默认启用 <a href="#docvalues">[docvalues]</a> 功能。但最终，GC 的频率和时长依然是你需要去观察的指标。因为它是集群不稳定的头号嫌疑人。</p>
</div>
<div class="paragraph">
<p>一个经常发生长 GC 的集群就会因为内存不足而处于高负载压力下。这些长 GC 会导致节点短时间内从集群里掉线。这种不稳定会导致分片频繁重定位，因为 Elasticsearch 会尝试保持集群均衡，保证有足够的副本在线。这接着就导致网络流量和磁盘 I/O 的增加。而所有这些都是在你的集群努力服务于正常的索引和查询的同时发生的。</p>
</div>
<div class="paragraph">
<p>总而言之，长时间 GC 总是不好的，需要尽可能的减少。</p>
</div>
</div>
</div>
<div class="paragraph">
<p>因为垃圾回收对 Elasticsearch 是如此重要，你应该非常熟悉 <code>node-stats</code> API 里的这部分内容：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">        "jvm": {
            "timestamp": 1408556438203,
            "uptime_in_millis": 14457,
            "mem": {
               "heap_used_in_bytes": 457252160,
               "heap_used_percent": 44,
               "heap_committed_in_bytes": 1038876672,
               "heap_max_in_bytes": 1038876672,
               "non_heap_used_in_bytes": 38680680,
               "non_heap_committed_in_bytes": 38993920,</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><code>jvm</code> 部分首先列出一些和 heap 内存使用有关的常见统计值。你可以看到有多少 heap 被使用了，多少被指派了（当前被分配给进程的），以及 heap 被允许分配的最大值。理想情况下，<code>heap_committed_in_bytes</code> 应该等于 <code>heap_max_in_bytes</code> 。如果指派的大小更小，JVM 最终会被迫调整 heap 大小——这是一个非常昂贵的操作。如果你的数字不相等，阅读 <a href="#heap-sizing">堆内存:大小和交换</a> 学习如何正确的配置它。</p>
<div class="paragraph">
<p><code>heap_used_percent</code> 指标是值得关注的一个数字。Elasticsearch 被配置为当 heap 达到 75% 的时候开始 GC。如果你的节点一直 &gt;= 75%，你的节点正处于 <em>内存压力</em> 状态。这是个危险信号，不远的未来可能就有慢 GC 要出现了。</p>
</div>
<div class="paragraph">
<p>如果 heap 使用率一直 &gt;=85%，你就麻烦了。Heap 在 90&#x2013;95% 之间，则面临可怕的性能风险，此时最好的情况是长达 10&#x2013;30s 的 GC，最差的情况就是内存溢出（OOM）异常。</p>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">   "pools": {
      "young": {
         "used_in_bytes": 138467752,
         "max_in_bytes": 279183360,
         "peak_used_in_bytes": 279183360,
         "peak_max_in_bytes": 279183360
      },
      "survivor": {
         "used_in_bytes": 34865152,
         "max_in_bytes": 34865152,
         "peak_used_in_bytes": 34865152,
         "peak_max_in_bytes": 34865152
      },
      "old": {
         "used_in_bytes": 283919256,
         "max_in_bytes": 724828160,
         "peak_used_in_bytes": 283919256,
         "peak_max_in_bytes": 724828160
      }
   }
},</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><code>新生代(young)</code> 、 <code>幸存区(survivor)</code> 和 <code>老生代(old)</code> 部分分别展示 GC 中每一个代的内存使用情况。这些统计值很方便观察其相对大小，但是在调试问题的时候，通常并不怎么重要。</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">"gc": {
   "collectors": {
      "young": {
         "collection_count": 13,
         "collection_time_in_millis": 923
      },
      "old": {
         "collection_count": 0,
         "collection_time_in_millis": 0
      }
   }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><code>gc</code> 部分显示新生代和老生代的垃圾回收次数和累积时间。大多数时候你可以忽略掉新生代的次数：这个数字通常都很大。这是正常的。</p>
<div class="paragraph">
<p>与之相反，老生代的次数应该很小，而且 <code>collection_time_in_millis</code> 也应该很小。这些是累积值，所以很难给出一个阈值表示你要开始操心了（比如，一个跑了一整年的节点，即使很健康，也会有一个比较大的计数）。这就是像 Marvel 这类工具很有用的一个原因。GC 计数的 <em>时间趋势</em> 是个重要的考虑因素。</p>
</div>
<div class="paragraph">
<p>GC 花费的时间也很重要。比如，在索引文档时，一系列垃圾生成了。这是很常见的情况，每时每刻都会导致 GC。这些 GC 绝大多数时候都很快，对节点影响很小：新生代一般就花一两毫秒，老生代花一百多毫秒。这些跟 10 秒级别的 GC 是很不一样的。</p>
</div>
<div class="paragraph">
<p>我们的最佳建议是定期收集 GC 计数和时长（或者使用 Marvel）然后观察 GC 频率。你也可以开启慢 GC 日志记录，在 <a href="#logging">日志记录</a> 小节已经讨论过。</p>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_线程池部分">线程池部分</h4>
<div class="paragraph">
<p>Elasticsearch 在内部维护了线程池。这些线程池相互协作完成任务，有必要的话相互间还会传递任务。通常来说，你不需要配置或者调优线程池，不过查看它们的统计值有时候还是有用的，可以洞察你的集群表现如何。</p>
</div>
<div class="paragraph">
<p>这有一系列的线程池，但以相同的格式输出：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">  "index": {
     "threads": 1,
     "queue": 0,
     "active": 0,
     "rejected": 0,
     "largest": 1,
     "completed": 1
  }</code></pre>
</div>
</div>
<div class="paragraph">
<p>每个线程池会列出已配置的线程数量（ <code>threads</code> ），当前在处理任务的线程数量（ <code>active</code> ），以及在队列中等待处理的任务单元数量（ <code>queue</code> ）。</p>
</div>
<div class="paragraph">
<p>如果队列中任务单元数达到了极限，新的任务单元会开始被拒绝，你会在 <code>rejected</code> 统计值上看到它反映出来。这通常是你的集群在某些资源上碰到瓶颈的信号。因为队列满意味着你的节点或集群在用最高速度运行，但依然跟不上工作的蜂拥而入。</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">批量操作的被拒绝数</div>
<div class="paragraph">
<p>如果你碰到了队列被拒，一般来说都是批量索引请求导致的。通过并发导入程序发送大量批量请求非常简单。越多越好嘛，对不？</p>
</div>
<div class="paragraph">
<p>事实上，每个集群都有它能处理的请求上限。一旦这个阈值被超过，队列会很快塞满，然后新的批量请求就被拒绝了。</p>
</div>
<div class="paragraph">
<p>这是一件 <em>好事情</em> 。队列的拒绝在回压方面是有用的。它们让你知道你的集群已经在最大容量了。这比把数据塞进内存队列要来得好。增加队列大小并不能增加性能，它只是隐藏了问题。当你的集群只能每秒钟处理 10000 个文档的时候，无论队列是 100 还是 10000000 都没关系——你的集群还是只能每秒处理 10000 个文档。</p>
</div>
<div class="paragraph">
<p>队列只是隐藏了性能问题，而且带来的是真实的数据丢失的风险。在队列里的数据都是还没处理的，如果节点挂掉，这些请求都会永久的丢失。此外，队列还要消耗大量内存，这也是不理想的。</p>
</div>
<div class="paragraph">
<p>在你的应用中，优雅的处理来自满载队列的回压，才是更好的选择。当你收到拒绝响应的时候，你应该采取如下几步：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>暂停导入线程 3&#x2013;5 秒。</p>
</li>
<li>
<p>从批量操作的响应里提取出来被拒绝的操作。因为可能很多操作还是成功的。响应会告诉你哪些成功，哪些被拒绝了。</p>
</li>
<li>
<p>发送一个新的批量请求，只包含这些被拒绝过的操作。</p>
</li>
<li>
<p>如果依然碰到拒绝，再次从步骤 1 开始。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>通过这个流程，你的代码可以很自然的适应你集群的负载，做到自动回压。</p>
</div>
<div class="paragraph">
<p>拒绝不是错误：它们只是意味着你要稍后重试。</p>
</div>
</div>
</div>
<div class="paragraph">
<p>这里的一系列的线程池，大多数你可以忽略，但是有一小部分还是值得关注的：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>indexing</code></dt>
<dd>
<p>普通的索引请求的线程池</p>
</dd>
<dt class="hdlist1"><code>bulk</code></dt>
<dd>
<p>批量请求，和单条的索引请求不同的线程池</p>
</dd>
<dt class="hdlist1"><code>get</code></dt>
<dd>
<p>Get-by-ID 操作</p>
</dd>
<dt class="hdlist1"><code>search</code></dt>
<dd>
<p>所有的搜索和查询请求</p>
</dd>
<dt class="hdlist1"><code>merging</code></dt>
<dd>
<p>专用于管理 Lucene 合并的线程池</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_文件系统和网络部分">文件系统和网络部分</h4>
<div class="paragraph">
<p>继续向下阅读 <code>node-stats</code> API，你会看到一串和你的文件系统相关的统计值：可用空间，数据目录路径，磁盘 I/O 统计值，等等。如果你没有监控磁盘可用空间的话，可以从这里获取这些统计值。磁盘 I/O 统计值也很方便，不过通常那些更专门的命令行工具（比如 <code>iostat</code> ）会更有用些。</p>
</div>
<div class="paragraph">
<p>显然，Elasticsearch 在磁盘空间满的时候很难运行——所以请确保不会这样。</p>
</div>
<div class="paragraph">
<p>还有两个跟网络统计值相关的部分：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">        "transport": {
            "server_open": 13,
            "rx_count": 11696,
            "rx_size_in_bytes": 1525774,
            "tx_count": 10282,
            "tx_size_in_bytes": 1440101928
         },
         "http": {
            "current_open": 4,
            "total_opened": 23
         },</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><code>transport</code> 显示和 <em>传输地址</em> 相关的一些基础统计值。包括节点间的通信（通常是 9300 端口）以及任意传输客户端或者节点客户端的连接。如果看到这里有很多连接数不要担心；Elasticsearch 在节点之间维护了大量的连接。</p>
</li>
<li>
<p><code>http</code> 显示 HTTP 端口（通常是 9200）的统计值。如果你看到 <code>total_opened</code> 数很大而且还在一直上涨，这是一个明确信号，说明你的 HTTP 客户端里有没启用 keep-alive 长连接的。持续的 keep-alive 长连接对性能很重要，因为连接、断开套接字是很昂贵的（而且浪费文件描述符）。请确认你的客户端都配置正确。</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_断路器">断路器</h4>
<div class="paragraph">
<p>终于，我们到了最后一段：跟 fielddata 断路器（在 <a href="#circuit-breaker">[circuit-breaker]</a> 介绍过）相关的统计值：</p>
</div>
<div class="listingblock pagebreak-before">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">         "fielddata_breaker": {
            "maximum_size_in_bytes": 623326003,
            "maximum_size": "594.4mb",
            "estimated_size_in_bytes": 0,
            "estimated_size": "0b",
            "overhead": 1.03,
            "tripped": 0
         }</code></pre>
</div>
</div>
<div class="paragraph">
<p>这里你可以看到断路器的最大值（比如，一个请求申请更多的内存时会触发断路器）。这个部分还会让你知道断路器被触发了多少次，以及当前配置的间接开销。间接开销用来铺垫评估，因为有些请求比其他请求更难评估。</p>
</div>
<div class="paragraph">
<p>主要需要关注的是 <code>tripped</code> 指标。如果这个数字很大或者持续上涨，这是一个信号，说明你的请求需要优化，或者你需要添加更多内存（单机上添加，或者通过添加新节点的方式）。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_cluster_stats">集群统计</h3>
<div class="paragraph">
<p><code>集群统计</code> API 提供了和 <code>节点统计</code> 相似的输出。 但有一个重要的区别：节点统计显示的是每个节点上的统计值，而 <code>集群统计</code> 展示的是对于单个指标，所有节点的总和值。</p>
</div>
<div class="paragraph">
<p>这里面提供一些很值得一看的统计值。比如说你可以看到，整个集群用了 50% 的堆内存，或者说过滤器缓存的驱逐情况不严重。这个接口主要用途是提供一个比 <code>集群健康</code> 更详细、但又没有 <code>节点统计</code> 那么详细的快速概览。对于非常大的集群来说也很有用，因为那时候 <code>节点统计</code> 的输出已经非常难于阅读了。</p>
</div>
<div class="paragraph">
<p>这个 API 可以像下面这样调用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET _cluster/stats</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_index_stats">索引统计</h3>
<div class="paragraph">
<p>到目前为止，我们看到的都是以 <em>节点为中心</em> 的统计值： 节点有多少内存？用了多少 CPU ？正在服务多少个搜索？</p>
</div>
<div class="paragraph">
<p>有时候从 <em>索引为中心</em> 的角度看统计值也很有用：<em>这个索引</em> 收到了多少个搜索请求？<em>那个索引</em> 获取文档耗费了多少时间？</p>
</div>
<div class="paragraph">
<p>要做到这点，选择你感兴趣的索引 （ 或者多个索引 ）然后执行一个索引级别的 <code>统计</code> API：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET my_index/_stats <b class="conum">(1)</b>

GET my_index,another_index/_stats <b class="conum">(2)</b>

GET _all/_stats <b class="conum">(3)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>统计 <code>my_index</code> 索引。</p>
</li>
<li>
<p>使用逗号分隔索引名可以请求多个索引统计值。</p>
</li>
<li>
<p>使用特定的 <code>_all</code> 可以请求全部索引的统计值</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>返回的统计信息和 <code>节点统计</code> 的输出很相似：<code>search</code> 、 <code>fetch</code> 、 <code>get</code> 、 <code>index</code> 、 <code>bulk</code> 、 <code>segment counts</code> 等等。</p>
</div>
<div class="paragraph">
<p>索引为中心的统计在有些时候很有用，比如辨别或验证集群中的 <em>热门</em> 索引，或者试图找出某些索引比其他索引更快或者更慢的原因。</p>
</div>
<div class="paragraph">
<p>实践中，节点为中心的统计还是显得更有用些。瓶颈往往是针对整个节点而言，而不是对于单个索引。因为索引一般是分布在多个节点上的，这导致以索引为中心的统计值通常不是很有用，因为它们是从不同环境的物理机器上汇聚的数据。</p>
</div>
<div class="paragraph">
<p>索引为中心的统计作为一个有用的工具可以保留在你的技能表里，但是通常它不会是第一个用的上的工具。</p>
</div>
</div>
<div class="sect2">
<h3 id="_pending_tasks">等待中的任务</h3>
<div class="paragraph">
<p>有一些任务只能由主节点去处理，比如创建一个新的索引或者在集群中移动分片。由于一个集群中只能有一个主节点，所以只有这一节点可以处理集群级别的元数据变动。在 99.9999% 的时间里，这不会有什么问题。元数据变动的队列基本上保持为零。</p>
</div>
<div class="paragraph">
<p>在一些 <code>罕见</code> 的集群里，元数据变动的次数比主节点能处理的还快。这会导致等待中的操作会累积成队列。</p>
</div>
<div class="paragraph">
<p><code>等待中的任务</code> API  会给你展示队列中（如果有的话）等待的集群级别的元数据变更操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET _cluster/pending_tasks</code></pre>
</div>
</div>
<div class="paragraph">
<p>通常，响应都是像这样的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "tasks": []
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这意味着没有等待中的任务。如果你有一个罕见的集群在主节点出现瓶颈了，等待中的任务列表可能会像这样：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "tasks": [
      {
         "insert_order": 101,
         "priority": "URGENT",
         "source": "create-index [foo_9], cause [api]",
         "time_in_queue_millis": 86,
         "time_in_queue": "86ms"
      },
      {
         "insert_order": 46,
         "priority": "HIGH",
         "source": "shard-started ([foo_2][1], node[tMTocMvQQgGCkj7QDHl3OA], [P],
         s[INITIALIZING]), reason [after recovery from gateway]",
         "time_in_queue_millis": 842,
         "time_in_queue": "842ms"
      },
      {
         "insert_order": 45,
         "priority": "HIGH",
         "source": "shard-started ([foo_2][0], node[tMTocMvQQgGCkj7QDHl3OA], [P],
         s[INITIALIZING]), reason [after recovery from gateway]",
         "time_in_queue_millis": 858,
         "time_in_queue": "858ms"
      }
  ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>可以看到任务都被指派了优先级（ 比如说 <code>URGENT</code> 要比 <code>HIGH</code> 更早的处理 ），任务插入的次序、操作进入队列多久，以及打算处理什么。在上面的列表中，有一个 <code>创建索引(create-index)</code> 和两个 <code>启动分片(shard-started)</code> 的操作在等待。</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">什么时候应该担心等待中的任务？</div>
<div class="paragraph">
<p>就像曾经提到过的，主节点很少会成为集群的瓶颈。唯一可能成为瓶颈的是集群状态非常大 <em>而且</em> 更新频繁。</p>
</div>
<div class="paragraph">
<p>例如，如果你允许客户按照他们的意愿创建任意的动态字段，而且每个客户每天都有一个独立索引，那么你的集群状态会变得非常大。集群状态包括 ( 但不限于 ) 所有索引及其类型，以及每个索引的全部字段。</p>
</div>
<div class="paragraph">
<p>所以如果你有 100000 客户，然后每个客户平均有 1000 个字段，而且数据有 90 天的保留期—这就有九十亿个字段需要保存在集群状态中。不管它何时发生变更，所有的节点都需要被通知。</p>
</div>
<div class="paragraph">
<p>主节点必须处理这些变动，这需要不小的 CPU 开销，加上推送更新的集群状态到所有节点的网络开销。</p>
</div>
<div class="paragraph">
<p>这就是那些可以看到集群状态操作队列上涨的集群。没有简单的办法可以解决这个问题，不过你有三个选择：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>使用一个更强大的主节点。不幸的是，这种垂直扩展只是延迟这种必然结果出现而已。</p>
</li>
<li>
<p>通过某些方式限定文档的动态性质来限制集群状态的大小。</p>
</li>
<li>
<p>到达某个阈值后组建另外一个集群。</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_cat_api">cat API</h3>
<div class="paragraph">
<p>如果经常在命令行环境下工作，<code>cat</code> API 对你会非常有用。用 Linux 的 <code>cat</code> 命令命名，这些 API 也就设计成像 *nix 命令行工具一样工作了。</p>
</div>
<div class="paragraph">
<p>他们提供的统计和前面已经讨论过的 API ( 健康、<code>节点统计</code> 等等 ) 是一样的。但是输出以表格的形式提供，而不是 JSON。对于系统管理员来说这是 <em>非常</em> 方便的，你仅仅想浏览一遍集群或者找出内存使用偏高的节点而已。</p>
</div>
<div class="paragraph">
<p>通过 <code>GET</code> 请求发送 <code>cat</code> 命名可以列出所有可用的 API：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">GET /_cat

=^.^=
/_cat/allocation
/_cat/shards
/_cat/shards/{index}
/_cat/master
/_cat/nodes
/_cat/indices
/_cat/indices/{index}
/_cat/segments
/_cat/segments/{index}
/_cat/count
/_cat/count/{index}
/_cat/recovery
/_cat/recovery/{index}
/_cat/health
/_cat/pending_tasks
/_cat/aliases
/_cat/aliases/{alias}
/_cat/thread_pool
/_cat/plugins
/_cat/fielddata
/_cat/fielddata/{fields}</code></pre>
</div>
</div>
<div class="paragraph">
<p>许多 API 看起来很熟悉了 ( 是的，顶上还有一只猫:) )。让我们看看 <code>cat</code> 的健康检查 API：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">GET /_cat/health

1408723713 12:08:33 elasticsearch_zach yellow 1 1 114 114 0 0 114</code></pre>
</div>
</div>
<div class="paragraph">
<p>首先你会注意到的是响应是表格样式的纯文本，而不是 JSON。其次你会注意到各列默认是没有表头的。这都是模仿 *nix 工具设计的，因为它假设一旦你对输出熟悉了，你就再也不想看见表头了。</p>
</div>
<div class="paragraph">
<p>要启用表头，添加 <code>?v</code> 参数即可：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">GET /_cat/health?v

epoch   time    cluster status node.total node.data shards pri relo init
1408[..] 12[..] el[..]  1         1         114 114    0    0     114
unassign</code></pre>
</div>
</div>
<div class="paragraph">
<p>嗯，好多了。我们现在看到 时间戳、集群名称、状态、集群中节点的数量等等—所有信息和 <code>集群健康</code> API 返回的都一样。</p>
</div>
<div class="paragraph">
<p>让我们再看看 <code>cat</code> API 里面的 <code>节点统计</code> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">GET /_cat/nodes?v

host         ip            heap.percent ram.percent load node.role master name
zacharys-air 192.168.1.131           45          72 1.85 d         *      Zach</code></pre>
</div>
</div>
<div class="paragraph">
<p>我们看到集群里节点的一些统计，不过和完整的 <code>节点统计</code> 输出相比而言是非常基础的。你可以包含更多的指标，但是比起查阅文档，让我们直接问 <code>cat</code> API 有哪些可用的吧。</p>
</div>
<div class="paragraph">
<p>你可以过对任意 API 添加 <code>?help</code> 参数来做到这点：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">GET /_cat/nodes?help

id               | id,nodeId               | unique node id
pid              | p                       | process id
host             | h                       | host name
ip               | i                       | ip address
port             | po                      | bound transport port
version          | v                       | es version
build            | b                       | es build hash
jdk              | j                       | jdk version
disk.avail       | d,disk,diskAvail        | available disk space
heap.percent     | hp,heapPercent          | used heap ratio
heap.max         | hm,heapMax              | max configured heap
ram.percent      | rp,ramPercent           | used machine memory ratio
ram.max          | rm,ramMax               | total machine memory
load             | l                       | most recent load avg
uptime           | u                       | node uptime
node.role        | r,role,dc,nodeRole      | d:data node, c:client node
master           | m                       | m:master-eligible, *:current master
...
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>( 注意这个输出为了页面简洁而被截断了 )。</p>
</div>
<div class="paragraph">
<p>第一列显示完整的名称，第二列显示缩写，第三列提供了关于这个参数的简介。现在我们知道了一些列名了，我们可以用 <code>?h</code> 参数来明确指定显示这些指标：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">GET /_cat/nodes?v&amp;h=ip,port,heapPercent,heapMax

ip            port heapPercent heapMax
192.168.1.131 9300          53 990.7mb</code></pre>
</div>
</div>
<div class="paragraph">
<p>因为 <code>cat</code> API 试图像 *nix 工具一样工作，你可以使用管道命令将结果传递给其他工具，比如 <code>sort</code> 、 <code>grep</code> 或者 <code>awk</code> 。例如，通过以下方式可以找到集群中最大的索引：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">% curl 'localhost:9200/_cat/indices?bytes=b' | sort -rnk8

yellow test_names         5 1 3476004 0 376324705 376324705
yellow .marvel-2014.08.19 1 1  263878 0 160777194 160777194
yellow .marvel-2014.08.15 1 1  234482 0 143020770 143020770
yellow .marvel-2014.08.09 1 1  222532 0 138177271 138177271
yellow .marvel-2014.08.18 1 1  225921 0 138116185 138116185
yellow .marvel-2014.07.26 1 1  173423 0 132031505 132031505
yellow .marvel-2014.08.21 1 1  219857 0 128414798 128414798
yellow .marvel-2014.07.27 1 1   75202 0  56320862  56320862
yellow wavelet            5 1    5979 0  54815185  54815185
yellow .marvel-2014.07.28 1 1   57483 0  43006141  43006141
yellow .marvel-2014.07.21 1 1   31134 0  27558507  27558507
yellow .marvel-2014.08.01 1 1   41100 0  27000476  27000476
yellow kibana-int         5 1       2 0     17791     17791
yellow t                  5 1       7 0     15280     15280
yellow website            5 1      12 0     12631     12631
yellow agg_analysis       5 1       5 0      5804      5804
yellow v2                 5 1       2 0      5410      5410
yellow v1                 5 1       2 0      5367      5367
yellow bank               1 1      16 0      4303      4303
yellow v                  5 1       1 0      2954      2954
yellow p                  5 1       2 0      2939      2939
yellow b0001_072320141238 5 1       1 0      2923      2923
yellow ipaddr             5 1       1 0      2917      2917
yellow v2a                5 1       1 0      2895      2895
yellow movies             5 1       1 0      2738      2738
yellow cars               5 1       0 0      1249      1249
yellow wavelet2           5 1       0 0       615       615</code></pre>
</div>
</div>
<div class="paragraph">
<p>通过添加 <code>?bytes=b</code> ，我们关闭了人类可读的数字格式化，强制它们以字节数输出。随后通过管道命令将输出传递给 <code>sort</code> 让索引按大小（ 第八列 ）排序</p>
</div>
<div class="paragraph">
<p>不幸的是，你会注意到 Marval 索引也出现在结果中，但是我们目前并不真正在意这些索引。让我们把结果传递给 <code>grep</code> 命令来移除提到 Marval 的数据：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">% curl 'localhost:9200/_cat/indices?bytes=b' | sort -rnk8 | grep -v marvel

yellow test_names         5 1 3476004 0 376324705 376324705
yellow wavelet            5 1    5979 0  54815185  54815185
yellow kibana-int         5 1       2 0     17791     17791
yellow t                  5 1       7 0     15280     15280
yellow website            5 1      12 0     12631     12631
yellow agg_analysis       5 1       5 0      5804      5804
yellow v2                 5 1       2 0      5410      5410
yellow v1                 5 1       2 0      5367      5367
yellow bank               1 1      16 0      4303      4303
yellow v                  5 1       1 0      2954      2954
yellow p                  5 1       2 0      2939      2939
yellow b0001_072320141238 5 1       1 0      2923      2923
yellow ipaddr             5 1       1 0      2917      2917
yellow v2a                5 1       1 0      2895      2895
yellow movies             5 1       1 0      2738      2738
yellow cars               5 1       0 0      1249      1249
yellow wavelet2           5 1       0 0       615       615</code></pre>
</div>
</div>
<div class="paragraph">
<p>瞧！在传递给 <code>grep</code> ( 通过 <code>-v</code> 来过滤掉不需要匹配的数据 ) 之后，我们得到了一个没有 Marval 混杂的索引排序列表了。</p>
</div>
<div class="paragraph">
<p>这只是命令行上 <code>cat</code> 的灵活性的一个简单示例。一旦你习惯了使用 <code>cat</code> ，你会发现它和其他所有 *nix 工具一样并且开始疯狂的使用管道、排序和过滤。如果你是一个系统管理员并且永远都是 SSH 登录到设备上，那么当然要花些时间来熟悉 <code>cat</code> API 了。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="deploy">部署</h2>
<div class="sectionbody">
<div class="paragraph">
<p>如果你按照书中步骤做到了这一步，希望你已经学到了一两件关于 Elasticsearch 的事情并且准备把你的集群部署到生产环境。 这一章不是在生产中运行集群的详尽指南，但是它涵盖了集群上线之前需要考虑的关键事项。</p>
</div>
<div class="paragraph">
<p>主要包括三个方面：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>后勤方面的考虑，如硬件和部署策略的建议</p>
</li>
<li>
<p>更适合于生产环境的配置更改</p>
</li>
<li>
<p>部署后的考虑，例如安全，最大限度的索引性能和备份</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="hardware">硬件</h3>
<div class="paragraph">
<p>按照正常的流程，你可能已经在自己的笔记本电脑或集群上使用了 Elasticsearch。
但是当要部署 Elasticsearch 到生产环境时，有一些建议是你需要考虑的。这里没有什么必须要遵守的准则，Elasticsearch 被用于在众多的机器上处理各种任务。基于我们在生产环境使用 Elasticsearch 集群的经验，这些建议可以为你提供一个好的起点。</p>
</div>
<div class="sect3">
<h4 id="_内存">内存</h4>
<div class="paragraph">
<p>如果有一种资源是最先被耗尽的，它可能是内存。排序和聚合都很耗内存，所以有足够的堆空间来应付它们是很重要的。即使堆空间是比较小的时候，
也能为操作系统文件缓存提供额外的内存。因为 Lucene 使用的许多数据结构是基于磁盘的格式，Elasticsearch 利用操作系统缓存能产生很大效果。</p>
</div>
<div class="paragraph">
<p>64 GB 内存的机器是非常理想的， 但是32 GB 和16 GB 机器也是很常见的。少于8 GB 会适得其反（你最终需要很多很多的小机器），大于64 GB 的机器也会有问题，
我们将在 <a href="#heap-sizing">堆内存:大小和交换</a> 中讨论。</p>
</div>
</div>
<div class="sect3">
<h4 id="_cpus">CPUs</h4>
<div class="paragraph">
<p>大多数 Elasticsearch 部署往往对 CPU 要求不高。因此，相对其它资源，具体配置多少个（CPU）不是那么关键。你应该选择具有多个内核的现代处理器，常见的集群使用两到八个核的机器。</p>
</div>
<div class="paragraph">
<p>如果你要在更快的 CPUs 和更多的核心之间选择，选择更多的核心更好。多个内核提供的额外并发远胜过稍微快一点点的时钟频率。</p>
</div>
</div>
<div class="sect3">
<h4 id="_硬盘">硬盘</h4>
<div class="paragraph">
<p>硬盘对所有的集群都很重要，对大量写入的集群更是加倍重要（例如那些存储日志数据的）。硬盘是服务器上最慢的子系统，这意味着那些写入量很大的集群很容易让硬盘饱和，使得它成为集群的瓶颈。</p>
</div>
<div class="paragraph">
<p>如果你负担得起 SSD，它将远远超出任何旋转介质（注：机械硬盘，磁带等）。 基于 SSD 的节点，查询和索引性能都有提升。如果你负担得起，SSD 是一个好的选择。</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">检查你的 I/O 调度程序</div>
<div class="paragraph">
<p>如果你正在使用 SSDs，确保你的系统 I/O 调度程序是配置正确的。
当你向硬盘写数据，I/O 调度程序决定何时把数据实际发送到硬盘。
大多数默认 *nix 发行版下的调度程序都叫做 <code>cfq</code>（完全公平队列）。</p>
</div>
<div class="paragraph">
<p>调度程序分配 <em>时间片</em> 到每个进程。并且优化这些到硬盘的众多队列的传递。但它是为旋转介质优化的：
机械硬盘的固有特性意味着它写入数据到基于物理布局的硬盘会更高效。</p>
</div>
<div class="paragraph">
<p>这对 SSD 来说是低效的，尽管这里没有涉及到机械硬盘。但是，<code>deadline</code> 或者 <code>noop</code> 应该被使用。<code>deadline</code> 调度程序基于写入等待时间进行优化，
<code>noop</code> 只是一个简单的 FIFO 队列。</p>
</div>
<div class="paragraph">
<p>这个简单的更改可以带来显著的影响。仅仅是使用正确的调度程序，我们看到了500倍的写入能力提升。</p>
</div>
</div>
</div>
<div class="paragraph">
<p>如果你使用旋转介质，尝试获取尽可能快的硬盘（高性能服务器硬盘，15k RPM 驱动器）。</p>
</div>
<div class="paragraph">
<p>使用 RAID 0 是提高硬盘速度的有效途径，对机械硬盘和 SSD 来说都是如此。没有必要使用镜像或其它 RAID 变体，因为高可用已经通过 replicas 内建于 Elasticsearch 之中。</p>
</div>
<div class="paragraph">
<p>最后，避免使用网络附加存储（NAS）。人们常声称他们的 NAS 解决方案比本地驱动器更快更可靠。除却这些声称，
我们从没看到 NAS 能配得上它的大肆宣传。NAS 常常很慢，显露出更大的延时和更宽的平均延时方差，而且它是单点故障的。</p>
</div>
</div>
<div class="sect3">
<h4 id="_网络">网络</h4>
<div class="paragraph">
<p>快速可靠的网络显然对分布式系统的性能是很重要的。
低延时能帮助确保节点间能容易的通讯，大带宽能帮助分片移动和恢复。现代数据中心网络（1 GbE, 10 GbE）对绝大多数集群都是足够的。</p>
</div>
<div class="paragraph">
<p>即使数据中心们近在咫尺，也要避免集群跨越多个数据中心。绝对要避免集群跨越大的地理距离。</p>
</div>
<div class="paragraph">
<p>Elasticsearch 假定所有节点都是平等的&#8212;&#8203;并不会因为有一半的节点在150ms 外的另一数据中心而有所不同。更大的延时会加重分布式系统中的问题而且使得调试和排错更困难。</p>
</div>
<div class="paragraph">
<p>和 NAS 的争论类似，每个人都声称他们的数据中心间的线路都是健壮和低延时的。这是真的&#8212;&#8203;直到它不是时（网络失败终究是会发生的，你可以相信它）。
从我们的经验来看，处理跨数据中心集群的麻烦事是根本不值得的。</p>
</div>
</div>
<div class="sect3">
<h4 id="_总则">总则</h4>
<div class="paragraph">
<p>获取真正的高配机器在今天是可能的：成百 GB 的 RAM 和几十个 CPU 核心。
反之，在云平台上串联起成千的小虚拟机也是可能的，例如 EC2。哪种方式是最好的?</p>
</div>
<div class="paragraph">
<p>通常，选择中配或者高配机器更好。避免使用低配机器，
因为你不会希望去管理拥有上千个节点的集群，而且在这些低配机器上运行 Elasticsearch 的开销也是显著的。</p>
</div>
<div class="paragraph">
<p>与此同时，避免使用真正的高配机器。它们通常会导致资源使用不均衡（例如，所有的内存都被使用，但 CPU 却没有）而且在单机上运行多个节点时，会增加逻辑复杂度。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_java_virtual_machine">Java 虚拟机</h3>
<div class="paragraph">
<p>你应该始终运行最新版本的 Java 虚拟机（ JVM ），
除非 Elasticsearch 网站上另有说明。  Elasticsearch，
特别是 Lucene，是一个高要求的软件。Lucene 的单元测试和集成测试经常暴露出 JVM 本身的 bug。这些 bug 的范围从轻微的麻烦到严重段错误，所以，最好尽可能的使用最新版本的 JVM。</p>
</div>
<div class="paragraph">
<p>Java 8 强烈优先选择于 Java 7。不再支持 Java 6。Oracle 或者 OpenJDK 是可以接受的，它们在性能和稳定性也差不多。</p>
</div>
<div class="paragraph">
<p>如果你的应用程序是用 Java 编写并正在使用传输客户端（注：Transport Client，下同）或节点客户端（注：Node Client，下同），请确保运行你应用程序的 JVM 和服务器的 JVM 是完全一样的。
在 Elasticsearch 的几个地方，使用 Java 的本地序列化（ IP 地址、异常等等）。不幸的是，Oracle 的 JVM 在几个小版本之间有修改序列化格式，从而导致奇怪的错误。
这种情况很少见，但最佳实践是客户端和服务器使用相同版本 JVM。</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">请不要调整 JVM 设置</div>
<div class="paragraph">
<p>JVM 暴露出几十个（甚至数百）的设置、参数和配置。 它们允许你进行微调 JVM 几乎是每一个方面。
当遇到一个旋钮，要打开它是人的本性。我们恳求你压制这个本性，而 <em>不要</em> 去调整 JVM 参数。Elasticsearch 是复杂的软件，并且我们根据多年的实际使用情况调整了当前 JVM 设置。
它很容易开始转动旋钮，并产生难以衡量的、未知的影响，并最终使集群进入一个缓慢的、不稳定的混乱的效果。当调试集群时，第一步往往是去除所有的自定义配置。多数情况下，仅此就可以恢复稳定和性能。</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_transport_client_versus_node_client">Transport Client 与 Node Client</h3>
<div class="paragraph">
<p>如果你使用的是 Java，你可能想知道何时使用传输客户端（注：Transport Client，下同）与节点客户端（注：Node Client，下同）。 在书的开头所述，
传输客户端作为一个集群和应用程序之间的通信层。它知道 API 并能自动帮你在节点之间轮询，帮你嗅探集群等等。但它是集群 <em>外部的</em> ，和 REST 客户端类似。</p>
</div>
<div class="paragraph">
<p>另一方面，节点客户端，实际上是一个集群中的节点（但不保存数据，不能成为主节点）。因为它是一个节点，它知道整个集群状态（所有节点驻留，分片分布在哪些节点，等等）。
这意味着它可以执行 APIs 但少了一个网络跃点。</p>
</div>
<div class="paragraph">
<p>这里有两个客户端案例的使用情况：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>如果要将应用程序和 Elasticsearch 集群进行解耦，传输客户端是一个理想的选择。例如，如果您的应用程序需要快速的创建和销毁到集群的连接，传输客户端比节点客户端”轻”，因为它不是一个集群的一部分。</p>
<div class="paragraph">
<p>类似地，如果您需要创建成千上万的连接，你不想有成千上万节点加入集群。传输客户端（ TC ）将是一个更好的选择。</p>
</div>
</li>
<li>
<p>另一方面，如果你只需要有少数的、长期持久的对象连接到集群，客户端节点可以更高效，因为它知道集群的布局。但是它会使你的应用程序和集群耦合在一起，所以从防火墙的角度，它可能会构成问题。</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_configuration_management">配置管理</h3>
<div class="paragraph">
<p>如果你已经使用配置管理（ Puppet，Chef，Ansible），则可以跳过此提示。</p>
</div>
<div class="paragraph">
<p>如果你没有使用配置管理工具，那么应该注意了！通过 <code>parallel-ssh</code> 管理少量服务器现在可能正常工作，但伴随着集群的增长它将成为一场噩梦。
在不犯错误的情况下手动编辑 30 个配置文件几乎是不可能的。</p>
</div>
<div class="paragraph">
<p>配置管理工具通过自动化更改配置的过程保持集群的一致性。这可能需要一点时间来建立和学习，但它本身，随着时间的推移会有丰厚的回报。</p>
</div>
</div>
<div class="sect2">
<h3 id="important-configuration-changes">重要配置的修改</h3>
<div class="paragraph">
<p>Elasticsearch 已经有了 <em>很好</em> 的默认值，特别是涉及到性能相关的配置或者选项。
如果你有疑问，最好就不要动它。我们已经目睹了数十个因为错误的设置而导致毁灭的集群，
因为它的管理者总认为改动一个配置或者选项就可以带来 100 倍的提升。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>请阅读整节文章，所有的配置项都同等重要，和描述顺序无关，请阅读所有的配置选项，并应用到你的集群中。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>其它数据库可能需要调优，但总得来说，Elasticsearch 不需要。
如果你遇到了性能问题，解决方法通常是更好的数据布局或者更多的节点。
在 Elasticsearch 中很少有“神奇的配置项”，
如果存在，我们也已经帮你优化了！</p>
</div>
<div class="paragraph">
<p>另外，有些 <em>逻辑上的</em> 配置在生产环境中是应该调整的。
这些调整可能会让你的工作更加轻松，又或者因为没办法设定一个默认值（它取决于你的集群布局）。</p>
</div>
<div class="sect3">
<h4 id="_指定名字">指定名字</h4>
<div class="paragraph">
<p>Elasticsearch 默认启动的集群名字叫 <code>elasticsearch</code> 。你最好给你的生产环境的集群改个名字，改名字的目的很简单，
就是防止某人的笔记本电脑加入了集群这种意外。简单修改成 <code>elasticsearch_production</code> 会很省心。</p>
</div>
<div class="paragraph">
<p>你可以在你的 <code>elasticsearch.yml</code> 文件中修改：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">cluster.name: elasticsearch_production</code></pre>
</div>
</div>
<div class="paragraph">
<p>同样，最好也修改你的节点名字。就像你现在可能发现的那样，
Elasticsearch 会在你的节点启动的时候随机给它指定一个名字。你可能会觉得这很有趣，但是当凌晨 3 点钟的时候，
你还在尝试回忆哪台物理机是 Tagak the Leopard Lord 的时候，你就不觉得有趣了。</p>
</div>
<div class="paragraph">
<p>更重要的是，这些名字是在启动的时候产生的，每次启动节点，
它都会得到一个新的名字。这会使日志变得很混乱，因为所有节点的名称都是不断变化的。</p>
</div>
<div class="paragraph">
<p>这可能会让你觉得厌烦，我们建议给每个节点设置一个有意义的、清楚的、描述性的名字，同样你可以在 <code>elasticsearch.yml</code> 中配置：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">node.name: elasticsearch_005_data</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_路径">路径</h4>
<div class="paragraph">
<p>默认情况下，Elasticsearch 会把插件、日志以及你最重要的数据放在安装目录下。这会带来不幸的事故，
如果你重新安装 Elasticsearch 的时候不小心把安装目录覆盖了。如果你不小心，你就可能把你的全部数据删掉了。</p>
</div>
<div class="paragraph">
<p>不要笑，这种情况，我们见过很多次了。</p>
</div>
<div class="paragraph">
<p>最好的选择就是把你的数据目录配置到安装目录以外的地方，
同样你也可以选择转移你的插件和日志目录。</p>
</div>
<div class="paragraph">
<p>可以更改如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">path.data: /path/to/data1,/path/to/data2 <b class="conum">(1)</b>

# Path to log files:
path.logs: /path/to/logs

# Path to where plugins are installed:
path.plugins: /path/to/plugins</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>注意：你可以通过逗号分隔指定多个目录。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>数据可以保存到多个不同的目录，
如果将每个目录分别挂载不同的硬盘，这可是一个简单且高效实现一个软磁盘阵列（ RAID 0 ）的办法。Elasticsearch 会自动把条带化（注：RAID 0 又称为 Stripe（条带化），在磁盘阵列中,数据是以条带的方式贯穿在磁盘阵列所有硬盘中的）
数据分隔到不同的目录，以便提高性能。</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
<div class="title">多个数据路径的安全性和性能</div>
<div class="paragraph">
<p>如同任何磁盘阵列（ RAID 0 ）的配置，只有单一的数据拷贝保存到硬盘驱动器。如果你失去了一个硬盘驱动器，你 <em>肯定</em> 会失去该计算机上的一部分数据。
运气好的话你的副本在集群的其他地方，可以用来恢复数据和最近的备份。</p>
</div>
<div class="paragraph">
<p>Elasticsearch 试图将全部的条带化分片放到单个驱动器来保证最小程度的数据丢失。这意味着 <code>分片 0</code> 将完全被放置在单个驱动器上。
Elasticsearch 没有一个条带化的分片跨越在多个驱动器，因为一个驱动器的损失会破坏整个分片。</p>
</div>
<div class="paragraph">
<p>这对性能产生的影响是：如果您添加多个驱动器来提高一个单独索引的性能，可能帮助不大，因为
大多数节点只有一个分片和这样一个积极的驱动器。多个数据路径只是帮助如果你有许多索引／分片在单个节点上。</p>
</div>
<div class="paragraph">
<p>多个数据路径是一个非常方便的功能，但到头来，Elasticsearch 并不是软磁盘阵列（ software RAID ）的软件。如果你需要更高级的、稳健的、灵活的配置，
我们建议你使用软磁盘阵列（ software RAID ）的软件，而不是多个数据路径的功能。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_最小主节点数">最小主节点数</h4>
<div class="paragraph">
<p><code>minimum_master_nodes</code> 设定对你的集群的稳定 <em>极其</em> 重要。

当你的集群中有两个 masters（注：主节点）的时候，这个配置有助于防止 <em>脑裂</em> ，一种两个主节点同时存在于一个集群的现象。</p>
</div>
<div class="paragraph">
<p>如果你的集群发生了脑裂，那么你的集群就会处在丢失数据的危险中，因为主节点被认为是这个集群的最高统治者，它决定了什么时候新的索引可以创建，分片是如何移动的等等。如果你有 <em>两个</em> masters 节点，
你的数据的完整性将得不到保证，因为你有两个节点认为他们有集群的控制权。</p>
</div>
<div class="paragraph">
<p>这个配置就是告诉 Elasticsearch 当没有足够 master 候选节点的时候，就不要进行 master 节点选举，等 master 候选节点足够了才进行选举。</p>
</div>
<div class="paragraph">
<p>此设置应该始终被配置为 master 候选节点的法定个数（大多数个）。法定个数就是 <code>( master 候选节点个数 / 2) + 1</code> 。
这里有几个例子：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>如果你有 10 个节点（能保存数据，同时能成为 master），法定数就是 <code>6</code> 。</p>
</li>
<li>
<p>如果你有 3 个候选 master 节点，和 100 个 data 节点，法定数就是 <code>2</code> ，你只要数数那些可以做 master 的节点数就可以了。</p>
</li>
<li>
<p>如果你有两个节点，你遇到难题了。法定数当然是 <code>2</code> ，但是这意味着如果有一个节点挂掉，你整个集群就不可用了。
设置成 <code>1</code> 可以保证集群的功能，但是就无法保证集群脑裂了，像这样的情况，你最好至少保证有 3 个节点。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>你可以在你的 <code>elasticsearch.yml</code> 文件中这样配置：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">discovery.zen.minimum_master_nodes: 2</code></pre>
</div>
</div>
<div class="paragraph">
<p>但是由于 ELasticsearch 是动态的，你可以很容易的添加和删除节点，
但是这会改变这个法定个数。
你不得不修改每一个索引节点的配置并且重启你的整个集群只是为了让配置生效，这将是非常痛苦的一件事情。</p>
</div>
<div class="paragraph">
<p>基于这个原因， <code>minimum_master_nodes</code> （还有一些其它配置）允许通过 API 调用的方式动态进行配置。
当你的集群在线运行的时候，你可以这样修改配置：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /_cluster/settings
{
    "persistent" : {
        "discovery.zen.minimum_master_nodes" : 2
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这将成为一个永久的配置，并且无论你配置项里配置的如何，这个将优先生效。当你添加和删除 master 节点的时候，你需要更改这个配置。</p>
</div>
</div>
<div class="sect3">
<h4 id="_集群恢复方面的配置">集群恢复方面的配置</h4>
<div class="paragraph">
<p>当你集群重启时，几个配置项影响你的分片恢复的表现。首先，我们需要明白如果什么也没配置将会发生什么。</p>
</div>
<div class="paragraph">
<p>想象一下假设你有 10 个节点，每个节点只保存一个分片，这个分片是一个主分片或者是一个副本分片，或者说有一个有 5 个主分片／1 个副本分片的索引。有时你需要为整个集群做离线维护（比如，为了安装一个新的驱动程序），
当你重启你的集群，恰巧出现了 5 个节点已经启动，还有 5 个还没启动的场景。</p>
</div>
<div class="paragraph">
<p>假设其它 5 个节点出问题，或者他们根本没有收到立即重启的命令。不管什么原因，你有 5 个节点在线上，这五个节点会相互通信，选出一个 master，从而形成一个集群。
他们注意到数据不再均匀分布，因为有 5 个节点在集群中丢失了，所以他们之间会立即启动分片复制。</p>
</div>
<div class="paragraph">
<p>最后，你的其它 5 个节点打开加入了集群。这些节点会发现 <em>它们</em> 的数据正在被复制到其他节点，所以他们删除本地数据（因为这份数据要么是多余的，要么是过时的）。
然后整个集群重新进行平衡，因为集群的大小已经从 5 变成了 10。</p>
</div>
<div class="paragraph">
<p>在整个过程中，你的节点会消耗磁盘和网络带宽，来回移动数据，因为没有更好的办法。对于有 TB 数据的大集群,
这种无用的数据传输需要 <em>很长时间</em> 。如果等待所有的节点重启好了，整个集群再上线，所有的本地的数据都不需要移动。</p>
</div>
<div class="paragraph">
<p>现在我们知道问题的所在了，我们可以修改一些设置来缓解它。
首先我们要给 ELasticsearch 一个严格的限制：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">gateway.recover_after_nodes: 8</code></pre>
</div>
</div>
<div class="paragraph">
<p>这将阻止 Elasticsearch 在存在至少 8 个节点（数据节点或者 master 节点）之前进行数据恢复。
这个值的设定取决于个人喜好：整个集群提供服务之前你希望有多少个节点在线？这种情况下，我们设置为 8，这意味着至少要有 8 个节点，该集群才可用。</p>
</div>
<div class="paragraph">
<p>现在我们要告诉 Elasticsearch 集群中 <em>应该</em> 有多少个节点，以及我们愿意为这些节点等待多长时间：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">gateway.expected_nodes: 10
gateway.recover_after_time: 5m</code></pre>
</div>
</div>
<div class="paragraph">
<p>这意味着 Elasticsearch 会采取如下操作：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>等待集群至少存在 8 个节点</p>
</li>
<li>
<p>等待 5 分钟，或者10 个节点上线后，才进行数据恢复，这取决于哪个条件先达到。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>这三个设置可以在集群重启的时候避免过多的分片交换。这可能会让数据恢复从数个小时缩短为几秒钟。</p>
</div>
<div class="paragraph">
<p>注意：这些配置只能设置在 <code>config/elasticsearch.yml</code> 文件中或者是在命令行里（它们不能动态更新）它们只在整个集群重启的时候有实质性作用。</p>
</div>
</div>
<div class="sect3">
<h4 id="unicast">最好使用单播代替组播</h4>
<div class="paragraph">
<p>Elasticsearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。</p>
</div>
<div class="paragraph">
<p>虽然组播仍然 <a href="https://www.elastic.co/guide/en/elasticsearch/plugins/current/discovery-multicast.html">作为插件提供</a>，
但它应该永远不被使用在生产环境了，否则你得到的结果就是一个节点意外的加入到了你的生产环境，仅仅是因为他们收到了一个错误的组播信号。
对于组播 <em>本身</em> 并没有错，组播会导致一些愚蠢的问题，并且导致集群变的脆弱（比如，一个网络工程师正在捣鼓网络，而没有告诉你，你会发现所有的节点突然发现不了对方了）。</p>
</div>
<div class="paragraph">
<p>使用单播，你可以为 Elasticsearch 提供一些它应该去尝试连接的节点列表。
当一个节点联系到单播列表中的成员时，它就会得到整个集群所有节点的状态，然后它会联系 master 节点，并加入集群。</p>
</div>
<div class="paragraph">
<p>这意味着你的单播列表不需要包含你的集群中的所有节点，
它只是需要足够的节点，当一个新节点联系上其中一个并且说上话就可以了。如果你使用 master 候选节点作为单播列表，你只要列出三个就可以了。
这个配置在 <code>elasticsearch.yml</code> 文件中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">discovery.zen.ping.unicast.hosts: ["host1", "host2:port"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>关于 Elasticsearch 节点发现的详细信息，请参阅 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-zen.html">Zen Discovery</a> Elasticsearch 文献。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="dont-touch-these-settings">不要触碰这些配置！</h3>
<div class="paragraph">
<p>在 Elasticsearch 中有一些热点，人们可能不可避免的会碰到。 我们理解的，所有的调整就是为了优化，但是这些调整，你真的不需要理会它。因为它们经常会被乱用，从而造成系统的不稳定或者糟糕的性能，甚至两者都有可能。</p>
</div>
<div class="sect3">
<h4 id="_垃圾回收器">垃圾回收器</h4>
<div class="paragraph">
<p>这里已经简要介绍了 <a href="#garbage_collector_primer">垃圾回收入门</a>，JVM 使用一个垃圾回收器来释放不再使用的内存。 这篇内容的确是上一篇的一个延续，
但是因为重要，所以值得单独拿出来作为一节。</p>
</div>
<div class="paragraph">
<p>不要更改默认的垃圾回收器！</p>
</div>
<div class="paragraph">
<p>Elasticsearch 默认的垃圾回收器（ GC ）是 CMS。 这个垃圾回收器可以和应用并行处理，以便它可以最小化停顿。
然而，它有两个 stop-the-world 阶段，处理大内存也有点吃力。</p>
</div>
<div class="paragraph">
<p>尽管有这些缺点，它还是目前对于像 Elasticsearch 这样低延迟需求软件的最佳垃圾回收器。官方建议使用 CMS。</p>
</div>
<div class="paragraph">
<p>现在有一款新的垃圾回收器，叫 G1 垃圾回收器（ G1GC ）。 这款新的 GC 被设计，旨在比 CMS 更小的暂停时间，以及对大内存的处理能力。
它的原理是把内存分成许多区域，并且预测哪些区域最有可能需要回收内存。通过优先收集这些区域（ <em>garbage first</em> ），产生更小的暂停时间，从而能应对更大的内存。</p>
</div>
<div class="paragraph">
<p>听起来很棒！遗憾的是，G1GC 还是太新了，经常发现新的 bugs。这些错误通常是段（ segfault ）类型，便造成硬盘的崩溃。
Lucene 的测试套件对垃圾回收算法要求严格，看起来这些缺陷 G1GC 并没有很好地解决。</p>
</div>
<div class="paragraph">
<p>我们很希望在将来某一天推荐使用 G1GC，但是对于现在，它还不能足够稳定的满足 Elasticsearch 和 Lucene 的要求。</p>
</div>
</div>
<div class="sect3">
<h4 id="_线程池">线程池</h4>
<div class="paragraph">
<p>许多人 <em>喜欢</em> 调整线程池。 无论什么原因，人们都对增加线程数无法抵抗。索引太多了？增加线程！搜索太多了？增加线程！节点空闲率低于 95％？增加线程！</p>
</div>
<div class="paragraph">
<p>Elasticsearch 默认的线程设置已经是很合理的了。对于所有的线程池（除了 <code>搜索</code> ），线程个数是根据 CPU 核心数设置的。
如果你有 8 个核，你可以同时运行的只有 8 个线程，只分配 8 个线程给任何特定的线程池是有道理的。</p>
</div>
<div class="paragraph">
<p>搜索线程池设置的大一点，配置为 <code>int（（ 核心数 ＊ 3 ）／ 2 ）＋ 1</code> 。</p>
</div>
<div class="paragraph">
<p>你可能会认为某些线程可能会阻塞（如磁盘上的 I／O 操作），所以你才想加大线程的。对于 Elasticsearch 来说这并不是一个问题：因为大多数 I／O 的操作是由 Lucene 线程管理的，而不是 Elasticsearch。</p>
</div>
<div class="paragraph">
<p>此外，线程池通过传递彼此之间的工作配合。你不必再因为它正在等待磁盘写操作而担心网络线程阻塞，
因为网络线程早已把这个工作交给另外的线程池，并且网络进行了响应。</p>
</div>
<div class="paragraph">
<p>最后，你的处理器的计算能力是有限的，拥有更多的线程会导致你的处理器频繁切换线程上下文。
一个处理器同时只能运行一个线程。所以当它需要切换到其它不同的线程的时候，它会存储当前的状态（寄存器等等），然后加载另外一个线程。
如果幸运的话，这个切换发生在同一个核心，如果不幸的话，这个切换可能发生在不同的核心，这就需要在内核间总线上进行传输。</p>
</div>
<div class="paragraph">
<p>这个上下文的切换，会给 CPU 时钟周期带来管理调度的开销；在现代的 CPUs 上，开销估计高达 30 μs。也就是说线程会被堵塞超过 30 μs，如果这个时间用于线程的运行，极有可能早就结束了。</p>
</div>
<div class="paragraph">
<p>人们经常稀里糊涂的设置线程池的值。8 个核的 CPU，我们遇到过有人配了 60、100 甚至 1000 个线程。
这些设置只会让 CPU 实际工作效率更低。</p>
</div>
<div class="paragraph">
<p>所以，下次请不要调整线程池的线程数。如果你真 <em>想调整</em> ，
一定要关注你的 CPU 核心数，最多设置成核心数的两倍，再多了都是浪费。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="heap-sizing">堆内存:大小和交换</h3>
<div class="paragraph">
<p>Elasticsearch 默认安装后设置的堆内存是 1 GB。对于任何一个业务部署来说，
这个设置都太小了。如果你正在使用这些默认堆内存配置，您的集群可能会出现问题。</p>
</div>
<div class="paragraph">
<p>这里有两种方式修改 Elasticsearch 的堆内存。最简单的一个方法就是指定 <code>ES_HEAP_SIZE</code> 环境变量。服务进程在启动时候会读取这个变量，并相应的设置堆的大小。
比如，你可以用下面的命令设置它：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">export ES_HEAP_SIZE=10g</code></pre>
</div>
</div>
<div class="paragraph">
<p>此外，你也可以通过命令行参数的形式，在程序启动的时候把内存大小传递给它，如果你觉得这样更简单的话：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">./bin/elasticsearch -Xmx10g -Xms10g <b class="conum">(1)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>确保堆内存最小值（ <code>Xms</code> ）与最大值（ <code>Xmx</code> ）的大小是相同的，防止程序在运行时改变堆内存大小，
这是一个很耗系统资源的过程。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>通常来说，设置 <code>ES_HEAP_SIZE</code> 环境变量，比直接写 <code>-Xmx -Xms</code> 更好一点。</p>
</div>
<div class="sect3">
<h4 id="_把你的内存的_少于_一半给_lucene">把你的内存的（少于）一半给 Lucene</h4>
<div class="paragraph">
<p>一个常见的问题是给 Elasticsearch 分配的内存 <em>太</em> 大了。假设你有一个 64 GB 内存的机器，
天啊，我要把 64 GB 内存全都给 Elasticsearch。因为越多越好啊！</p>
</div>
<div class="paragraph">
<p>当然，内存对于 Elasticsearch 来说绝对是重要的，它可以被许多内存数据结构使用来提供更快的操作。但是说到这里，
还有另外一个内存消耗大户 <em>非堆内存</em> （off-heap）：Lucene。</p>
</div>
<div class="paragraph">
<p>Lucene 被设计为可以利用操作系统底层机制来缓存内存数据结构。
Lucene 的段是分别存储到单个文件中的。因为段是不可变的，这些文件也都不会变化，这是对缓存友好的，同时操作系统也会把这些段文件缓存起来，以便更快的访问。</p>
</div>
<div class="paragraph">
<p>Lucene 的性能取决于和操作系统的相互作用。如果你把所有的内存都分配给 Elasticsearch 的堆内存，那将不会有剩余的内存交给 Lucene。
这将严重地影响全文检索的性能。</p>
</div>
<div class="paragraph">
<p>标准的建议是把 50％ 的可用内存作为 Elasticsearch 的堆内存，保留剩下的 50％。当然它也不会被浪费，Lucene 会很乐意利用起余下的内存。</p>
</div>
<div class="paragraph">
<p>如果你不需要对分词字符串做聚合计算（例如，不需要 <a href="#aggregations-and-analysis">fielddata</a> ）可以考虑降低堆内存。堆内存越小，Elasticsearch（更快的 GC）和 Lucene（更多的内存用于缓存）的性能越好。</p>
</div>
</div>
<div class="sect3">
<h4 id="compressed_oops">不要超过 32 GB！</h4>
<div class="paragraph">
<p>这里有另外一个原因不分配大内存给 Elasticsearch。事实上，
JVM 在内存小于 32 GB 的时候会采用一个内存对象指针压缩技术。</p>
</div>
<div class="paragraph">
<p>在 Java 中，所有的对象都分配在堆上，并通过一个指针进行引用。
普通对象指针（OOP）指向这些对象，通常为 CPU <em>字长</em> 的大小：32 位或 64 位，取决于你的处理器。指针引用的就是这个 OOP 值的字节位置。</p>
</div>
<div class="paragraph">
<p>对于 32 位的系统，意味着堆内存大小最大为 4 GB。对于 64 位的系统，
可以使用更大的内存，但是 64 位的指针意味着更大的浪费，因为你的指针本身大了。更糟糕的是，
更大的指针在主内存和各级缓存（例如 LLC，L1 等）之间移动数据的时候，会占用更多的带宽。</p>
</div>
<div class="paragraph">
<p>Java 使用一个叫作  <a href="https://wikis.oracle.com/display/HotSpotInternals/CompressedOops">内存指针压缩（compressed oops）</a>的技术来解决这个问题。
它的指针不再表示对象在内存中的精确位置，而是表示 <em>偏移量</em> 。这意味着 32 位的指针可以引用 40 亿个 <em>对象</em> ，
而不是 40 亿个字节。最终，
也就是说堆内存增长到 32 GB 的物理内存，也可以用 32 位的指针表示。</p>
</div>
<div class="paragraph">
<p>一旦你越过那个神奇的 ~32 GB 的边界，指针就会切回普通对象的指针。
每个对象的指针都变长了，就会使用更多的 CPU 内存带宽，也就是说你实际上失去了更多的内存。事实上，当内存到达
40&#x2013;50 GB 的时候，有效内存才相当于使用内存对象指针压缩技术时候的 32 GB 内存。</p>
</div>
<div class="paragraph">
<p>这段描述的意思就是说：即便你有足够的内存，也尽量不要
超过 32 GB。因为它浪费了内存，降低了 CPU 的性能，还要让 GC 应对大内存。</p>
</div>
</div>
<div class="sect3">
<h4 id="_到底需要低于_32_gb多少_来设置我的_jvm">到底需要低于 32 GB多少，来设置我的 JVM？</h4>
<div class="paragraph">
<p>遗憾的是，这需要看情况。确切的划分要根据 JVMs 和操作系统而定。
如果你想保证其安全可靠，设置堆内存为 <code>31 GB</code> 是一个安全的选择。
另外，你可以在你的 JVM 设置里添加 <code>-XX:+PrintFlagsFinal</code> 用来验证 <code>JVM</code> 的临界值，
并且检查 UseCompressedOops 的值是否为 true。对于你自己使用的 JVM 和操作系统，这将找到最合适的堆内存临界值。</p>
</div>
<div class="paragraph">
<p>例如，我们在一台安装  Java 1.7 的 MacOSX 上测试，可以看到指针压缩在被禁用之前，最大堆内存大约是在 32600 mb（~31.83 gb）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ JAVA_HOME=`/usr/libexec/java_home -v 1.7` java -Xmx32600m -XX:+PrintFlagsFinal 2&gt; /dev/null | grep UseCompressedOops
     bool UseCompressedOops   := true
$ JAVA_HOME=`/usr/libexec/java_home -v 1.7` java -Xmx32766m -XX:+PrintFlagsFinal 2&gt; /dev/null | grep UseCompressedOops
     bool UseCompressedOops   = false</code></pre>
</div>
</div>
<div class="paragraph">
<p>相比之下，同一台机器安装 Java 1.8，可以看到指针压缩在被禁用之前，最大堆内存大约是在 32766 mb（~31.99 gb）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">$ JAVA_HOME=`/usr/libexec/java_home -v 1.8` java -Xmx32766m -XX:+PrintFlagsFinal 2&gt; /dev/null | grep UseCompressedOops
     bool UseCompressedOops   := true
$ JAVA_HOME=`/usr/libexec/java_home -v 1.8` java -Xmx32767m -XX:+PrintFlagsFinal 2&gt; /dev/null | grep UseCompressedOops
     bool UseCompressedOops   = false</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个例子告诉我们，影响内存指针压缩使用的临界值，
是会根据 JVM 的不同而变化的。
所以从其他地方获取的例子，需要谨慎使用，要确认检查操作系统配置和 JVM。</p>
</div>
<div class="paragraph">
<p>如果使用的是  Elasticsearch v2.2.0，启动日志其实会告诉你 JVM 是否正在使用内存指针压缩。
你会看到像这样的日志消息：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">[2015-12-16 13:53:33,417][INFO ][env] [Illyana Rasputin] heap size [989.8mb], compressed ordinary object pointers [true]</code></pre>
</div>
</div>
<div class="paragraph">
<p>这表明内存指针压缩正在被使用。如果没有，日志消息会显示 <code>[false]</code> 。</p>
</div>
<div class="sidebarblock pagebreak-before">
<div class="content">
<div class="title">我有一个 1 TB 内存的机器！</div>
<div class="paragraph">
<p>这个 32 GB 的分割线是很重要的。那如果你的机器有很大的内存怎么办呢？
一台有着 512&#x2013;768 GB内存的服务器愈发常见。</p>
</div>
<div class="paragraph">
<p>首先，我们建议避免使用这样的高配机器（参考 <a href="#hardware">硬件</a>）。</p>
</div>
<div class="paragraph">
<p>但是如果你已经有了这样的机器，你有三个可选项：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>你主要做全文检索吗？考虑给 Elasticsearch 4 - 32 GB 的内存，
让 Lucene 通过操作系统文件缓存来利用余下的内存。那些内存都会用来缓存 segments，带来极速的全文检索。</p>
</li>
<li>
<p>你需要更多的排序和聚合？而且大部分的聚合计算是在数字、日期、地理点和 <code>非分词</code> 字符串上？你很幸运，你的聚合计算将在内存友好的 doc values 上完成！
给 Elasticsearch 4 到 32 GB 的内存，其余部分为操作系统缓存内存中的 doc values。</p>
</li>
<li>
<p>你在对分词字符串做大量的排序和聚合（例如，标签或者 SigTerms，等等）不幸的是，这意味着你需要 fielddata，意味着你需要堆空间。考虑在单个机器上运行两个或多个节点，而不是拥有大量 RAM 的一个节点。仍然要坚持 50％ 原则。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>假设你有个机器有 128 GB 的内存，你可以创建两个节点，每个节点内存分配不超过 32 GB。
也就是说不超过 64 GB 内存给 ES 的堆内存，剩下的超过 64 GB 的内存给 Lucene。</p>
</div>
<div class="paragraph">
<p>如果你选择这一种，你需要配置 <code>cluster.routing.allocation.same_shard.host: true</code> 。
这会防止同一个分片（shard）的主副本存在同一个物理机上（因为如果存在一个机器上，副本的高可用性就没有了）。</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_swapping_是性能的坟墓">Swapping 是性能的坟墓</h4>
<div class="paragraph">
<p>这是显而易见的，但是还是有必要说的更清楚一点：内存交换
到磁盘对服务器性能来说是 <em>致命</em> 的。想想看：一个内存操作必须能够被快速执行。</p>
</div>
<div class="paragraph">
<p>如果内存交换到磁盘上，一个 100 微秒的操作可能变成 10 毫秒。
再想想那么多 10 微秒的操作时延累加起来。
不难看出 swapping 对于性能是多么可怕。</p>
</div>
<div class="paragraph">
<p>最好的办法就是在你的操作系统中完全禁用 swap。这样可以暂时禁用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">sudo swapoff -a</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果需要永久禁用，你可能需要修改 <code>/etc/fstab</code> 文件，这要参考你的操作系统相关文档。</p>
</div>
<div class="paragraph">
<p>如果你并不打算完全禁用 swap，也可以选择降低 <code>swappiness</code> 的值。
这个值决定操作系统交换内存的频率。
这可以预防正常情况下发生交换，但仍允许操作系统在紧急情况下发生交换。</p>
</div>
<div class="paragraph">
<p>对于大部分Linux操作系统，可以在 <code>sysctl</code> 中这样配置：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">vm.swappiness = 1 <b class="conum">(1)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>swappiness</code> 设置为 <code>1</code> 比设置为 <code>0</code> 要好，因为在一些内核版本 <code>swappiness</code> 设置为 <code>0</code> 会触发系统 OOM-killer（注：Linux 内核的 Out of Memory（OOM）killer 机制）。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>最后，如果上面的方法都不合适，你需要打开配置文件中的 <code>mlockall</code> 开关。
它的作用就是允许 JVM 锁住内存，禁止操作系统交换出去。在你的 <code>elasticsearch.yml</code> 文件中，设置如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">bootstrap.mlockall: true</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_file_descriptors_and_mmap">文件描述符和 MMap</h3>
<div class="paragraph">
<p>Lucene 使用了 <em>大量的</em> 文件。 同时，Elasticsearch 在节点和 HTTP 客户端之间进行通信也使用了大量的套接字（注：sockets）。
所有这一切都需要足够的文件描述符。</p>
</div>
<div class="paragraph">
<p>可悲的是，许多现代的 Linux 发行版本，每个进程默认允许一个微不足道的 1024 文件描述符。这对一个小的 Elasticsearch 节点来说实在是太 <em>低</em> 了，更不用说一个处理数以百计索引的节点。</p>
</div>
<div class="paragraph">
<p>你应该增加你的文件描述符，设置一个很大的值，如 64,000。这个过程困难得让人恼火，它高度依赖于你的特定操作系统和分布。请参考你操作系统文档来确定如何最好地修改允许的文件描述符数量。</p>
</div>
<div class="paragraph">
<p>一旦你认为已经改变了它，检查 Elasticsearch，以确保它的真的起作用并且有足够的文件描述符：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_nodes/process

{
   "cluster_name": "elasticsearch__zach",
   "nodes": {
      "TGn9iO2_QQKb0kavcLbnDw": {
         "name": "Zach",
         "transport_address": "inet[/192.168.1.131:9300]",
         "host": "zacharys-air",
         "ip": "192.168.1.131",
         "version": "2.0.0-SNAPSHOT",
         "build": "612f461",
         "http_address": "inet[/192.168.1.131:9200]",
         "process": {
            "refresh_interval_in_millis": 1000,
            "id": 19808,
            "max_file_descriptors": 64000, <b class="conum">(1)</b>
            "mlockall": true
         }
      }
   }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>max_file_descriptors</code> 字段显示 Elasticsearch 进程可以访问的可用文件描述符数量。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Elasticsearch 对各种文件混合使用了 NioFs（ 注：非阻塞文件系统）和 MMapFs （ 注：内存映射文件系统）。请确保你配置的最大映射数量，以便有足够的虚拟内存可用于 mmapped 文件。这可以暂时设置：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">sysctl -w vm.max_map_count=262144</code></pre>
</div>
</div>
<div class="paragraph">
<p>或者你可以在 <code>/etc/sysctl.conf</code> 通过修改 <code>vm.max_map_count</code> 永久设置它。</p>
</div>
</div>
<div class="sect2">
<h3 id="_revisit_this_list_before_production">在生产之前，重温这个列表</h3>
<div class="paragraph">
<p>在你进入生产之前，你可能阅读了本节。本章中涉及的细节非常好，一般是可以知道的，但关键是，正确部署到生产环境之前需要重温这个列表。</p>
</div>
<div class="paragraph">
<p>一些问题会简单地阻止你(如：可用的文件描述符太少)。因为他们很快显现出来，这些都是容易调试的。
其他的一些问题，如脑裂和内存设置，只有在糟糕的事情发生之后才可见。在这一点上，解决办法往往是凌乱和繁琐的。</p>
</div>
<div class="paragraph">
<p>在灾难发生 <em>之前</em> ，通过适当配置集群来主动阻止这些情况发生，是更好的选择。所以如果你想要从整本书的一个部分折角（或保存书签），本章将是一个很好的选择。在部署到生产环境的前一周，简单地浏览这里给出的列表，并检查所有的建议。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="post_deploy">部署后</h2>
<div class="sectionbody">
<div class="paragraph">
<p>一旦将集群部署到生产环境后，就需要有一些工具及最佳实践经验来保证集群运行在最佳状态。本章将探讨动态配置、日志调优、索引性能优化以及集群备份。</p>
</div>
<div class="sect2">
<h3 id="_changing_settings_dynamically">动态变更设置</h3>
<div class="paragraph">
<p>Elasticsearch 里很多设置都是动态的，可以通过 API 修改。需要强制重启节点（或者集群）的配置修改都要极力避免。而且虽然通过静态配置项也可以完成这些变更，我们建议你还是用 API 来实现。</p>
</div>
<div class="paragraph">
<p><code>集群更新</code> API 有两种工作模式：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">临时（Transient）</dt>
<dd>
<p>这些变更在集群重启之前一直会生效。一旦整个集群重启，这些配置就被清除。</p>
</dd>
<dt class="hdlist1">永久（Persistent）</dt>
<dd>
<p>这些变更会永久存在直到被显式修改。即使全集群重启它们也会存活下来并覆盖掉静态配置文件里的选项。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>临时或永久配置需要在 JSON 体里分别指定：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /_cluster/settings
{
    "persistent" : {
        "discovery.zen.minimum_master_nodes" : 2 <b class="conum">(1)</b>
    },
    "transient" : {
        "indices.store.throttle.max_bytes_per_sec" : "50mb" <b class="conum">(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>这个永久设置会在全集群重启时存活下来。</p>
</li>
<li>
<p>这个临时设置会在第一次全集群重启后被移除。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>可以动态更新的设置的完整清单，请阅读 {ref}/cluster-update-settings.html[online reference docs]。</p>
</div>
</div>
<div class="sect2">
<h3 id="logging">日志记录</h3>
<div class="paragraph">
<p>Elasticsearch 会输出很多日志，都放在 <code>ES_HOME/logs</code> 目录下。默认的日志记录等级是 <code>INFO</code> 。它提供了适度的信息，但是又设计好了不至于让你的日志太过庞大。</p>
</div>
<div class="paragraph">
<p>当调试问题的时候，特别是节点发现相关的问题（因为这个经常依赖于各式过于繁琐的网络配置），提高日志记录等级到 <code>DEBUG</code> 是很有帮助的。</p>
</div>
<div class="paragraph">
<p>你 <em>可以</em> 修改 <code>logging.yml</code> 文件然后重启你的节点——但是这样做即繁琐还会导致不必要的宕机时间。作为替代，你可以通过 <code>cluster-settings</code> API 更新日志记录级别，就像我们前面刚学过的那样。</p>
</div>
<div class="paragraph">
<p>要实现这个更新，选择你感兴趣的日志器，然后在前面补上 <code>logger.</code> 。对根日志器你可以用 <code>logger._root</code> 来表示。</p>
</div>
<div class="paragraph">
<p>让我们调高节点发现的日志记录级别：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /_cluster/settings
{
    "transient" : {
        "logger.discovery" : "DEBUG"
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>设置生效，Elasticsearch 将开始输出 <code>discovery</code> 模块的 <code>DEBUG</code> 级别的日志。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
避免使用 <code>TRACE</code> 。这个级别非常的详细，详细到日志反而不再有用了。
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="slowlog">慢日志</h4>
<div class="paragraph">
<p>还有另一个日志叫 <em>慢日志</em> 。这个日志的目的是捕获那些超过指定时间阈值的查询和索引请求。这个日志用来追踪由用户产生的很慢的请求很有用。</p>
</div>
<div class="paragraph">
<p>默认情况，慢日志是不开启的。要开启它，需要定义具体动作（query，fetch 还是 index），你期望的事件记录等级（ <code>WARN</code> 、 <code>DEBUG</code> 等），以及时间阈值。</p>
</div>
<div class="paragraph">
<p>这是一个索引级别的设置，也就是说可以独立应用给单个索引：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index/_settings
{
    "index.search.slowlog.threshold.query.warn" : "10s", <b class="conum">(1)</b>
    "index.search.slowlog.threshold.fetch.debug": "500ms", <b class="conum">(2)</b>
    "index.indexing.slowlog.threshold.index.info": "5s" <b class="conum">(3)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>查询慢于 10 秒输出一个 <code>WARN</code> 日志。</p>
</li>
<li>
<p>获取慢于 500 毫秒输出一个 <code>DEBUG</code> 日志。</p>
</li>
<li>
<p>索引慢于 5 秒输出一个 <code>INFO</code> 日志。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>你也可以在 <code>elasticsearch.yml</code> 文件里定义这些阈值。没有阈值设置的索引会自动继承在静态配置文件里配置的参数。</p>
</div>
<div class="paragraph">
<p>一旦阈值设置过了，你可以和其他日志器一样切换日志记录等级：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /_cluster/settings
{
    "transient" : {
        "logger.index.search.slowlog" : "DEBUG", <b class="conum">(1)</b>
        "logger.index.indexing.slowlog" : "WARN" <b class="conum">(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>设置搜索慢日志为 <code>DEBUG</code> 级别。</p>
</li>
<li>
<p>设置索引慢日志为 <code>WARN</code> 级别。</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="indexing-performance">索引性能技巧</h3>
<div class="paragraph">
<p>如果你是在一个索引负载很重的环境，比如索引的是基础设施日志，你可能愿意牺牲一些搜索性能换取更快的索引速率。在这些场景里，搜索常常是很少见的操作，而且一般是由你公司内部的人发起的。他们也愿意为一个搜索等上几秒钟，而不像普通消费者，要求一个搜索必须毫秒级返回。</p>
</div>
<div class="paragraph">
<p>基于这种特殊的场景，我们可以有几种权衡办法来提高你的索引性能。</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">这些技巧仅适用于 Elasticsearch 1.3 及以后的版本</div>
<div class="paragraph">
<p>本书是为最新几个版本的 Elasticsearch 写的，虽然大多数内容在更老的版本也也有效。</p>
</div>
<div class="paragraph">
<p>不过，本节提及的技巧， <em>只</em> 针对 1.3 及以后版本。该版本后有不少性能提升和故障修复是直接影响到索引的。事实上，有些建议在老版本上反而会因为故障或性能缺陷而 <em>降低</em> 性能。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_科学的测试性能">科学的测试性能</h4>
<div class="paragraph">
<p>性能测试永远是复杂的，所以在你的方法里已经要尽可能的科学。随机摆弄旋钮以及写入开关可不是做性能调优的好办法。如果有太多种 <em>可能</em> ，我们就无法判断到底哪一种有最好的 <em>效果</em> 。合理的测试方法如下：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>在单个节点上，对单个分片，无副本的场景测试性能。</p>
</li>
<li>
<p>在 100% 默认配置的情况下记录性能结果，这样你就有了一个对比基线。</p>
</li>
<li>
<p>确保性能测试运行足够长的时间（30 分钟以上）这样你可以评估长期性能，而不是短期的峰值或延迟。一些事件（比如段合并，GC）不会立刻发生，所以性能概况会随着时间继续而改变的。</p>
</li>
<li>
<p>开始在基线上逐一修改默认值。严格测试它们，如果性能提升可以接受，保留这个配置项，开始下一项。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_使用批量请求并调整其大小">使用批量请求并调整其大小</h4>
<div class="paragraph">
<p>显而易见的，优化性能应该使用批量请求。批量的大小则取决于你的数据、分析和集群配置，不过每次批量数据 5&#x2013;15 MB 大是个不错的起始点。注意这里说的是物理字节数大小。文档计数对批量大小来说不是一个好指标。比如说，如果你每次批量索引 1000 个文档，记住下面的事实：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>1000 个 1 KB 大小的文档加起来是 1 MB 大。</p>
</li>
<li>
<p>1000 个 100 KB 大小的文档加起来是 100 MB 大。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>这可是完完全全不一样的批量大小了。批量请求需要在协调节点上加载进内存，所以批量请求的物理大小比文档计数重要得多。</p>
</div>
<div class="paragraph">
<p>从 5&#x2013;15 MB 开始测试批量请求大小，缓慢增加这个数字，直到你看不到性能提升为止。然后开始增加你的批量写入的并发度（多线程等等办法）。</p>
</div>
<div class="paragraph">
<p>用 Marvel 以及诸如 <code>iostat</code> 、 <code>top</code> 和 <code>ps</code> 等工具监控你的节点，观察资源什么时候达到瓶颈。如果你开始收到 <code>EsRejectedExecutionException</code> ，你的集群没办法再继续了：至少有一种资源到瓶颈了。或者减少并发数，或者提供更多的受限资源（比如从机械磁盘换成 SSD），或者添加更多节点。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>写数据的时候，要确保批量请求是轮询发往你的全部数据节点的。不要把所有请求都发给单个节点，因为这个节点会需要在处理的时候把所有批量请求都存在内存里。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_存储">存储</h4>
<div class="paragraph">
<p>磁盘在现代服务器上通常都是瓶颈。Elasticsearch 重度使用磁盘，你的磁盘能处理的吞吐量越大，你的节点就越稳定。这里有一些优化磁盘 I/O 的技巧：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>使用 SSD。就像其他地方提过的，他们比机械磁盘优秀多了。</p>
</li>
<li>
<p>使用 RAID 0。条带化 RAID 会提高磁盘 I/O，代价显然就是当一块硬盘故障时整个就故障了。不要使用镜像或者奇偶校验 RAID 因为副本已经提供了这个功能。</p>
</li>
<li>
<p>另外，使用多块硬盘，并允许 Elasticsearch 通过多个 <code>path.data</code> 目录配置把数据条带化分配到它们上面。</p>
</li>
<li>
<p>不要使用远程挂载的存储，比如 NFS 或者 SMB/CIFS。这个引入的延迟对性能来说完全是背道而驰的。</p>
</li>
<li>
<p>如果你用的是 EC2，当心 EBS。即便是基于 SSD 的 EBS，通常也比本地实例的存储要慢。</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="segments-and-merging">段和合并</h4>
<div class="paragraph">
<p>段合并的计算量庞大，而且还要吃掉大量磁盘 I/O。合并在后台定期操作，因为他们可能要很长时间才能完成，尤其是比较大的段。这个通常来说都没问题，因为大规模段合并的概率是很小的。</p>
</div>
<div class="paragraph">
<p>不过有时候合并会拖累写入速率。如果这个真的发生了，Elasticsearch 会自动限制索引请求到单个线程里。这个可以防止出现 <em>段爆炸</em> 问题，即数以百计的段在被合并之前就生成出来。如果 Elasticsearch 发现合并拖累索引了，它会会记录一个声明有 <code>now throttling indexing</code> 的 <code>INFO</code> 级别信息。</p>
</div>
<div class="paragraph">
<p>Elasticsearch 默认设置在这块比较保守：不希望搜索性能被后台合并影响。不过有时候（尤其是 SSD，或者日志场景）限流阈值太低了。</p>
</div>
<div class="paragraph">
<p>默认值是 20 MB/s，对机械磁盘应该是个不错的设置。如果你用的是 SSD，可以考虑提高到 100&#x2013;200 MB/s。测试验证对你的系统哪个值合适：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /_cluster/settings
{
    "persistent" : {
        "indices.store.throttle.max_bytes_per_sec" : "100mb"
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果你在做批量导入，完全不在意搜索，你可以彻底关掉合并限流。这样让你的索引速度跑到你磁盘允许的极限：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /_cluster/settings
{
    "transient" : {
        "indices.store.throttle.type" : "none" <b class="conum">(1)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>设置限流类型为 <code>none</code> 彻底关闭合并限流。等你完成了导入，记得改回 <code>merge</code> 重新打开限流。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>如果你使用的是机械磁盘而非 SSD，你需要添加下面这个配置到你的 <code>elasticsearch.yml</code> 里：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-yaml" data-lang="yaml">index.merge.scheduler.max_thread_count: 1</code></pre>
</div>
</div>
<div class="paragraph">
<p>机械磁盘在并发 I/O 支持方面比较差，所以我们需要降低每个索引并发访问磁盘的线程数。这个设置允许 <code>max_thread_count + 2</code> 个线程同时进行磁盘操作，也就是设置为 <code>1</code> 允许三个线程。</p>
</div>
<div class="paragraph">
<p>对于 SSD，你可以忽略这个设置，默认是 <code>Math.min(3, Runtime.getRuntime().availableProcessors() / 2)</code> ，对 SSD 来说运行的很好。</p>
</div>
<div class="paragraph">
<p>最后，你可以增加 <code>index.translog.flush_threshold_size</code> 设置，从默认的 512 MB 到更大一些的值，比如 1 GB。这可以在一次清空触发的时候在事务日志里积累出更大的段。而通过构建更大的段，清空的频率变低，大段合并的频率也变低。这一切合起来导致更少的磁盘 I/O 开销和更好的索引速率。当然，你会需要对应量级的 heap 内存用以积累更大的缓冲空间，调整这个设置的时候请记住这点。</p>
</div>
</div>
<div class="sect3">
<h4 id="_其他">其他</h4>
<div class="paragraph">
<p>最后，还有一些其他值得考虑的东西需要记住：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>如果你的搜索结果不需要近实时的准确度，考虑把每个索引的 <code>index.refresh_interval</code>改到 <code>30s</code> 。如果你是在做大批量导入，导入期间你可以通过设置这个值为 <code>-1</code> 关掉刷新。别忘记在完工的时候重新开启它。</p>
</li>
<li>
<p>如果你在做大批量导入，考虑通过设置 <code>index.number_of_replicas: 0</code>关闭副本。文档在复制的时候，整个文档内容都被发往副本节点，然后逐字的把索引过程重复一遍。这意味着每个副本也会执行分析、索引以及可能的合并过程。</p>
<div class="paragraph">
<p>相反，如果你的索引是零副本，然后在写入完成后再开启副本，恢复过程本质上只是一个字节到字节的网络传输。相比重复索引过程，这个算是相当高效的了。</p>
</div>
</li>
<li>
<p>如果你没有给每个文档自带 ID，使用 Elasticsearch 的自动 ID 功能。这个为避免版本查找做了优化，因为自动生成的 ID 是唯一的。</p>
</li>
<li>
<p>如果你在使用自己的 ID，尝试使用一种 <a href="http://blog.mikemccandless.com/2014/05/choosing-fast-unique-identifier-uuid.html">Lucene 友好的</a> ID。包括零填充序列 ID、UUID-1 和纳秒；这些 ID 都是有一致的，压缩良好的序列模式。相反的，像 UUID-4 这样的 ID，本质上是随机的，压缩比很低，会明显拖慢 Lucene。</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_delaying_shard_allocation">推迟分片分配</h3>
<div class="paragraph">
<p>正如我们在 <a href="#_scale_horizontally">[_scale_horizontally]</a> 讨论过， Elasticsearch 将自动在可用节点间进行分片均衡，包括新节点的加入和现有节点的离线。</p>
</div>
<div class="paragraph">
<p>理论上来说，这个是理想的行为，我们想要提拔副本分片来尽快恢复丢失的主分片。
我们同时也希望保证资源在整个集群的均衡，用以避免热点。</p>
</div>
<div class="paragraph">
<p>然而，在实践中，立即的再均衡所造成的问题会比其解决的更多。举例来说，考虑到以下情形：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Node（节点） 19 在网络中失联了（某个家伙踢到了电源线)</p>
</li>
<li>
<p>Master 立即注意到了这个节点的离线，它决定在集群内提拔其他拥有 Node 19 上面的主分片对应的副本分片为主分片</p>
</li>
<li>
<p>在副本被提拔为主分片以后，master 节点开始执行恢复操作来重建缺失的副本。集群中的节点之间互相拷贝分片数据，网卡压力剧增，集群状态尝试变绿。</p>
</li>
<li>
<p>由于目前集群处于非平衡状态，这个过程还有可能会触发小规模的分片移动。其他不相关的分片将在节点间迁移来达到一个最佳的平衡状态</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>与此同时，那个踢到电源线的倒霉管理员，把服务器插好电源线进行了重启，现在节点 Node 19 又重新加入到了集群。不幸的是，这个节点被告知当前的数据已经没有用了，
数据已经在其他节点上重新分配了。所以 Node 19 把本地的数据进行删除，然后重新开始恢复集群的其他分片（然后这又导致了一个新的再平衡）</p>
</div>
<div class="paragraph">
<p>如果这一切听起来是不必要的且开销极大，那就对了。是的，不过前提是你知道这个节点会很快回来。如果节点 Node 19 真的丢了，上面的流程确实正是我们想要发生的。</p>
</div>
<div class="paragraph">
<p>为了解决这种瞬时中断的问题，Elasticsearch 可以推迟分片的分配。这可以让你的集群在重新分配之前有时间去检测这个节点是否会再次重新加入。</p>
</div>
<div class="sect3">
<h4 id="_修改默认延时">修改默认延时</h4>
<div class="paragraph">
<p>默认情况，集群会等待一分钟来查看节点是否会重新加入，如果这个节点在此期间重新加入，重新加入的节点会保持其现有的分片数据，不会触发新的分片分配。</p>
</div>
<div class="paragraph">
<p>通过修改参数 <code>delayed_timeout</code> ，默认等待时间可以全局设置也可以在索引级别进行修改:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /_all/_settings <b class="conum">(1)</b>
{
  "settings": {
    "index.unassigned.node_left.delayed_timeout": "5m" <b class="conum">(2)</b>
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>通过使用 <code>_all</code> 索引名，我们可以为集群里面的所有的索引使用这个参数</p>
</li>
<li>
<p>默认时间被修改成了 5 分钟</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这个配置是动态的，可以在运行时进行修改。如果你希望分片立即分配而不想等待，你可以设置参数： <code>delayed_timeout: 0</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
延迟分配不会阻止副本被提拔为主分片。集群还是会进行必要的提拔来让集群回到 <code>yellow</code> 状态。缺失副本的重建是唯一被延迟的过程。
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_自动取消分片迁移">自动取消分片迁移</h4>
<div class="paragraph">
<p>如果节点在超时之后再回来，且集群还没有完成分片的移动，会发生什么事情呢？在这种情形下，
Elasticsearch 会检查该机器磁盘上的分片数据和当前集群中的活跃主分片的数据是不是一样&#8201;&#8212;&#8201;如果两者匹配，
说明没有进来新的文档，包括删除和修改&#8201;&#8212;&#8201;那么 master 将会取消正在进行的再平衡并恢复该机器磁盘上的数据。</p>
</div>
<div class="paragraph">
<p>之所以这样做是因为本地磁盘的恢复永远要比网络间传输要快，并且我们保证了他们的分片数据是一样的，这个过程可以说是双赢。</p>
</div>
<div class="paragraph">
<p>如果分片已经产生了分歧（比如：节点离线之后又索引了新的文档），那么恢复进程会继续按照正常流程进行。重新加入的节点会删除本地的、过时的数据，然后重新获取一份新的。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_rolling_restarts">滚动重启</h3>
<div class="paragraph">
<p>总有一天你会需要做一次集群的滚动重启——保持集群在线和可操作，但是逐一把节点下线。</p>
</div>
<div class="paragraph">
<p>常见的原因：Elasticsearch 版本升级，或者服务器自身的一些维护操作（比如操作系统升级或者硬件相关）。不管哪种情况，都要有一种特别的方法来完成一次滚动重启。</p>
</div>
<div class="paragraph">
<p>正常情况下，Elasticsearch 希望你的数据被完全的复制和均衡的分布。如果你手动关闭了一个节点，集群会立刻发现节点的丢失并开始再平衡。如果节点的维护是短期工作的话，这一点就很烦人了，因为大型分片的再平衡需要花费相当的时间（想想尝试复制 1TB 的数据——即便在高速网络上也是不一般的事情了）。</p>
</div>
<div class="paragraph">
<p>我们需要的是，告诉 Elasticsearch 推迟再平衡，因为对外部因子影响下的集群状态，我们自己更了解。操作流程如下：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>可能的话，停止索引新的数据。虽然不是每次都能真的做到，但是这一步可以帮助提高恢复速度。</p>
</li>
<li>
<p>禁止分片分配。这一步阻止 Elasticsearch 再平衡缺失的分片，直到你告诉它可以进行了。如果你知道维护窗口会很短，这个主意棒极了。你可以像下面这样禁止分配：</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /_cluster/settings
{
    "transient" : {
        "cluster.routing.allocation.enable" : "none"
    }
}</code></pre>
</div>
</div>
</li>
<li>
<p>关闭单个节点。</p>
</li>
<li>
<p>执行维护/升级。</p>
</li>
<li>
<p>重启节点，然后确认它加入到集群了。</p>
</li>
<li>
<p>用如下命令重启分片分配：</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /_cluster/settings
{
    "transient" : {
        "cluster.routing.allocation.enable" : "all"
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>分片再平衡会花一些时间。一直等到集群变成 <code>绿色</code> 状态后再继续。</p>
</div>
</li>
<li>
<p>重复第 2 到 6 步操作剩余节点。</p>
</li>
<li>
<p>到这步你可以安全的恢复索引了（如果你之前停止了的话），不过等待集群完全均衡后再恢复索引，也会有助于提高处理速度。</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="backing-up-your-cluster">备份你的集群</h3>
<div class="paragraph">
<p>使用无论哪个存储数据的软件，定期备份你的数据都是很重要的。Elasticsearch 副本提供了高可靠性；它们让你可以容忍零星的节点丢失而不会中断服务。</p>
</div>
<div class="paragraph">
<p>但是，副本并不提供对灾难性故障的保护。对这种情况，你需要的是对集群真正的备份——在某些东西确实出问题的时候有一个完整的拷贝。</p>
</div>
<div class="paragraph">
<p>要备份你的集群，你可以使用 <code>snapshot</code> API。这个会拿到你集群里当前的状态和数据然后保存到一个共享仓库里。这个备份过程是"智能"的。你的第一个快照会是一个数据的完整拷贝，但是所有后续的快照会保留的是已存快照和新数据之间的差异。随着你不时的对数据进行快照，备份也在增量的添加和删除。这意味着后续备份会相当快速，因为它们只传输很小的数据量。</p>
</div>
<div class="paragraph">
<p>要使用这个功能，你必须首先创建一个保存数据的仓库。有多个仓库类型可以供你选择：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>共享文件系统，比如 NAS</p>
</li>
<li>
<p>Amazon S3</p>
</li>
<li>
<p>HDFS (Hadoop 分布式文件系统)</p>
</li>
<li>
<p>Azure Cloud</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_创建仓库">创建仓库</h4>
<div class="paragraph">
<p>让我部署一个共享文件系统仓库：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT _snapshot/my_backup <b class="conum">(1)</b>
{
    "type": "fs", <b class="conum">(2)</b>
    "settings": {
        "location": "/mount/backups/my_backup" <b class="conum">(3)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>给我们的仓库取一个名字，在本例它叫 <code>my_backup</code> 。</p>
</li>
<li>
<p>我们指定仓库的类型应该是一个共享文件系统。</p>
</li>
<li>
<p>最后，我们提供一个已挂载的设备作为目的地址。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>注意：共享文件系统路径必须确保集群所有节点都可以访问到。</p>
</div>
<div class="paragraph">
<p>这步会在挂载点创建仓库和所需的元数据。还有一些其他的配置你可能想要配置的，这些取决于你的节点、网络的性能状况和仓库位置：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>max_snapshot_bytes_per_sec</code></dt>
<dd>
<p>当快照数据进入仓库时，这个参数控制这个过程的限流情况。默认是每秒 <code>20mb</code> 。</p>
</dd>
<dt class="hdlist1"><code>max_restore_bytes_per_sec</code></dt>
<dd>
<p>当从仓库恢复数据时，这个参数控制什么时候恢复过程会被限流以保障你的网络不会被占满。默认是每秒 <code>20mb</code>。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>假设我们有一个非常快的网络，而且对额外的流量也很 OK，那我们可以增加这些默认值：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">POST _snapshot/my_backup/ <b class="conum">(1)</b>
{
    "type": "fs",
    "settings": {
        "location": "/mount/backups/my_backup",
        "max_snapshot_bytes_per_sec" : "50mb", <b class="conum">(2)</b>
        "max_restore_bytes_per_sec" : "50mb"
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>注意我们用的是 <code>POST</code> 而不是 <code>PUT</code> 。这会更新已有仓库的设置。</p>
</li>
<li>
<p>然后添加我们的新设置。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_快照所有打开的索引">快照所有打开的索引</h4>
<div class="paragraph">
<p>一个仓库可以包含多个快照。每个快照跟一系列索引相关（比如所有索引，一部分索引，或者单个索引）。当创建快照的时候，你指定你感兴趣的索引然后给快照取一个唯一的名字。</p>
</div>
<div class="paragraph">
<p>让我们从最基础的快照命令开始：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT _snapshot/my_backup/snapshot_1</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个会备份所有打开的索引到 <code>my_backup</code> 仓库下一个命名为 <code>snapshot_1</code> 的快照里。这个调用会立刻返回，然后快照会在后台运行。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>通常你会希望你的快照作为后台进程运行，不过有时候你会希望在你的脚本中一直等待到完成。这可以通过添加一个 <code>wait_for_completion</code> 标记实现：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT _snapshot/my_backup/snapshot_1?wait_for_completion=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个会阻塞调用直到快照完成。注意大型快照会花很长时间才返回。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_快照指定索引">快照指定索引</h4>
<div class="paragraph">
<p>默认行为是备份所有打开的索引。不过如果你在用 Marvel，你不是真的想要把所有诊断相关的 <code>.marvel</code> 索引也备份起来。可能你就压根没那么大空间备份所有数据。</p>
</div>
<div class="paragraph">
<p>这种情况下，你可以在快照你的集群的时候指定备份哪些索引：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT _snapshot/my_backup/snapshot_2
{
    "indices": "index_1,index_2"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个快照命令现在只会备份 <code>index1</code> 和 <code>index2</code> 了。</p>
</div>
</div>
<div class="sect3">
<h4 id="_列出快照相关的信息">列出快照相关的信息</h4>
<div class="paragraph">
<p>一旦你开始在你的仓库里积攒起快照了，你可能就慢慢忘记里面各自的细节了——特别是快照按照时间划分命名的时候（比如， <code>backup_2014_10_28</code> ）。</p>
</div>
<div class="paragraph">
<p>要获得单个快照的信息，直接对仓库和快照名发起一个 <code>GET</code> 请求：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET _snapshot/my_backup/snapshot_2</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个会返回一个小响应，包括快照相关的各种信息：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "snapshots": [
      {
         "snapshot": "snapshot_1",
         "indices": [
            ".marvel_2014_28_10",
            "index1",
            "index2"
         ],
         "state": "SUCCESS",
         "start_time": "2014-09-02T13:01:43.115Z",
         "start_time_in_millis": 1409662903115,
         "end_time": "2014-09-02T13:01:43.439Z",
         "end_time_in_millis": 1409662903439,
         "duration_in_millis": 324,
         "failures": [],
         "shards": {
            "total": 10,
            "failed": 0,
            "successful": 10
         }
      }
   ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>要获取一个仓库中所有快照的完整列表，使用 <code>_all</code> 占位符替换掉具体的快照名称：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET _snapshot/my_backup/_all</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_删除快照">删除快照</h4>
<div class="paragraph">
<p>最后，我们需要一个命令来删除所有不再有用的旧快照。这只要对仓库/快照名称发一个简单的 <code>DELETE</code> HTTP 调用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">DELETE _snapshot/my_backup/snapshot_2</code></pre>
</div>
</div>
<div class="paragraph">
<p>用 API 删除快照很重要，而不能用其他机制（比如手动删除，或者用 S3 上的自动清除工具）。因为快照是增量的，有可能很多快照依赖于过去的段。<code>delete</code> API 知道哪些数据还在被更多近期快照使用，然后会只删除不再被使用的段。</p>
</div>
<div class="paragraph">
<p>但是，如果你做了一次人工文件删除，你将会面临备份严重损坏的风险，因为你在删除的是可能还在使用中的数据。</p>
</div>
</div>
<div class="sect3">
<h4 id="_监控快照进度">监控快照进度</h4>
<div class="paragraph">
<p><code>wait_for_completion</code> 标记提供了一个监控的基础形式，但哪怕只是对一个中等规模的集群做快照恢复的时候，它都真的不够用。</p>
</div>
<div class="paragraph">
<p>另外两个 API 会给你有关快照状态更详细的信息。首先你可以给快照 ID 执行一个 <code>GET</code>，就像我们之前获取一个特定快照的信息时做的那样：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET _snapshot/my_backup/snapshot_3</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果你调用这个命令的时候快照还在进行中，你会看到它什么时候开始，运行了多久等等信息。不过要注意，这个 API 用的是快照机制相同的线程池。如果你在快照非常大的分片，状态更新的间隔会很大，因为 API 在竞争相同的线程池资源。</p>
</div>
<div class="paragraph">
<p>更好的方案是拽取 <code>_status</code> API 数据：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET _snapshot/my_backup/snapshot_3/_status</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>_status</code> API 立刻返回，然后给出详细的多的统计值输出：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "snapshots": [
      {
         "snapshot": "snapshot_3",
         "repository": "my_backup",
         "state": "IN_PROGRESS", <b class="conum">(1)</b>
         "shards_stats": {
            "initializing": 0,
            "started": 1, <b class="conum">(2)</b>
            "finalizing": 0,
            "done": 4,
            "failed": 0,
            "total": 5
         },
         "stats": {
            "number_of_files": 5,
            "processed_files": 5,
            "total_size_in_bytes": 1792,
            "processed_size_in_bytes": 1792,
            "start_time_in_millis": 1409663054859,
            "time_in_millis": 64
         },
         "indices": {
            "index_3": {
               "shards_stats": {
                  "initializing": 0,
                  "started": 0,
                  "finalizing": 0,
                  "done": 5,
                  "failed": 0,
                  "total": 5
               },
               "stats": {
                  "number_of_files": 5,
                  "processed_files": 5,
                  "total_size_in_bytes": 1792,
                  "processed_size_in_bytes": 1792,
                  "start_time_in_millis": 1409663054859,
                  "time_in_millis": 64
               },
               "shards": {
                  "0": {
                     "stage": "DONE",
                     "stats": {
                        "number_of_files": 1,
                        "processed_files": 1,
                        "total_size_in_bytes": 514,
                        "processed_size_in_bytes": 514,
                        "start_time_in_millis": 1409663054862,
                        "time_in_millis": 22
                     }
                  },
                  ...</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>一个正在运行的快照会显示 <code>IN_PROGRESS</code> 作为状态。</p>
</li>
<li>
<p>这个特定快照有一个分片还在传输（另外四个已经完成）。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>响应包括快照的总体状况，但也包括下钻到每个索引和每个分片的统计值。这个给你展示了有关快照进展的非常详细的视图。分片可以在不同的完成状态：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>INITIALIZING</code></dt>
<dd>
<p>分片在检查集群状态看看自己是否可以被快照。这个一般是非常快的。</p>
</dd>
<dt class="hdlist1"><code>STARTED</code></dt>
<dd>
<p>数据正在被传输到仓库。</p>
</dd>
<dt class="hdlist1"><code>FINALIZING</code></dt>
<dd>
<p>数据传输完成；分片现在在发送快照元数据。</p>
</dd>
<dt class="hdlist1"><code>DONE</code></dt>
<dd>
<p>快照完成！</p>
</dd>
<dt class="hdlist1"><code>FAILED</code></dt>
<dd>
<p>快照处理的时候碰到了错误，这个分片/索引/快照不可能完成了。检查你的日志获取更多信息。</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_取消一个快照">取消一个快照</h4>
<div class="paragraph">
<p>最后，你可能想取消一个快照或恢复。因为它们是长期运行的进程，执行操作的时候一个笔误或者过错就会花很长时间来解决——而且同时还会耗尽有价值的资源。</p>
</div>
<div class="paragraph">
<p>要取消一个快照，在他进行中的时候简单的删除快照就可以：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">DELETE _snapshot/my_backup/snapshot_3</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个会中断快照进程。然后删除仓库里进行到一半的快照。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_restoring_from_a_snapshot">从快照恢复</h3>
<div class="paragraph">
<p>一旦你备份过了数据，恢复它就简单了：只要在你希望恢复回集群的快照 ID后面加上 <code>_restore</code> 即可：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">POST _snapshot/my_backup/snapshot_1/_restore</code></pre>
</div>
</div>
<div class="paragraph">
<p>默认行为是把这个快照里存有的所有索引都恢复。如果 <code>snapshot_1</code> 包括五个索引，这五个都会被恢复到我们集群里。和 <code>snapshot</code> API 一样，我们也可以选择希望恢复具体哪个索引。</p>
</div>
<div class="paragraph">
<p>还有附加的选项用来重命名索引。这个选项允许你通过模式匹配索引名称，然后通过恢复进程提供一个新名称。如果你想在不替换现有数据的前提下，恢复老数据来验证内容，或者做其他处理，这个选项很有用。让我们从快照里恢复单个索引并提供一个替换的名称：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">POST /_snapshot/my_backup/snapshot_1/_restore
{
    "indices": "index_1", <b class="conum">(1)</b>
    "rename_pattern": "index_(.+)", <b class="conum">(2)</b>
    "rename_replacement": "restored_index_$1" <b class="conum">(3)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>只恢复 <code>index_1</code> 索引，忽略快照中存在的其余索引。</p>
</li>
<li>
<p>查找所提供的模式能匹配上的正在恢复的索引。</p>
</li>
<li>
<p>然后把它们重命名成替代的模式。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这个会恢复 <code>index_1</code> 到你及群里，但是重命名成了 <code>restored_index_1</code> 。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>和快照类似， <code>restore</code> 命令也会立刻返回，恢复进程会在后台进行。如果你更希望你的 HTTP 调用阻塞直到恢复完成，添加 <code>wait_for_completion</code> 标记：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">POST _snapshot/my_backup/snapshot_1/_restore?wait_for_completion=true</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_监控恢复操作">监控恢复操作</h4>
<div class="paragraph">
<p>从仓库恢复数据借鉴了 Elasticsearch 里已有的现行恢复机制。在内部实现上，从仓库恢复分片和从另一个节点恢复是等价的。</p>
</div>
<div class="paragraph">
<p>如果你想监控恢复的进度，你可以使用 <code>recovery</code> API。这是一个通用目的的 API，用来展示你集群中移动着的分片状态。</p>
</div>
<div class="paragraph">
<p>这个 API 可以为你在恢复的指定索引单独调用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET restored_index_3/_recovery</code></pre>
</div>
</div>
<div class="paragraph">
<p>或者查看你集群里所有索引，可能包括跟你的恢复进程无关的其他分片移动：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_recovery/</code></pre>
</div>
</div>
<div class="paragraph">
<p>输出会跟这个类似（注意，根据你集群的活跃度，输出可能会变得非常啰嗦！）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "restored_index_3" : {
    "shards" : [ {
      "id" : 0,
      "type" : "snapshot", <b class="conum">(1)</b>
      "stage" : "index",
      "primary" : true,
      "start_time" : "2014-02-24T12:15:59.716",
      "stop_time" : 0,
      "total_time_in_millis" : 175576,
      "source" : { <b class="conum">(2)</b>
        "repository" : "my_backup",
        "snapshot" : "snapshot_3",
        "index" : "restored_index_3"
      },
      "target" : {
        "id" : "ryqJ5lO5S4-lSFbGntkEkg",
        "hostname" : "my.fqdn",
        "ip" : "10.0.1.7",
        "name" : "my_es_node"
      },
      "index" : {
        "files" : {
          "total" : 73,
          "reused" : 0,
          "recovered" : 69,
          "percent" : "94.5%" <b class="conum">(3)</b>
        },
        "bytes" : {
          "total" : 79063092,
          "reused" : 0,
          "recovered" : 68891939,
          "percent" : "87.1%"
        },
        "total_time_in_millis" : 0
      },
      "translog" : {
        "recovered" : 0,
        "total_time_in_millis" : 0
      },
      "start" : {
        "check_index_time" : 0,
        "total_time_in_millis" : 0
      }
    } ]
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>type</code> 字段告诉你恢复的本质；这个分片是在从一个快照恢复。</p>
</li>
<li>
<p><code>source</code> 哈希描述了作为恢复来源的特定快照和仓库。</p>
</li>
<li>
<p><code>percent</code> 字段让你对恢复的状态有个概念。这个特定分片目前已经恢复了 94% 的文件；它就快完成了。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>输出会列出所有目前正在经历恢复的索引，然后列出这些索引里的所有分片。每个分片里会有启动/停止时间、持续时间、恢复百分比、传输字节数等统计值。</p>
</div>
</div>
<div class="sect3">
<h4 id="_取消一个恢复">取消一个恢复</h4>
<div class="paragraph">
<p>要取消一个恢复，你需要删除正在恢复的索引。因为恢复进程其实就是分片恢复，发送一个 <code>删除索引</code> API 修改集群状态，就可以停止恢复进程。比如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">DELETE /restored_index_3</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果 <code>restored_index_3</code> 正在恢复中，这个删除命令会停止恢复，同时删除所有已经恢复到集群里的数据。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_clusters_are_living_breathing_creatures">集群是活着的、呼吸着的生命</h3>
<div class="paragraph">
<p>一旦你的集群投入生产，你会发现他就开始了他自己的一生。Elasticsearch 努力工作来保证集群自给自足而且 <em>真就在工作</em> 。不过一个集群也还要有日常照料和投喂，比如日常备份和升级。</p>
</div>
<div class="paragraph">
<p>Elasticsearch 以非常快的速度发布新版本，进行错误修复和性能增强。保持你的集群采用最新版总是一个好主意。类似的，Lucene 持续在发现 JVM 自身的新的和令人惊讶的错误，这意味着你需要尽量保持你的 JVM 是最新的。</p>
</div>
<div class="paragraph">
<p>这意味着最好是拥有一个标准化的、日常的方案来操作你集群的滚动重启和升级。升级应该是一个日常程序，而不是一个需要好多个小时的精细规划下的年度『惨剧』。</p>
</div>
<div class="paragraph">
<p>类似的，拥有一个灾备计划是很重要的。请对你的集群做频繁的快照——而且通过执行真实恢复的方式定期 <em>测试</em> 这些快照！有些组织做日常备份却从不测试他们的恢复机制，这简直太常见了。通常你会在第一次演练真实恢复的时候发现明显的缺陷（比如用户不知道应该挂载哪个磁盘）。比起在凌晨 3 点真的发生危机的时候，在日常测试中暴露出这些问题总是更好的。</p>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2018-05-17 22:26:24 CST
</div>
</div>
</body>
</html>