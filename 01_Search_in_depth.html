<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.6.2">
<title>placeholder1</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Remove comment around @import statement below when using as a custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.spread{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
*:not(pre)>code.nobreak{word-wrap:normal}
*:not(pre)>code.nowrap{white-space:nowrap}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:initial}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px 0}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:.4em .75em 0 .75em;line-height:1;vertical-align:top}
.colist>table tr>td:first-of-type img{max-width:initial}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;text-indent:-1.05em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
</style>
</head>
<body class="article">
<div id="header">
<h1>placeholder1</h1>
</div>
<div id="content">
<h1 id="search-in-depth" class="sect0">深入搜索</h1>

<div class="sect1">
<h2 id="structured-search">结构化搜索</h2>
<div class="sectionbody">
<div class="paragraph">
<p><em>结构化搜索（Structured search）</em> 是指有关探询那些具有内在结构数据的过程。比如日期、时间和数字都是结构化的：它们有精确的格式，我们可以对这些格式进行逻辑操作。比较常见的操作包括比较数字或时间的范围，或判定两个值的大小。</p>
</div>
<div class="paragraph">
<p>文本也可以是结构化的。如彩色笔可以有离散的颜色集合： <code>红（red）</code> 、 <code>绿（green）</code> 、 <code>蓝（blue）</code> 。一个博客可能被标记了关键词 <code>分布式（distributed）</code> 和 <code>搜索（search）</code> 。电商网站上的商品都有 UPCs（通用产品码 Universal Product Codes）或其他的唯一标识，它们都需要遵从严格规定的、结构化的格式。</p>
</div>
<div class="paragraph">
<p>在结构化查询中，我们得到的结果 <em>总是</em> 非是即否，要么存于集合之中，要么存在集合之外。结构化查询不关心文件的相关度或评分；它简单的对文档包括或排除处理。</p>
</div>
<div class="paragraph">
<p>这在逻辑上是能说通的，因为一个数字不能比其他数字 <em>更</em> 适合存于某个相同范围。结果只能是：存于范围之中，抑或反之。同样，对于结构化文本来说，一个值要么相等，要么不等。没有 <em>更似</em> 这种概念。</p>
</div>
<div class="sect2">
<h3 id="_finding_exact_values">精确值查找</h3>
<div class="paragraph">
<p>当进行精确值查找时， 我们会使用过滤器（filters）。过滤器很重要，因为它们执行速度非常快，不会计算相关度（直接跳过了整个评分阶段）而且很容易被缓存。我们会在本章后面的 <a href="#filter-caching">过滤器缓存</a> 中讨论过滤器的性能优势，不过现在只要记住：请尽可能多的使用过滤式查询。</p>
</div>
<div class="sect3">
<h4 id="_term_查询数字">term 查询数字</h4>
<div class="paragraph">
<p>我们首先来看最为常用的 <code>term</code> 查询，
可以用它处理数字（numbers）、布尔值（Booleans）、日期（dates）以及文本（text）。</p>
</div>
<div class="literalblock">
<div class="content">
<pre>让我们以下面的例子开始介绍，创建并索引一些表示产品的文档，文档里有字段 `price` 和 `productID` （ `价格` 和 `产品ID` ）：</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">POST /my_store/products/_bulk
{ "index": { "_id": 1 }}
{ "price" : 10, "productID" : "XHDK-A-1293-#fJ3" }
{ "index": { "_id": 2 }}
{ "price" : 20, "productID" : "KDKE-B-9947-#kL5" }
{ "index": { "_id": 3 }}
{ "price" : 30, "productID" : "JODL-X-1937-#pV7" }
{ "index": { "_id": 4 }}
{ "price" : 30, "productID" : "QQPX-R-3956-#aD8" }</code></pre>
</div>
</div>
<div class="paragraph">
<p>我们想要做的是查找具有某个价格的所有产品，有关系数据库背景的人肯定熟悉 SQL，如果我们将其用 SQL 形式表达，会是下面这样：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">SELECT document
FROM   products
WHERE  price = 20</code></pre>
</div>
</div>
<div class="paragraph">
<p>在 Elasticsearch 的查询表达式（query DSL）中，我们可以使用 <code>term</code> 查询达到相同的目的。 <code>term</code> 查询会查找我们指定的精确值。作为其本身， <code>term</code> 查询是简单的。它接受一个字段名以及我们希望查找的数值：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "term" : {
        "price" : 20
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>通常当查找一个精确值的时候，我们不希望对查询进行评分计算。只希望对文档进行包括或排除的计算，所以我们会使用 <code>constant_score</code> 查询以非评分模式来执行 <code>term</code> 查询并以一作为统一评分。</p>
</div>
<div class="paragraph">
<p>最终组合的结果是一个 <code>constant_score</code> 查询，它包含一个 <code>term</code> 查询：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_store/products/_search
{
    "query" : {
        "constant_score" : { <b class="conum">(1)</b>
            "filter" : {
                "term" : { <b class="conum">(2)</b>
                    "price" : 20
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>我们用 <code>constant_score</code> 将 <code>term</code> 查询转化成为过滤器</p>
</li>
<li>
<p>我们之前看到过的 <code>term</code> 查询</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>执行后，这个查询所搜索到的结果与我们期望的一致：只有文档 2 命中并作为结果返回（因为只有 <code>2</code> 的价格是 <code>20</code> ）:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">"hits" : [
    {
        "_index" : "my_store",
        "_type" :  "products",
        "_id" :    "2",
        "_score" : 1.0, <b class="conum">(1)</b>
        "_source" : {
          "price" :     20,
          "productID" : "KDKE-B-9947-#kL5"
        }
    }
]</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>查询置于 <code>filter</code> 语句内不进行评分或相关度的计算，所以所有的结果都会返回一个默认评分 <code>1</code> 。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_term_查询文本">term 查询文本</h4>
<div class="paragraph">
<p>如本部分开始处提到过的一样 ，使用 <code>term</code> 查询匹配字符串和匹配数字一样容易。如果我们想要查询某个具体 UPC ID 的产品，使用 SQL 表达式会是如下这样：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">SELECT product
FROM   products
WHERE  productID = "XHDK-A-1293-#fJ3"</code></pre>
</div>
</div>
<div class="paragraph">
<p>转换成查询表达式（query DSL），同样使用 <code>term</code> 查询，形式如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_store/products/_search
{
    "query" : {
        "constant_score" : {
            "filter" : {
                "term" : {
                    "productID" : "XHDK-A-1293-#fJ3"
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>但这里有个小问题：我们无法获得期望的结果。为什么呢？问题不在 <code>term</code> 查询，而在于索引数据的方式。  如果我们使用 <code>analyze</code> API (<a href="#analyze-api">分析 API</a>)，我们可以看到这里的 UPC 码被拆分成多个更小的 token ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_store/_analyze
{
  "field": "productID",
  "text": "XHDK-A-1293-#fJ3"
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "tokens" : [ {
    "token" :        "xhdk",
    "start_offset" : 0,
    "end_offset" :   4,
    "type" :         "&lt;ALPHANUM&gt;",
    "position" :     1
  }, {
    "token" :        "a",
    "start_offset" : 5,
    "end_offset" :   6,
    "type" :         "&lt;ALPHANUM&gt;",
    "position" :     2
  }, {
    "token" :        "1293",
    "start_offset" : 7,
    "end_offset" :   11,
    "type" :         "&lt;NUM&gt;",
    "position" :     3
  }, {
    "token" :        "fj3",
    "start_offset" : 13,
    "end_offset" :   16,
    "type" :         "&lt;ALPHANUM&gt;",
    "position" :     4
  } ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这里有几点需要注意：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Elasticsearch 用 4 个不同的 token 而不是单个 token 来表示这个 UPC 。</p>
</li>
<li>
<p>所有字母都是小写的。</p>
</li>
<li>
<p>丢失了连字符和哈希符（ <code>#</code> ）。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>所以当我们用 <code>term</code> 查询查找精确值 <code>XHDK-A-1293-#fJ3</code> 的时候，找不到任何文档，因为它并不在我们的倒排索引中，正如前面呈现出的分析结果，索引里有四个 token 。</p>
</div>
<div class="paragraph">
<p>显然这种对 ID 码或其他任何精确值的处理方式并不是我们想要的。</p>
</div>
<div class="paragraph">
<p>为了避免这种问题，我们需要告诉 Elasticsearch 该字段具有精确值，要将其设置成 <code>not_analyzed</code> 无需分析的。 我们可以在 <a href="#custom-field-mappings">自定义字段映射</a> 中查看它的用法。为了修正搜索结果，我们需要首先删除旧索引（因为它的映射不再正确）然后创建一个能正确映射的新索引：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">DELETE /my_store <b class="conum">(1)</b>

PUT /my_store <b class="conum">(2)</b>
{
    "mappings" : {
        "products" : {
            "properties" : {
                "productID" : {
                    "type" : "string",
                    "index" : "not_analyzed" <b class="conum">(3)</b>
                }
            }
        }
    }

}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>删除索引是必须的，因为我们不能更新已存在的映射。</p>
</li>
<li>
<p>在索引被删除后，我们可以创建新的索引并为其指定自定义映射。</p>
</li>
<li>
<p>这里我们告诉 Elasticsearch ，我们不想对 <code>productID</code> 做任何分析。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>现在我们可以为文档重建索引：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">POST /my_store/products/_bulk
{ "index": { "_id": 1 }}
{ "price" : 10, "productID" : "XHDK-A-1293-#fJ3" }
{ "index": { "_id": 2 }}
{ "price" : 20, "productID" : "KDKE-B-9947-#kL5" }
{ "index": { "_id": 3 }}
{ "price" : 30, "productID" : "JODL-X-1937-#pV7" }
{ "index": { "_id": 4 }}
{ "price" : 30, "productID" : "QQPX-R-3956-#aD8" }</code></pre>
</div>
</div>
<div class="paragraph">
<p>此时， <code>term</code> 查询就能搜索到我们想要的结果，让我们再次搜索新索引过的数据（注意，查询和过滤并没有发生任何改变，改变的是数据映射的方式）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_store/products/_search
{
    "query" : {
        "constant_score" : {
            "filter" : {
                "term" : {
                    "productID" : "XHDK-A-1293-#fJ3"
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>因为 <code>productID</code> 字段是未分析过的， <code>term</code> 查询不会对其做任何分析，查询会进行精确查找并返回文档 1 。成功！</p>
</div>
</div>
<div class="sect3">
<h4 id="_internal_filter_operation">内部过滤器的操作</h4>
<div class="paragraph">
<p>在内部，Elasticsearch 
会在运行非评分查询的时执行多个操作：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>查找匹配文档</em>.</p>
<div class="paragraph">
<p><code>term</code> 查询在倒排索引中查找 <code>XHDK-A-1293-#fJ3</code> 然后获取包含该 term 的所有文档。本例中，只有文档 1 满足我们要求。</p>
</div>
</li>
<li>
<p><em>创建 bitset</em>.</p>
<div class="paragraph">
<p>过滤器会创建一个 <em>bitset</em> （一个包含 0 和 1 的数组），它描述了哪个文档会包含该 term 。匹配文档的标志位是 1 。本例中，bitset 的值为 <code>[1,0,0,0]</code> 。在内部，它表示成一个 <a href="https://www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps">"roaring bitmap"</a>，可以同时对稀疏或密集的集合进行高效编码。</p>
</div>
</li>
<li>
<p><em>迭代 bitset(s)</em></p>
<div class="paragraph">
<p>一旦为每个查询生成了 bitsets ，Elasticsearch 就会循环迭代 bitsets 从而找到满足所有过滤条件的匹配文档的集合。执行顺序是启发式的，但一般来说先迭代稀疏的 bitset （因为它可以排除掉大量的文档）。</p>
</div>
</li>
<li>
<p><em>增量使用计数</em>.</p>
<div class="paragraph">
<p>Elasticsearch 能够缓存非评分查询从而获取更快的访问，但是它也会不太聪明地缓存一些使用极少的东西。非评分计算因为倒排索引已经足够快了，所以我们只想缓存那些我们 <em>知道</em> 在将来会被再次使用的查询，以避免资源的浪费。</p>
</div>
<div class="paragraph">
<p>为了实现以上设想，Elasticsearch 会为每个索引跟踪保留查询使用的历史状态。如果查询在最近的 256 次查询中会被用到，那么它就会被缓存到内存中。当 bitset 被缓存后，缓存会在那些低于 10,000 个文档（或少于 3% 的总索引数）的段（segment）中被忽略。这些小的段即将会消失，所以为它们分配缓存是一种浪费。</p>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>实际情况并非如此（执行有它的复杂性，这取决于查询计划是如何重新规划的，有些启发式的算法是基于查询代价的），理论上非评分查询 <em>先于</em> 评分查询执行。非评分查询任务旨在降低那些将对评分查询计算带来更高成本的文档数量，从而达到快速搜索的目的。</p>
</div>
<div class="paragraph">
<p>从概念上记住非评分计算是首先执行的，这将有助于写出高效又快速的搜索请求。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="combining-filters">组合过滤器</h3>
<div class="paragraph">
<p>前面的两个例子都是单个过滤器（filter）的使用方式。 在实际应用中，我们很有可能会过滤多个值或字段。比方说，怎样用 Elasticsearch 来表达下面的 SQL ？</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">SELECT product
FROM   products
WHERE  (price = 20 OR productID = "XHDK-A-1293-#fJ3")
  AND  (price != 30)</code></pre>
</div>
</div>
<div class="paragraph">
<p>这种情况下，我们需要 <code>bool</code> （布尔）过滤器。 这是个 <em>复合过滤器（compound filter）</em> ，它可以接受多个其他过滤器作为参数，并将这些过滤器结合成各式各样的布尔（逻辑）组合。</p>
</div>
<div class="sect3">
<h4 id="bool-filter">布尔过滤器</h4>
<div class="paragraph">
<p>一个 <code>bool</code> 过滤器由三部分组成：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "bool" : {
      "must" :     [],
      "should" :   [],
      "must_not" : [],
   }
}</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>must</code></dt>
<dd>
<p>所有的语句都 <em>必须（must）</em> 匹配，与 <code>AND</code> 等价。</p>
</dd>
<dt class="hdlist1"><code>must_not</code></dt>
<dd>
<p>所有的语句都 <em>不能（must not）</em> 匹配，与 <code>NOT</code> 等价。</p>
</dd>
<dt class="hdlist1"><code>should</code></dt>
<dd>
<p>至少有一个语句要匹配，与 <code>OR</code> 等价。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>就这么简单！ 当我们需要多个过滤器时，只须将它们置入 <code>bool</code> 过滤器的不同部分即可。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>一个 <code>bool</code> 过滤器的每个部分都是可选的（例如，我们可以只有一个 <code>must</code> 语句），而且每个部分内部可以只有一个或一组过滤器。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>用 Elasticsearch 来表示本部分开始处的 SQL 例子，将两个 <code>term</code> 过滤器置入  <code>bool</code> 过滤器的 <code>should</code> 语句内，再增加一个语句处理 <code>NOT</code> 非的条件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_store/products/_search
{
   "query" : {
      "filtered" : { <b class="conum">(1)</b>
         "filter" : {
            "bool" : {
              "should" : [
                 { "term" : {"price" : 20}}, <b class="conum">(2)</b>
                 { "term" : {"productID" : "XHDK-A-1293-#fJ3"}} <b class="conum">(2)</b>
              ],
              "must_not" : {
                 "term" : {"price" : 30} <b class="conum">(3)</b>
              }
           }
         }
      }
   }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>注意，我们仍然需要一个 <code>filtered</code> 查询将所有的东西包起来。</p>
</li>
<li>
<p>在 <code>should</code> 语句块里面的两个 <code>term</code> 过滤器与 <code>bool</code> 过滤器是父子关系，两个 <code>term</code> 条件需要匹配其一。</p>
</li>
<li>
<p>如果一个产品的价格是 <code>30</code> ，那么它会自动被排除，因为它处于 <code>must_not</code> 语句里面。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>我们搜索的结果返回了 2 个命中结果，两个文档分别匹配了 <code>bool</code> 过滤器其中的一个条件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">"hits" : [
    {
        "_id" :     "1",
        "_score" :  1.0,
        "_source" : {
          "price" :     10,
          "productID" : "XHDK-A-1293-#fJ3" <b class="conum">(1)</b>
        }
    },
    {
        "_id" :     "2",
        "_score" :  1.0,
        "_source" : {
          "price" :     20, <b class="conum">(2)</b>
          "productID" : "KDKE-B-9947-#kL5"
        }
    }
]</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>与 <code>term</code> 过滤器中 <code>productID = "XHDK-A-1293-#fJ3"</code> 条件匹配</p>
</li>
<li>
<p>与 <code>term</code> 过滤器中 <code>price = 20</code> 条件匹配</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_嵌套布尔过滤器">嵌套布尔过滤器</h4>
<div class="paragraph">
<p>尽管 <code>bool</code> 是一个复合的过滤器，可以接受多个子过滤器，需要注意的是 <code>bool</code> 过滤器本身仍然还只是一个过滤器。  这意味着我们可以将一个 <code>bool</code> 过滤器置于其他 <code>bool</code> 过滤器内部，这为我们提供了对任意复杂布尔逻辑进行处理的能力。</p>
</div>
<div class="paragraph">
<p>对于以下这个 SQL 语句：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">SELECT document
FROM   products
WHERE  productID      = "KDKE-B-9947-#kL5"
  OR (     productID = "JODL-X-1937-#pV7"
       AND price     = 30 )</code></pre>
</div>
</div>
<div class="paragraph">
<p>我们将其转换成一组嵌套的 <code>bool</code> 过滤器：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_store/products/_search
{
   "query" : {
      "filtered" : {
         "filter" : {
            "bool" : {
              "should" : [
                { "term" : {"productID" : "KDKE-B-9947-#kL5"}}, <b class="conum">(1)</b>
                { "bool" : { <b class="conum">(1)</b>
                  "must" : [
                    { "term" : {"productID" : "JODL-X-1937-#pV7"}}, <b class="conum">(2)</b>
                    { "term" : {"price" : 30}} <b class="conum">(2)</b>
                  ]
                }}
              ]
           }
         }
      }
   }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>因为 <code>term</code> 和 <code>bool</code> 过滤器是兄弟关系，他们都处于外层的布尔逻辑 <code>should</code> 的内部，返回的命中文档至少须匹配其中一个过滤器的条件。</p>
</li>
<li>
<p>这两个 <code>term</code> 语句作为兄弟关系，同时处于 <code>must</code> 语句之中，所以返回的命中文档要必须都能同时匹配这两个条件。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>得到的结果有两个文档，它们各匹配 <code>should</code> 语句中的一个条件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">"hits" : [
    {
        "_id" :     "2",
        "_score" :  1.0,
        "_source" : {
          "price" :     20,
          "productID" : "KDKE-B-9947-#kL5" <b class="conum">(1)</b>
        }
    },
    {
        "_id" :     "3",
        "_score" :  1.0,
        "_source" : {
          "price" :      30, <b class="conum">(2)</b>
          "productID" : "JODL-X-1937-#pV7" <b class="conum">(2)</b>
        }
    }
]</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>这个 <code>productID</code> 与外层的 <code>bool</code> 过滤器 <code>should</code> 里的唯一一个 <code>term</code> 匹配。</p>
</li>
<li>
<p>这两个字段与嵌套的 <code>bool</code> 过滤器 <code>must</code> 里的两个 <code>term</code> 匹配。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这只是个简单的例子，但足以展示布尔过滤器可以用来作为构造复杂逻辑条件的基本构建模块。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_finding_multiple_exact_values">查找多个精确值</h3>
<div class="paragraph">
<p><code>term</code> 查询对于查找单个值非常有用，但通常我们可能想搜索多个值。  如果我们想要查找价格字段值为 $20 或 $30 的文档该如何处理呢？</p>
</div>
<div class="paragraph">
<p>不需要使用多个 <code>term</code> 查询，我们只要用单个 <code>terms</code> 查询（注意末尾的 <em>s</em> ）， <code>terms</code> 查询好比是 <code>term</code> 查询的复数形式（以英语名词的单复数做比）。</p>
</div>
<div class="paragraph">
<p>它几乎与 <code>term</code> 的使用方式一模一样，与指定单个价格不同，我们只要将 <code>term</code> 字段的值改为数组即可：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "terms" : {
        "price" : [20, 30]
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>与 <code>term</code> 查询一样，也需要将其置入 <code>filter</code> 语句的常量评分查询中使用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_store/products/_search
{
    "query" : {
        "constant_score" : {
            "filter" : {
                "terms" : { <b class="conum">(1)</b>
                    "price" : [20, 30]
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>这个 <code>terms</code> 查询被置于 <code>constant_score</code> 查询中</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>运行结果返回第二、第三和第四个文档：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">"hits" : [
    {
        "_id" :    "2",
        "_score" : 1.0,
        "_source" : {
          "price" :     20,
          "productID" : "KDKE-B-9947-#kL5"
        }
    },
    {
        "_id" :    "3",
        "_score" : 1.0,
        "_source" : {
          "price" :     30,
          "productID" : "JODL-X-1937-#pV7"
        }
    },
    {
        "_id":     "4",
        "_score":  1.0,
        "_source": {
           "price":     30,
           "productID": "QQPX-R-3956-#aD8"
        }
     }
]</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="_包含_而不是相等">包含，而不是相等</h4>
<div class="paragraph">
<p>一定要了解 <code>term</code> 和 <code>terms</code> 是 <em>包含（contains）</em> 操作，而非 <em>等值（equals）</em> （判断）。  如何理解这句话呢？</p>
</div>
<div class="paragraph">
<p>如果我们有一个 term（词项）过滤器 <code>{ "term" : { "tags" : "search" } }</code> ，它会与以下两个文档 <em>同时</em> 匹配：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{ "tags" : ["search"] }
{ "tags" : ["search", "open_source"] } <b class="conum">(1)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>尽管第二个文档包含除 <code>search</code> 以外的其他词，它还是被匹配并作为结果返回。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>回忆一下 <code>term</code> 查询是如何工作的？ Elasticsearch 会在倒排索引中查找包括某 term 的所有文档，然后构造一个 bitset 。在我们的例子中，倒排索引表如下：</p>
</div>
<table class="tableblock frame-topbot grid-all" style="width: 50%;">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Token</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">DocIDs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>open_source</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>search</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code>,<code>2</code></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>当 <code>term</code> 查询匹配标记 <code>search</code> 时，它直接在倒排索引中找到记录并获取相关的文档 ID，如倒排索引所示，这里文档 1 和文档 2 均包含该标记，所以两个文档会同时作为结果返回。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>由于倒排索引表自身的特性，整个字段是否相等会难以计算，如果确定某个特定文档是否 <em>只（only）</em> 包含我们想要查找的词呢？首先我们需要在倒排索引中找到相关的记录并获取文档 ID，然后再扫描 <em>倒排索引中的每行记录</em> ，查看它们是否包含其他的 terms 。</p>
</div>
<div class="paragraph">
<p>可以想象，这样不仅低效，而且代价高昂。正因如此， <code>term</code> 和 <code>terms</code> 是 <em>必须包含（must contain）</em> 操作，而不是 <em>必须精确相等（must equal exactly）</em> 。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_精确相等">精确相等</h4>
<div class="paragraph">
<p>如果一定期望得到我们前面说的那种行为（即整个字段完全相等），最好的方式是增加并索引另一个字段， 这个字段用以存储该字段包含词项的数量，同样以上面提到的两个文档为例，现在我们包括了一个维护标签数的新字段：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{ "tags" : ["search"], "tag_count" : 1 }
{ "tags" : ["search", "open_source"], "tag_count" : 2 }</code></pre>
</div>
</div>
<div class="paragraph">
<p>一旦增加这个用来索引项 term 数目信息的字段，我们就可以构造一个 <code>constant_score</code> 查询，来确保结果中的文档所包含的词项数量与要求是一致的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
    "query": {
        "constant_score" : {
            "filter" : {
                 "bool" : {
                    "must" : [
                        { "term" : { "tags" : "search" } }, <b class="conum">(1)</b>
                        { "term" : { "tag_count" : 1 } } <b class="conum">(2)</b>
                    ]
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>查找所有包含 term <code>search</code> 的文档。</p>
</li>
<li>
<p>确保文档只有一个标签。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这个查询现在只会匹配具有单个标签 <code>search</code> 的文档，而不是任意一个包含 <code>search</code> 的文档。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ranges">范围</h3>
<div class="paragraph">
<p>本章到目前为止，对于数字，只介绍如何处理精确值查询。实际上，对数字范围进行过滤有时会更有用。例如，我们可能想要查找所有价格大于 $20 且小于 $40 美元的产品。</p>
</div>
<div class="paragraph">
<p>在 SQL 中，范围查询可以表示为：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">SELECT document
FROM   products
WHERE  price BETWEEN 20 AND 40</code></pre>
</div>
</div>
<div class="paragraph">
<p>Elasticsearch 有 <code>range</code> 查询，不出所料地，可以用它来查找处于某个范围内的文档：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">"range" : {
    "price" : {
        "gte" : 20,
        "lte" : 40
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>range</code> 查询可同时提供包含（inclusive）和不包含（exclusive）这两种范围表达式，可供组合的选项如下：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>gt</code>: <code>&gt;</code> 大于（greater than）</p>
</li>
<li>
<p><code>lt</code>: <code>&lt;</code> 小于（less than）</p>
</li>
<li>
<p><code>gte</code>: <code>&gt;=</code> 大于或等于（greater than or equal to）</p>
</li>
<li>
<p><code>lte</code>: <code>&#8656;</code> 小于或等于（less than or equal to）</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">下面是一个范围查询的例子：</div>
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_store/products/_search
{
    "query" : {
        "constant_score" : {
            "filter" : {
                "range" : {
                    "price" : {
                        "gte" : 20,
                        "lt"  : 40
                    }
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果想要范围无界（比方说 &gt;20 ），只须省略其中一边的限制：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">"range" : {
    "price" : {
        "gt" : 20
    }
}</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="_日期范围">日期范围</h4>
<div class="paragraph">
<p><code>range</code> 查询同样可以应用在日期字段上：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">"range" : {
    "timestamp" : {
        "gt" : "2014-01-01 00:00:00",
        "lt" : "2014-01-07 00:00:00"
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>当使用它处理日期字段时， <code>range</code> 查询支持对  <em>日期计算（date math）</em>  进行操作，比方说，如果我们想查找时间戳在过去一小时内的所有文档：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">"range" : {
    "timestamp" : {
        "gt" : "now-1h"
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个过滤器会一直查找时间戳在过去一个小时内的所有文档，让过滤器作为一个时间  <em>滑动窗口（sliding window）</em> 来过滤文档。</p>
</div>
<div class="paragraph">
<p>日期计算还可以被应用到某个具体的时间，并非只能是一个像 now 这样的占位符。只要在某个日期后加上一个双管符号 (<code>||</code>) 并紧跟一个日期数学表达式就能做到：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">"range" : {
    "timestamp" : {
        "gt" : "2014-01-01 00:00:00",
        "lt" : "2014-01-01 00:00:00||+1M" <b class="conum">(1)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>早于 2014 年 1 月 1 日加 1 月（2014 年 2 月 1 日 零时）</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>日期计算是 <em>日历相关（calendar aware）</em> 的，所以它不仅知道每月的具体天数，还知道某年的总天数（闰年）等信息。更详细的内容可以参考：
 {ref}/mapping-date-format.html[时间格式参考文档] 。</p>
</div>
</div>
<div class="sect3">
<h4 id="_字符串范围">字符串范围</h4>
<div class="paragraph">
<p><code>range</code> 查询同样可以处理字符串字段，字符串范围可采用 <em>字典顺序（lexicographically）</em> 或字母顺序（alphabetically）。例如，下面这些字符串是采用字典序（lexicographically）排序的：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>5, 50, 6, B, C, a, ab, abb, abc, b</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>在倒排索引中的词项就是采取字典顺序（lexicographically）排列的，这也是字符串范围可以使用这个顺序来确定的原因。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>如果我们想查找从 <code>a</code> 到 <code>b</code> （不包含）的字符串，同样可以使用 <code>range</code> 查询语法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">"range" : {
    "title" : {
        "gte" : "a",
        "lt" :  "b"
    }
}</code></pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">注意基数</div>
<div class="paragraph">
<p>数字和日期字段的索引方式使高效地范围计算成为可能。但字符串却并非如此，要想对其使用范围过滤，Elasticsearch 实际上是在为范围内的每个词项都执行 <code>term</code> 过滤器，这会比日期或数字的范围过滤慢许多。</p>
</div>
<div class="paragraph">
<p>字符串范围在过滤 <em>低基数（low cardinality）</em> 字段（即只有少量唯一词项）时可以正常工作，但是唯一词项越多，字符串范围的计算会越慢。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_dealing_with_null_values">处理 Null 值</h3>
<div class="paragraph">
<p>回想在之前例子中，有的文档有名为 <code>tags</code> （标签）的字段，它是个多值字段，一个文档可能有一个或多个标签，也可能根本就没有标签。如果一个字段没有值，那么如何将它存入倒排索引中的呢？</p>
</div>
<div class="paragraph">
<p>这是个有欺骗性的问题，因为答案是：什么都不存。让我们看看之前内容里提到过的倒排索引：</p>
</div>
<table class="tableblock frame-topbot grid-all" style="width: 50%;">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Token</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">DocIDs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>open_source</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>search</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code>,<code>2</code></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>如何将某个不存在的字段存储在这个数据结构中呢？无法做到！简单的说，一个倒排索引只是一个 token 列表和与之相关的文档信息，如果字段不存在，那么它也不会持有任何 token，也就无法在倒排索引结构中表现。</p>
</div>
<div class="paragraph">
<p>最终，这也就意味着，<code>null</code>, <code>[]</code> （空数组）和 <code>[null]</code> 所有这些都是等价的，它们无法存于倒排索引中。</p>
</div>
<div class="paragraph">
<p>显然，世界并不简单，数据往往会有缺失字段，或有显式的空值或空数组。为了应对这些状况，Elasticsearch 提供了一些工具来处理空或缺失值。</p>
</div>
<div class="sect3">
<h4 id="_存在查询">存在查询</h4>
<div class="paragraph">
<p>第一件武器就是 <code>exists</code> 存在查询。这个查询会返回那些在指定字段有任何值的文档，让我们索引一些示例文档并用标签的例子来说明：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">POST /my_index/posts/_bulk
{ "index": { "_id": "1"              }}
{ "tags" : ["search"]                }  <b class="conum">(1)</b>
{ "index": { "_id": "2"              }}
{ "tags" : ["search", "open_source"] }  <b class="conum">(2)</b>
{ "index": { "_id": "3"              }}
{ "other_field" : "some data"        }  <b class="conum">(3)</b>
{ "index": { "_id": "4"              }}
{ "tags" : null                      }  <b class="conum">(4)</b>
{ "index": { "_id": "5"              }}
{ "tags" : ["search", null]          }  <b class="conum">(5)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>tags</code> 字段有 1 个值。</p>
</li>
<li>
<p><code>tags</code> 字段有 2 个值。</p>
</li>
<li>
<p><code>tags</code> 字段缺失。</p>
</li>
<li>
<p><code>tags</code> 字段被置为 <code>null</code> 。</p>
</li>
<li>
<p><code>tags</code> 字段有 1 个值和 1 个 <code>null</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>以上文档集合中 <code>tags</code> 字段对应的倒排索引如下：</p>
</div>
<table class="tableblock frame-topbot grid-all" style="width: 50%;">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Token</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">DocIDs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>open_source</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>search</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code>,<code>2</code>,<code>5</code></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>我们的目标是找到那些被设置过标签字段的文档，并不关心标签的具体内容。只要它存在于文档中即可，用 SQL 的话就是用 <code>IS NOT NULL</code> 非空进行查询：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">SELECT tags
FROM   posts
WHERE  tags IS NOT NULL</code></pre>
</div>
</div>
<div class="paragraph">
<p>在 Elasticsearch 中，使用 <code>exists</code> 查询的方式如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/posts/_search
{
    "query" : {
        "constant_score" : {
            "filter" : {
                "exists" : { "field" : "tags" }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个查询返回 3 个文档：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">"hits" : [
    {
      "_id" :     "1",
      "_score" :  1.0,
      "_source" : { "tags" : ["search"] }
    },
    {
      "_id" :     "5",
      "_score" :  1.0,
      "_source" : { "tags" : ["search", null] } <b class="conum">(1)</b>
    },
    {
      "_id" :     "2",
      "_score" :  1.0,
      "_source" : { "tags" : ["search", "open source"] }
    }
]</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>尽管文档 5 有 <code>null</code> 值，但它仍会被命中返回。字段之所以存在，是因为标签有实际值（  <code>search</code> ）可以被索引，所以 <code>null</code> 对过滤不会产生任何影响。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>显而易见，只要 <code>tags</code> 字段存在项（term）的文档都会命中并作为结果返回，只有 3 和 4 两个文档被排除。</p>
</div>
</div>
<div class="sect3">
<h4 id="_缺失查询">缺失查询</h4>
<div class="paragraph">
<p>这个 <code>missing</code> 查询本质上与 <code>exists</code> 恰好相反：它返回某个特定 <em>无</em> 值字段的文档，与以下 SQL 表达的意思类似：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-sql" data-lang="sql">SELECT tags
FROM   posts
WHERE  tags IS NULL</code></pre>
</div>
</div>
<div class="paragraph">
<p>我们将前面例子中 <code>exists</code> 查询换成 <code>missing</code> 查询：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/posts/_search
{
    "query" : {
        "constant_score" : {
            "filter": {
                "missing" : { "field" : "tags" }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>按照期望的那样，我们得到 3 和 4 两个文档（这两个文档的 <code>tags</code> 字段没有实际值）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">"hits" : [
    {
      "_id" :     "3",
      "_score" :  1.0,
      "_source" : { "other_field" : "some data" }
    },
    {
      "_id" :     "4",
      "_score" :  1.0,
      "_source" : { "tags" : null }
    }
]</code></pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">当 null 的意思是 null</div>
<div class="paragraph">
<p>有时候我们需要区分一个字段是没有值，还是它已被显式的设置成了 <code>null</code> 。在之前例子中，我们看到的默认的行为是无法做到这点的；数据被丢失了。不过幸运的是，我们可以选择将显式的 <code>null</code> 值替换成我们指定 <em>占位符（placeholder）</em> 。</p>
</div>
<div class="paragraph">
<p>在为字符串（string）、数字（numeric）、布尔值（Boolean）或日期（date）字段指定映射时，同样可以为之设置 <code>null_value</code> 空值，用以处理显式 <code>null</code> 值的情况。不过即使如此，还是会将一个没有值的字段从倒排索引中排除。</p>
</div>
<div class="paragraph">
<p>当选择合适的 <code>null_value</code> 空值的时候，需要保证以下几点：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>它会匹配字段的类型，我们不能为一个 <code>date</code> 日期字段设置字符串类型的 <code>null_value</code> 。</p>
</li>
<li>
<p>它必须与普通值不一样，这可以避免把实际值当成 <code>null</code> 空的情况。</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_对象上的存在与缺失">对象上的存在与缺失</h4>
<div class="paragraph">
<p>不仅可以过滤核心类型， <code>exists</code> and <code>missing</code> 查询 
 还可以处理一个对象的内部字段。以下面文档为例：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "name" : {
      "first" : "John",
      "last" :  "Smith"
   }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>我们不仅可以检查 <code>name.first</code> 和 <code>name.last</code> 的存在性，也可以检查 <code>name</code> ，不过在 <a href="#mapping">映射</a> 中，如上对象的内部是个扁平的字段与值（field-value）的简单键值结构，类似下面这样：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "name.first" : "John",
   "name.last"  : "Smith"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>那么我们如何用 <code>exists</code> 或 <code>missing</code> 查询 <code>name</code> 字段呢？ <code>name</code> 字段并不真实存在于倒排索引中。</p>
</div>
<div class="paragraph">
<p>原因是当我们执行下面这个过滤的时候：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "exists" : { "field" : "name" }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>实际执行的是：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "bool": {
        "should": [
            { "exists": { "field": "name.first" }},
            { "exists": { "field": "name.last" }}
        ]
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这也就意味着，如果 <code>first</code> 和 <code>last</code> 都是空，那么 <code>name</code> 这个命名空间才会被认为不存在。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="filter-caching">关于缓存</h3>
<div class="paragraph">
<p>在本章前面（<a href="#_internal_filter_operation">过滤器的内部操作</a>）中，我们已经简单介绍了过滤器是如何计算的。其核心实际是采用一个 bitset 记录与过滤器匹配的文档。Elasticsearch 积极地把这些 bitset 缓存起来以备随后使用。一旦缓存成功，bitset 可以复用 <em>任何</em> 已使用过的相同过滤器，而无需再次计算整个过滤器。</p>
</div>
<div class="paragraph">
<p>这些 bitsets 缓存是“智能”的：它们以增量方式更新。当我们索引新文档时，只需将那些新文档加入已有 bitset，而不是对整个缓存一遍又一遍的重复计算。和系统其他部分一样，过滤器是实时的，我们无需担心缓存过期问题。</p>
</div>
<div class="sect3">
<h4 id="_独立的过滤器缓存">独立的过滤器缓存</h4>
<div class="paragraph">
<p>属于一个查询组件的 bitsets 是独立于它所属搜索请求其他部分的。这就意味着，一旦被缓存，一个查询可以被用作多个搜索请求。bitsets 并不依赖于它所存在的查询上下文。这样使得缓存可以加速查询中经常使用的部分，从而降低较少、易变的部分所带来的消耗。</p>
</div>
<div class="paragraph">
<p>同样，如果单个请求重用相同的非评分查询，它缓存的 bitset 可以被单个搜索里的所有实例所重用。</p>
</div>
<div class="paragraph">
<p>让我们看看下面例子中的查询，它查找满足以下任意一个条件的电子邮件：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>在收件箱中，且没有被读过的</p>
</li>
<li>
<p><em>不在</em> 收件箱中，但被标注重要的</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /inbox/emails/_search
{
  "query": {
      "constant_score": {
          "filter": {
              "bool": {
                 "should": [
                    { "bool": {
                          "must": [
                             { "term": { "folder": "inbox" }}, <b class="conum">(1)</b>
                             { "term": { "read": false }}
                          ]
                    }},
                    { "bool": {
                          "must_not": {
                             "term": { "folder": "inbox" } <b class="conum">(1)</b>
                          },
                          "must": {
                             "term": { "important": true }
                          }
                    }}
                 ]
              }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>两个过滤器是相同的，所以会使用同一 bitset 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>尽管其中一个收件箱的条件是 <code>must</code> 语句，另一个是 <code>must_not</code> 语句，但他们两者是完全相同的。这意味着在第一个语句执行后， bitset 就会被计算然后缓存起来供另一个使用。当再次执行这个查询时，收件箱的这个过滤器已经被缓存了，所以两个语句都会使用已缓存的 bitset 。</p>
</div>
<div class="paragraph">
<p>这点与查询表达式（query DSL）的可组合性结合得很好。它易被移动到表达式的任何地方，或者在同一查询中的多个位置复用。这不仅能方便开发者，而且对提升性能有直接的益处。</p>
</div>
</div>
<div class="sect3">
<h4 id="_自动缓存行为">自动缓存行为</h4>
<div class="paragraph">
<p>在 Elasticsearch 的较早版本中，默认的行为是缓存一切可以缓存的对象。这也通常意味着系统缓存 bitsets 太富侵略性，从而因为清理缓存带来性能压力。不仅如此，尽管很多过滤器都很容易被评价，但本质上是慢于缓存的（以及从缓存中复用）。缓存这些过滤器的意义不大，因为可以简单地再次执行过滤器。</p>
</div>
<div class="paragraph">
<p>检查一个倒排是非常快的，然后绝大多数查询组件却很少使用它。例如 <code>term</code> 过滤字段 <code>"user_id"</code> ：如果有上百万的用户，每个具体的用户 ID 出现的概率都很小。那么为这个过滤器缓存 bitsets 就不是很合算，因为缓存的结果很可能在重用之前就被剔除了。</p>
</div>
<div class="paragraph">
<p>这种缓存的扰动对性能有着严重的影响。更严重的是，它让开发者难以区分有良好表现的缓存以及无用缓存。</p>
</div>
<div class="paragraph">
<p>为了解决问题，Elasticsearch 会基于使用频次自动缓存查询。如果一个非评分查询在最近的 256 次查询中被使用过（次数取决于查询类型），那么这个查询就会作为缓存的候选。但是，并不是所有的片段都能保证缓存 bitset 。只有那些文档数量超过 10,000 （或超过总文档数量的 3% )才会缓存 bitset 。因为小的片段可以很快的进行搜索和合并，这里缓存的意义不大。</p>
</div>
<div class="paragraph">
<p>一旦缓存了，非评分计算的 bitset 会一直驻留在缓存中直到它被剔除。剔除规则是基于 LRU 的：一旦缓存满了，最近最少使用的过滤器会被剔除。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="full-text-search">全文搜索</h2>
<div class="sectionbody">
<div class="paragraph">
<p>我们已经介绍了搜索结构化数据的简单应用示例，现在来探寻 <em>全文搜索（full-text search）</em> ：怎样在全文字段中搜索到最相关的文档。</p>
</div>
<div class="paragraph">
<p>全文搜索两个最重要的方面是：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">相关性（Relevance）</dt>
<dd>
<p>它是评价查询与其结果间的相关程度，并根据这种相关程度对结果排名的一种能力，这种计算方式可以是 TF/IDF 方法（参见 <a href="#relevance-intro">相关性的介绍</a>）、地理位置邻近、模糊相似，或其他的某些算法。</p>
</dd>
<dt class="hdlist1">分析（Analysis）</dt>
<dd>
<p>它是将文本块转换为有区别的、规范化的 token 的一个过程，（参见 <a href="#analysis-intro">分析的介绍</a>） 目的是为了（a）创建倒排索引以及（b）查询倒排索引。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>一旦谈论相关性或分析这两个方面的问题时，我们所处的语境是关于查询的而不是过滤。</p>
</div>
<div class="sect2">
<h3 id="term-vs-full-text">基于词项与基于全文</h3>
<div class="paragraph">
<p>所有查询会或多或少的执行相关度计算，但不是所有查询都有分析阶段。和一些特殊的完全不会对文本进行操作的查询（如 <code>bool</code> 或 <code>function_score</code> ）不同，文本查询可以划分成两大家族：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">基于词项的查询</dt>
<dd>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>如 <code>term</code> 或 <code>fuzzy</code> 这样的底层查询不需要分析阶段，它们对单个词项进行操作。用 <code>term</code> 查询词项 <code>Foo</code> 只要在倒排索引中查找 <em>准确词项</em> ，并且用 TF/IDF 算法为每个包含该词项的文档计算相关度评分 <code>_score</code> 。</p>
</div>
<div class="paragraph">
<p>记住 <code>term</code> 查询只对倒排索引的词项精确匹配，这点很重要，它不会对词的多样性进行处理（如， <code>foo</code> 或 <code>FOO</code> ）。这里，无须考虑词项是如何存入索引的。如果是将 <code>["Foo","Bar"]</code> 索引存入一个不分析的（ <code>not_analyzed</code> ）包含精确值的字段，或者将 <code>Foo Bar</code> 索引到一个带有 <code>whitespace</code> 空格分析器的字段，两者的结果都会是在倒排索引中有 <code>Foo</code> 和 <code>Bar</code> 这两个词。</p>
</div>
</div>
</div>
</dd>
<dt class="hdlist1">基于全文的查询</dt>
<dd>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>像 <code>match</code> 或 <code>query_string</code> 这样的查询是高层查询，它们了解字段映射的信息：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>如果查询 <code>日期（date）</code> 或 <code>整数（integer）</code> 字段，它们会将查询字符串分别作为日期或整数对待。</p>
</li>
<li>
<p>如果查询一个（ <code>not_analyzed</code> ）未分析的精确值字符串字段，它们会将整个查询字符串作为单个词项对待。</p>
</li>
<li>
<p>但如果要查询一个（ <code>analyzed</code> ）已分析的全文字段，它们会先将查询字符串传递到一个合适的分析器，然后生成一个供查询的词项列表。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>一旦组成了词项列表，这个查询会对每个词项逐一执行底层的查询，再将结果合并，然后为每个文档生成一个最终的相关度评分。</p>
</div>
<div class="paragraph">
<p>我们将会在随后章节中详细讨论这个过程。</p>
</div>
</div>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>我们很少直接使用基于词项的搜索，通常情况下都是对全文进行查询，而非单个词项，这只需要简单的执行一个高层全文查询（进而在高层查询内部会以基于词项的底层查询完成搜索）。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>当我们想要查询一个具有精确值的 <code>not_analyzed</code> 未分析字段之前，需要考虑，是否真的采用评分查询，或者非评分查询会更好。</p>
</div>
<div class="paragraph">
<p>单词项查询通常可以用是、非这种二元问题表示，所以更适合用过滤，而且这样做可以有效利用<a href="#filter-caching">缓存</a>：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_search
{
    "query": {
        "constant_score": {
            "filter": {
                "term": { "gender": "female" }
            }
        }
    }
}</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="match-query">匹配查询</h3>
<div class="paragraph">
<p>匹配查询 <code>match</code> 是个 <em>核心</em> 查询。无论需要查询什么字段， <code>match</code> 查询都应该会是首选的查询方式。它是一个高级 <em>全文查询</em> ，这表示它既能处理全文字段，又能处理精确字段。</p>
</div>
<div class="paragraph">
<p>这就是说， <code>match</code> 查询主要的应用场景就是进行全文搜索，我们以下面一个简单例子来说明全文搜索是如何工作的：</p>
</div>
<div class="sect3">
<h4 id="match-test-data">索引一些数据</h4>
<div class="paragraph">
<p>首先，我们使用 <a href="#bulk"><code>bulk</code> API</a> 创建一些新的文档和索引：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">DELETE /my_index <b class="conum">(1)</b>

PUT /my_index
{ "settings": { "number_of_shards": 1 }} <b class="conum">(2)</b>

POST /my_index/my_type/_bulk
{ "index": { "_id": 1 }}
{ "title": "The quick brown fox" }
{ "index": { "_id": 2 }}
{ "title": "The quick brown fox jumps over the lazy dog" }
{ "index": { "_id": 3 }}
{ "title": "The quick brown fox jumps over the quick dog" }
{ "index": { "_id": 4 }}
{ "title": "Brown fox brown dog" }</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>删除已有的索引。</p>
</li>
<li>
<p>稍后，我们会在 <a href="#relevance-is-broken">被破坏的相关性！</a> 中解释只为这个索引分配一个主分片的原因。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_单个词查询">单个词查询</h4>
<div class="paragraph">
<p>我们用第一个示例来解释使用 <code>match</code> 查询搜索全文字段中的单个词：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
    "query": {
        "match": {
            "title": "QUICK!"
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Elasticsearch 执行上面这个 <code>match</code> 查询的步骤是：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>检查字段类型</em> 。</p>
<div class="paragraph">
<p>标题 <code>title</code> 字段是一个 <code>string</code> 类型（ <code>analyzed</code> ）已分析的全文字段，这意味着查询字符串本身也应该被分析。</p>
</div>
</li>
<li>
<p><em>分析查询字符串</em> 。</p>
<div class="paragraph">
<p>将查询的字符串 <code>QUICK!</code> 传入标准分析器中，输出的结果是单个项 <code>quick</code> 。因为只有一个单词项，所以 <code>match</code> 查询执行的是单个底层 <code>term</code> 查询。</p>
</div>
</li>
<li>
<p><em>查找匹配文档</em> 。</p>
<div class="paragraph">
<p>用 <code>term</code> 查询在倒排索引中查找 <code>quick</code> 然后获取一组包含该项的文档，本例的结果是文档：1、2 和 3 。</p>
</div>
</li>
<li>
<p><em>为每个文档评分</em> 。</p>
<div class="paragraph">
<p>用 <code>term</code> 查询计算每个文档相关度评分 <code>_score</code> ，这是种将词频（term frequency，即词 <code>quick</code> 在相关文档的 <code>title</code> 字段中出现的频率）和反向文档频率（inverse document frequency，即词 <code>quick</code> 在所有文档的 <code>title</code> 字段中出现的频率），以及字段的长度（即字段越短相关度越高）相结合的计算方式。参见 <a href="#relevance-intro">相关性的介绍</a> 。</p>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>这个过程给我们以下（经缩减）结果：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">"hits": [
 {
    "_id":      "1",
    "_score":   0.5, <b class="conum">(1)</b>
    "_source": {
       "title": "The quick brown fox"
    }
 },
 {
    "_id":      "3",
    "_score":   0.44194174, <b class="conum">(2)</b>
    "_source": {
       "title": "The quick brown fox jumps over the quick dog"
    }
 },
 {
    "_id":      "2",
    "_score":   0.3125, <b class="conum">(2)</b>
    "_source": {
       "title": "The quick brown fox jumps over the lazy dog"
    }
 }
]</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>文档 1 最相关，因为它的 <code>title</code> 字段更短，即 <code>quick</code> 占据内容的一大部分。</p>
</li>
<li>
<p>文档 3 比 文档 2 更具相关性，因为在文档 2 中 <code>quick</code> 出现了两次。</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="match-multi-word">多词查询</h3>
<div class="paragraph">
<p>如果我们一次只能搜索一个词，那么全文搜索就会不太灵活，幸运的是 <code>match</code> 查询让多词查询变得简单：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
    "query": {
        "match": {
            "title": "BROWN DOG!"
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>上面这个查询返回所有四个文档：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id":      "4",
        "_score":   0.73185337, <b class="conum">(1)</b>
        "_source": {
           "title": "Brown fox brown dog"
        }
     },
     {
        "_id":      "2",
        "_score":   0.47486103, <b class="conum">(2)</b>
        "_source": {
           "title": "The quick brown fox jumps over the lazy dog"
        }
     },
     {
        "_id":      "3",
        "_score":   0.47486103, <b class="conum">(2)</b>
        "_source": {
           "title": "The quick brown fox jumps over the quick dog"
        }
     },
     {
        "_id":      "1",
        "_score":   0.11914785, <b class="conum">(3)</b>
        "_source": {
           "title": "The quick brown fox"
        }
     }
  ]
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>文档 4 最相关，因为它包含词 <code>"brown"</code> 两次以及 <code>"dog"</code> 一次。</p>
</li>
<li>
<p>文档 2、3 同时包含 <code>brown</code> 和 <code>dog</code> 各一次，而且它们 <code>title</code> 字段的长度相同，所以具有相同的评分。</p>
</li>
<li>
<p>文档 1 也能匹配，尽管它只有 <code>brown</code> 没有 <code>dog</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>因为 <code>match</code> 查询必须查找两个词（ <code>["brown","dog"]</code> ），它在内部实际上先执行两次 <code>term</code> 查询，然后将两次查询的结果合并作为最终结果输出。为了做到这点，它将两个 <code>term</code> 查询包入一个 <code>bool</code> 查询中，详细信息见 <a href="#bool-query">布尔查询</a>。</p>
</div>
<div class="paragraph">
<p>以上示例告诉我们一个重要信息：即任何文档只要 <code>title</code> 字段里包含 <em>指定词项中的至少一个词</em> 就能匹配，被匹配的词项越多，文档就越相关。</p>
</div>
<div class="sect3">
<h4 id="match-improving-precision">提高精度</h4>
<div class="paragraph">
<p>用 <em>任意</em> 查询词项匹配文档可能会导致结果中出现不相关的长尾。这是种散弹式搜索。可能我们只想搜索包含 <em>所有</em> 词项的文档，也就是说，不去匹配 <code>brown OR dog</code> ，而通过匹配 <code>brown AND dog</code> 找到所有文档。</p>
</div>
<div class="paragraph">
<p><code>match</code> 查询还可以接受 <code>operator</code> 操作符作为输入参数，默认情况下该操作符是 <code>or</code> 。我们可以将它修改成 <code>and</code> 让所有指定词项都必须匹配：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
    "query": {
        "match": {
            "title": {      <b class="conum">(1)</b>
                "query":    "BROWN DOG!",
                "operator": "and"
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>match</code> 查询的结构需要做稍许调整才能使用 <code>operator</code> 操作符参数。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这个查询可以把文档 1 排除在外，因为它只包含两个词项中的一个。</p>
</div>
</div>
<div class="sect3">
<h4 id="match-precision">控制精度</h4>
<div class="paragraph">
<p>在 <em>所有</em> 与 <em>任意</em> 间二选一有点过于非黑即白。如果用户给定 5 个查询词项，想查找只包含其中 4 个的文档，该如何处理？将 <code>operator</code> 操作符参数设置成 <code>and</code> 只会将此文档排除。</p>
</div>
<div class="paragraph">
<p>有时候这正是我们期望的，但在全文搜索的大多数应用场景下，我们既想包含那些可能相关的文档，同时又排除那些不太相关的。换句话说，我们想要处于中间某种结果。</p>
</div>
<div class="paragraph">
<p><code>match</code> 查询支持 <code>minimum_should_match</code> 最小匹配参数，这让我们可以指定必须匹配的词项数用来表示一个文档是否相关。我们可以将其设置为某个具体数字，更常用的做法是将其设置为一个百分数，因为我们无法控制用户搜索时输入的单词数量：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
  "query": {
    "match": {
      "title": {
        "query":                "quick brown dog",
        "minimum_should_match": "75%"
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>当给定百分比的时候， <code>minimum_should_match</code> 会做合适的事情：在之前三词项的示例中， <code>75%</code> 会自动被截断成 <code>66.6%</code> ，即三个里面两个词。无论这个值设置成什么，至少包含一个词项的文档才会被认为是匹配的。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>参数 <code>minimum_should_match</code> 的设置非常灵活，可以根据用户输入词项的数目应用不同的规则。完整的信息参考文档
{ref}/query-dsl-minimum-should-match.html#query-dsl-minimum-should-match</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>为了完全理解 <code>match</code> 是如何处理多词查询的，我们就需要查看如何使用 <code>bool</code> 查询将多个查询条件组合在一起。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="bool-query">组合查询</h3>
<div class="paragraph">
<p>在 <a href="#combining-filters">组合过滤器</a> 中，我们讨论过如何使用 <code>bool</code> 过滤器通过 <code>and</code> 、 <code>or</code> 和 <code>not</code> 逻辑组合将多个过滤器进行组合。在查询中， <code>bool</code> 查询有类似的功能，只有一个重要的区别。</p>
</div>
<div class="paragraph">
<p>过滤器做二元判断：文档是否应该出现在结果中？但查询更精妙，它除了决定一个文档是否应该被包括在结果中，还会计算文档的 <em>相关程度</em> 。</p>
</div>
<div class="paragraph">
<p>与过滤器一样， <code>bool</code> 查询也可以接受 <code>must</code> 、 <code>must_not</code> 和 <code>should</code> 参数下的多个查询语句。比如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
  "query": {
    "bool": {
      "must":     { "match": { "title": "quick" }},
      "must_not": { "match": { "title": "lazy"  }},
      "should": [
                  { "match": { "title": "brown" }},
                  { "match": { "title": "dog"   }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>以上的查询结果返回 <code>title</code> 字段包含词项 <code>quick</code> 但不包含 <code>lazy</code> 的任意文档。目前为止，这与 <code>bool</code> 过滤器的工作方式非常相似。</p>
</div>
<div class="paragraph">
<p>区别就在于两个 <code>should</code> 语句，也就是说：一个文档不必包含 <code>brown</code> 或 <code>dog</code> 这两个词项，但如果一旦包含，我们就认为它们 <em>更相关</em> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id":      "3",
        "_score":   0.70134366, <b class="conum">(1)</b>
        "_source": {
           "title": "The quick brown fox jumps over the quick dog"
        }
     },
     {
        "_id":      "1",
        "_score":   0.3312608,
        "_source": {
           "title": "The quick brown fox"
        }
     }
  ]
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>文档 3 会比文档 1 有更高评分是因为它同时包含 <code>brown</code> 和 <code>dog</code> 。</p>
</li>
</ol>
</div>
<div class="sect3">
<h4 id="_评分计算">评分计算</h4>
<div class="paragraph">
<p><code>bool</code> 查询会为每个文档计算相关度评分 <code>_score</code> ，再将所有匹配的 <code>must</code> 和 <code>should</code> 语句的分数 <code>_score</code> 求和，最后除以 <code>must</code> 和 <code>should</code> 语句的总数。</p>
</div>
<div class="paragraph">
<p><code>must_not</code> 语句不会影响评分；它的作用只是将不相关的文档排除。</p>
</div>
</div>
<div class="sect3">
<h4 id="_控制精度">控制精度</h4>
<div class="paragraph">
<p>所有 <code>must</code> 语句必须匹配，所有 <code>must_not</code> 语句都必须不匹配，但有多少 <code>should</code> 语句应该匹配呢？默认情况下，没有 <code>should</code> 语句是必须匹配的，只有一个例外：那就是当没有 <code>must</code> 语句的时候，至少有一个 <code>should</code> 语句必须匹配。</p>
</div>
<div class="paragraph">
<p>就像我们能控制 <a href="#match-precision"><code>match</code> 查询的精度</a> 一样，我们可以通过 <code>minimum_should_match</code> 参数控制需要匹配的 <code>should</code> 语句的数量，它既可以是一个绝对的数字，又可以是个百分比：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { "title": "brown" }},
        { "match": { "title": "fox"   }},
        { "match": { "title": "dog"   }}
      ],
      "minimum_should_match": 2 <b class="conum">(1)</b>
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>这也可以用百分比表示。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这个查询结果会将所有满足以下条件的文档返回： <code>title</code> 字段包含 <code>"brown"
AND "fox"</code> 、 <code>"brown" AND "dog"</code> 或 <code>"fox" AND "dog"</code> 。如果有文档包含所有三个条件，它会比只包含两个的文档更相关。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_how_match_uses_bool">如何使用布尔匹配</h3>
<div class="paragraph">
<p>目前为止，可能已经意识到<a href="#match-multi-word">多词 <code>match</code> 查询</a>只是简单地将生成的 <code>term</code> 查询包裹在一个 <code>bool</code> 查询中。如果使用默认的 <code>or</code> 操作符，每个 <code>term</code> 查询都被当作 <code>should</code> 语句，这样就要求必须至少匹配一条语句。以下两个查询是等价的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "match": { "title": "brown fox"}
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "bool": {
    "should": [
      { "term": { "title": "brown" }},
      { "term": { "title": "fox"   }}
    ]
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果使用 <code>and</code> 操作符，所有的 <code>term</code> 查询都被当作 <code>must</code> 语句，所以 <em>所有（all）</em> 语句都必须匹配。以下两个查询是等价的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "match": {
        "title": {
            "query":    "brown fox",
            "operator": "and"
        }
    }
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "bool": {
    "must": [
      { "term": { "title": "brown" }},
      { "term": { "title": "fox"   }}
    ]
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果指定参数 <code>minimum_should_match</code> ，它可以通过 <code>bool</code> 查询直接传递，使以下两个查询等价：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "match": {
        "title": {
            "query":                "quick brown fox",
            "minimum_should_match": "75%"
        }
    }
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "bool": {
    "should": [
      { "term": { "title": "brown" }},
      { "term": { "title": "fox"   }},
      { "term": { "title": "quick" }}
    ],
    "minimum_should_match": 2 <b class="conum">(1)</b>
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>因为只有三条语句，<code>match</code> 查询的参数 <code>minimum_should_match</code> 值 75% 会被截断成 <code>2</code> 。即三条 <code>should</code> 语句中至少有两条必须匹配。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>当然，我们通常将这些查询用 <code>match</code> 查询来表示，但是如果了解 <code>match</code> 内部的工作原理，我们就能根据自己的需要来控制查询过程。有些时候单个 <code>match</code> 查询无法满足需求，比如为某些查询条件分配更高的权重。我们会在下一小节中看到这个例子。</p>
</div>
</div>
<div class="sect2">
<h3 id="_boosting_query_clauses">查询语句提升权重</h3>
<div class="paragraph">
<p>当然 <code>bool</code> 查询不仅限于组合简单的单个词 <code>match</code> 查询，它可以组合任意其他的查询，以及其他 <code>bool</code> 查询。普遍的用法是通过汇总多个独立查询的分数，从而达到为每个文档微调其相关度评分 <code>_score</code> 的目的。</p>
</div>
<div class="paragraph">
<p>假设想要查询关于 “full-text search（全文搜索）” 的文档，但我们希望为提及 “Elasticsearch” 或 “Lucene” 的文档给予更高的 <em>权重</em> ，这里 <em>更高权重</em> 是指如果文档中出现 “Elasticsearch” 或 “Lucene” ，它们会比没有的出现这些词的文档获得更高的相关度评分 <code>_score</code> ，也就是说，它们会出现在结果集的更上面。</p>
</div>
<div class="paragraph">
<p>一个简单的 <code>bool</code> <em>查询</em> 允许我们写出如下这种非常复杂的逻辑：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_search
{
    "query": {
        "bool": {
            "must": {
                "match": {
                    "content": { <b class="conum">(1)</b>
                        "query":    "full text search",
                        "operator": "and"
                    }
                }
            },
            "should": [ <b class="conum">(2)</b>
                { "match": { "content": "Elasticsearch" }},
                { "match": { "content": "Lucene"        }}
            ]
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>content</code> 字段必须包含 <code>full</code> 、 <code>text</code> 和 <code>search</code> 所有三个词。</p>
</li>
<li>
<p>如果 <code>content</code> 字段也包含 <code>Elasticsearch</code> 或 <code>Lucene</code> ，文档会获得更高的评分 <code>_score</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><code>should</code> 语句匹配得越多表示文档的相关度越高。目前为止还挺好。</p>
</div>
<div class="paragraph">
<p>但是如果我们想让包含 <code>Lucene</code> 的有更高的权重，并且包含 <code>Elasticsearch</code> 的语句比 <code>Lucene</code> 的权重更高，该如何处理?</p>
</div>
<div class="paragraph">
<p>我们可以通过指定 <code>boost</code> 来控制任何查询语句的相对的权重， <code>boost</code> 的默认值为 <code>1</code> ，大于 <code>1</code> 会提升一个语句的相对权重。所以下面重写之前的查询：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_search
{
    "query": {
        "bool": {
            "must": {
                "match": {  <b class="conum">(1)</b>
                    "content": {
                        "query":    "full text search",
                        "operator": "and"
                    }
                }
            },
            "should": [
                { "match": {
                    "content": {
                        "query": "Elasticsearch",
                        "boost": 3 <b class="conum">(2)</b>
                    }
                }},
                { "match": {
                    "content": {
                        "query": "Lucene",
                        "boost": 2 <b class="conum">(3)</b>
                    }
                }}
            ]
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>这些语句使用默认的 <code>boost</code> 值 <code>1</code> 。</p>
</li>
<li>
<p>这条语句更为重要，因为它有最高的 <code>boost</code> 值。</p>
</li>
<li>
<p>这条语句比使用默认值的更重要，但它的重要性不及 <code>Elasticsearch</code> 语句。</p>
</li>
</ol>
</div>
<div id="boost-normalization" class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p><code>boost</code> 参数被用来提升一个语句的相对权重（ <code>boost</code> 值大于 <code>1</code> ）或降低相对权重（ <code>boost</code> 值处于 <code>0</code> 到 <code>1</code> 之间），但是这种提升或降低并不是线性的，换句话说，如果一个 <code>boost</code> 值为 <code>2</code> ，并不能获得两倍的评分 <code>_score</code> 。</p>
</div>
<div class="paragraph">
<p>相反，新的评分 <code><em>score</code> 会在应用权重提升之后被 _归一化</em> ，每种类型的查询都有自己的归一算法，细节超出了本书的范围，所以不作介绍。简单的说，更高的 <code>boost</code> 值为我们带来更高的评分 <code>_score</code> 。</p>
</div>
<div class="paragraph">
<p>如果不基于 TF/IDF 要实现自己的评分模型，我们就需要对权重提升的过程能有更多控制，可以使用 <a href="#function-score-query"><code>function_score</code> 查询</a>操纵一个文档的权重提升方式而跳过归一化这一步骤。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>更多的组合查询方式会在下章<a href="#multi-field-search">多字段搜索</a>中介绍，但在此之前，让我们先看另外一个重要的查询特性：文本分析（text analysis）。</p>
</div>
</div>
<div class="sect2">
<h3 id="_controlling_analysis">控制分析</h3>
<div class="paragraph">
<p>查询只能查找倒排索引表中真实存在的项，所以保证文档在索引时与查询字符串在搜索时应用相同的分析过程非常重要，这样查询的项才能够匹配倒排索引中的项。</p>
</div>
<div class="paragraph">
<p>尽管是在说 <em>文档</em> ，不过分析器可以由每个字段决定。每个字段都可以有不同的分析器，既可以通过配置为字段指定分析器，也可以使用更高层的类型（type）、索引（index）或节点（node）的默认配置。在索引时，一个字段值是根据配置或默认分析器分析的。</p>
</div>
<div class="paragraph">
<p>例如为 <code>my_index</code> 新增一个字段：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index/_mapping/my_type
{
    "my_type": {
        "properties": {
            "english_title": {
                "type":     "string",
                "analyzer": "english"
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>现在我们就可以通过使用 <code>analyze</code> API 来分析单词 <code>Foxes</code> ，进而比较 <code>english_title</code> 字段和 <code>title</code> 字段在索引时的分析结果：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/_analyze
{
  "field": "my_type.title",   <b class="conum">(1)</b>
  "text": "Foxes"
}

GET /my_index/_analyze
{
  "field": "my_type.english_title",   <b class="conum">(2)</b>
  "text": "Foxes"
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>字段 <code>title</code> ，使用默认的 <code>standard</code> 标准分析器，返回词项 <code>foxes</code> 。</p>
</li>
<li>
<p>字段 <code>english_title</code> ，使用 <code>english</code> 英语分析器，返回词项 <code>fox</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这意味着，如果使用底层 <code>term</code> 查询精确项 <code>fox</code> 时， <code>english_title</code> 字段会匹配但 <code>title</code> 字段不会。</p>
</div>
<div class="paragraph">
<p>如同 <code>match</code> 查询这样的高层查询知道字段映射的关系，能为每个被查询的字段应用正确的分析器。可以使用  <code>validate-query</code> API 查看这个行为：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_validate/query?explain
{
    "query": {
        "bool": {
            "should": [
                { "match": { "title":         "Foxes"}},
                { "match": { "english_title": "Foxes"}}
            ]
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>返回语句的 <code>explanation</code> 结果：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>(title:foxes english_title:fox)</pre>
</div>
</div>
<div class="paragraph">
<p><code>match</code> 查询为每个字段使用合适的分析器，以保证它在寻找每个项时都为该字段使用正确的格式。</p>
</div>
<div class="sect3">
<h4 id="_默认分析器">默认分析器</h4>
<div class="paragraph">
<p>虽然我们可以在字段层级指定分析器，但是如果该层级没有指定任何的分析器，那么我们如何能确定这个字段使用的是哪个分析器呢？</p>
</div>
<div class="paragraph">
<p>分析器可以从三个层面进行定义：按字段（per-field）、按索引（per-index）或全局缺省（global default）。Elasticsearch 会按照以下顺序依次处理，直到它找到能够使用的分析器。索引时的顺序如下：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>字段映射里定义的 <code>analyzer</code> ，否则</p>
</li>
<li>
<p>索引设置中名为 <code>default</code> 的分析器，默认为</p>
</li>
<li>
<p><code>standard</code> 标准分析器</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>在搜索时，顺序有些许不同：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>查询自己定义的  <code>analyzer</code> ，否则</p>
</li>
<li>
<p>字段映射里定义的 <code>analyzer</code> ，否则</p>
</li>
<li>
<p>索引设置中名为 <code>default</code> 的分析器，默认为</p>
</li>
<li>
<p><code>standard</code> 标准分析器</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>有时，在索引时和搜索时使用不同的分析器是合理的。我们可能要想为同义词建索引（例如，所有 <code>quick</code> 出现的地方，同时也为 <code>fast</code> 、 <code>rapid</code> 和 <code>speedy</code> 创建索引）。但在搜索时，我们不需要搜索所有的同义词，取而代之的是寻找用户输入的单词是否是 <code>quick</code> 、 <code>fast</code> 、 <code>rapid</code> 或 <code>speedy</code> 。</p>
</div>
<div class="paragraph">
<p>为了区分，Elasticsearch 也支持一个可选的 <code>search_analyzer</code> 映射，它仅会应用于搜索时（ <code>analyzer</code> 还用于索引时）。还有一个等价的 <code>default_search</code> 映射，用以指定索引层的默认配置。</p>
</div>
<div class="paragraph">
<p>如果考虑到这些额外参数，一个搜索时的 <em>完整</em> 顺序会是下面这样：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>查询自己定义的  <code>analyzer</code> ，否则</p>
</li>
<li>
<p>字段映射里定义的 <code>search_analyzer</code> ，否则</p>
</li>
<li>
<p>字段映射里定义的 <code>analyzer</code> ，否则</p>
</li>
<li>
<p>索引设置中名为 <code>default_search</code> 的分析器，默认为</p>
</li>
<li>
<p>索引设置中名为 <code>default</code> 的分析器，默认为</p>
</li>
<li>
<p><code>standard</code> 标准分析器</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_分析器配置实践">分析器配置实践</h4>
<div class="paragraph">
<p>就可以配置分析器地方的数量而言是十分惊人的，但是实际非常简单。</p>
</div>
<div class="sect4">
<h5 id="_保持简单">保持简单</h5>
<div class="paragraph">
<p>多数情况下，会提前知道文档会包括哪些字段。最简单的途径就是在创建索引或者增加类型映射时，为每个全文字段设置分析器。这种方式尽管有点麻烦，但是它让我们可以清楚的看到每个字段每个分析器是如何设置的。</p>
</div>
<div class="paragraph">
<p>通常，多数字符串字段都是 <code>not_analyzed</code> 精确值字段，比如标签（tag）或枚举（enum），而且更多的全文字段会使用默认的 <code>standard</code> 分析器或 <code>english</code> 或其他某种语言的分析器。这样只需要为少数一两个字段指定自定义分析：或许标题 <code>title</code> 字段需要以支持 <em>输入即查找（find-as-you-type）</em> 的方式进行索引。</p>
</div>
<div class="paragraph">
<p>可以在索引级别设置中，为绝大部分的字段设置你想指定的 <code>default</code> 默认分析器。然后在字段级别设置中，对某一两个字段配置需要指定的分析器。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>对于和时间相关的日志数据，通常的做法是每天自行创建索引，由于这种方式不是从头创建的索引，仍然可以用
{ref}/indices-templates.html[索引模板（Index Template）]
为新建的索引指定配置和映射。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="relevance-is-broken">被破坏的相关度！</h3>
<div class="paragraph">
<p>在讨论更复杂的 <a href="#multi-field-search">多字段搜索</a> 之前，让我们先快速解释一下为什么只在主分片上 <a href="#match-test-data">创建测试索引</a> 。</p>
</div>
<div class="paragraph">
<p>用户会时不时的抱怨无法按相关度排序并提供简短的重现步骤：用户索引了一些文档，运行一个简单的查询，然后发现明显低相关度的结果出现在高相关度结果之上。</p>
</div>
<div class="paragraph">
<p>为了理解为什么会这样，可以设想，我们在两个主分片上创建了索引和总共 10 个文档，其中 6 个文档有单词 <code>foo</code> 。可能是分片 1 有其中 3 个 <code>foo</code> 文档，而分片 2 有其中另外 3 个文档，换句话说，所有文档是均匀分布存储的。</p>
</div>
<div class="paragraph">
<p>在 <a href="#relevance-intro">什么是相关度？</a>中，我们描述了 Elasticsearch 默认使用的相似度算法，这个算法叫做 <em>词频/逆向文档频率</em> 或 TF/IDF 。词频是计算某个词在当前被查询文档里某个字段中出现的频率，出现的频率越高，文档越相关。 <em>逆向文档频率</em> 将 <em>某个词在索引内所有文档出现的百分数</em> 考虑在内，出现的频率越高，它的权重就越低。</p>
</div>
<div class="paragraph">
<p>但是由于性能原因， Elasticsearch 不会计算索引内所有文档的 IDF 。相反，每个分片会根据 <em>该分片</em> 内的所有文档计算一个本地 IDF 。</p>
</div>
<div class="paragraph">
<p>因为文档是均匀分布存储的，两个分片的 IDF 是相同的。相反，设想如果有 5 个 <code>foo</code> 文档存于分片 1 ，而第 6 个文档存于分片 2 ，在这种场景下， <code>foo</code> 在一个分片里非常普通（所以不那么重要），但是在另一个分片里非常出现很少（所以会显得更重要）。这些 IDF 之间的差异会导致不正确的结果。</p>
</div>
<div class="paragraph">
<p>在实际应用中，这并不是一个问题，本地和全局的 IDF 的差异会随着索引里文档数的增多渐渐消失，在真实世界的数据量下，局部的 IDF 会被迅速均化，所以上述问题并不是相关度被破坏所导致的，而是由于数据太少。</p>
</div>
<div class="paragraph">
<p>为了测试，我们可以通过两种方式解决这个问题。第一种是只在主分片上创建索引，正如 <a href="#match-query"><code>match</code> 查询</a> 里介绍的那样，如果只有一个分片，那么本地的 IDF <em>就是</em> 全局的 IDF。</p>
</div>
<div class="paragraph">
<p>第二个方式就是在搜索请求后添加 <code>?search_type=dfs_query_then_fetch</code> ， <code>dfs</code> 是指 <em>分布式频率搜索（Distributed Frequency Search）</em> ， 它告诉 Elasticsearch ，先分别获得每个分片本地的 IDF ，然后根据结果再计算整个索引的全局 IDF 。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
不要在生产环境上使用 <code>dfs_query_then_fetch</code> 。完全没有必要。只要有足够的数据就能保证词频是均匀分布的。没有理由给每个查询额外加上 DFS 这步。
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="multi-field-search">多字段搜索</h2>
<div class="sectionbody">
<div class="paragraph">
<p>查询很少是简单一句话的  <code>match</code>  匹配查询。通常我们需要用相同或不同的字符串查询一个或多个字段，也就是说，需要对多个查询语句以及它们相关度评分进行合理的合并。</p>
</div>
<div class="paragraph">
<p>有时候或许我们正查找作者 Leo Tolstoy 写的一本名为 <em>War and Peace</em>（战争与和平）的书。或许我们正用 “minimum should match” （最少应该匹配）的方式在文档中对标题或页面内容进行搜索，或许我们正在搜索所有名字为 John Smith 的用户。</p>
</div>
<div class="paragraph">
<p>在本章，我们会介绍构造多语句搜索的工具及在特定场景下应该采用的解决方案。</p>
</div>
<div class="sect2">
<h3 id="multi-query-strings">多字符串查询</h3>
<div class="paragraph">
<p>最简单的多字段查询可以将搜索项映射到具体的字段。如果我们知道 <em>War and Peace</em> 是标题，Leo Tolstoy 是作者，很容易就能把两个条件用 <code>match</code> 语句表示，并将它们用 <a href="#bool-query"><code>bool</code> 查询</a> 组合起来：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { "title":  "War and Peace" }},
        { "match": { "author": "Leo Tolstoy"   }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>bool</code> 查询采取 <em>more-matches-is-better</em> 匹配越多越好的方式，所以每条 <code>match</code> 语句的评分结果会被加在一起，从而为每个文档提供最终的分数 <code>_score</code> 。能与两条语句同时匹配的文档比只与一条语句匹配的文档得分要高。</p>
</div>
<div class="paragraph">
<p>当然，并不是只能使用 <code>match</code> 语句：可以用 <code>bool</code> 查询来包裹组合任意其他类型的查询，甚至包括其他的 <code>bool</code> 查询。我们可以在上面的示例中添加一条语句来指定译者版本的偏好：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { "title":  "War and Peace" }},
        { "match": { "author": "Leo Tolstoy"   }},
        { "bool":  {
          "should": [
            { "match": { "translator": "Constance Garnett" }},
            { "match": { "translator": "Louise Maude"      }}
          ]
        }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>为什么将译者条件语句放入另一个独立的 <code>bool</code> 查询中呢？所有的四个 <code>match</code> 查询都是 <code>should</code> 语句，所以为什么不将 translator 语句与其他如 title 、 author 这样的语句放在同一层呢？</p>
</div>
<div class="paragraph">
<p>答案在于评分的计算方式。 <code>bool</code> 查询运行每个 <code>match</code> 查询，再把评分加在一起，然后将结果与所有匹配的语句数量相乘，最后除以所有的语句数量。处于同一层的每条语句具有相同的权重。在前面这个例子中，包含 translator 语句的 <code>bool</code> 查询，只占总评分的三分之一。如果将 translator 语句与 title 和 author 两条语句放入同一层，那么 title 和 author 语句只贡献四分之一评分。</p>
</div>
<div class="sect3">
<h4 id="prioritising-clauses">语句的优先级</h4>
<div class="paragraph">
<p>前例中每条语句贡献三分之一评分的这种方式可能并不是我们想要的，我们可能对 title 和 author 两条语句更感兴趣，这样就需要调整查询，使 title 和 author 语句相对来说更重要。</p>
</div>
<div class="paragraph">
<p>在武器库中，最容易使用的就是 <code>boost</code> 参数。为了提升 <code>title</code> 和 <code>author</code> 字段的权重，为它们分配的 <code>boost</code> 值大于 <code>1</code> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { <b class="conum">(1)</b>
            "title":  {
              "query": "War and Peace",
              "boost": 2
        }}},
        { "match": { <b class="conum">(1)</b>
            "author":  {
              "query": "Leo Tolstoy",
              "boost": 2
        }}},
        { "bool":  { <b class="conum">(2)</b>
            "should": [
              { "match": { "translator": "Constance Garnett" }},
              { "match": { "translator": "Louise Maude"      }}
            ]
        }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>title</code> 和 <code>author</code> 语句的 <code>boost</code> 值为 <code>2</code> 。</p>
</li>
<li>
<p>嵌套 <code>bool</code> 语句默认的 <code>boost</code> 值为 <code>1</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>要获取 <code>boost</code> 参数 “最佳” 值，较为简单的方式就是不断试错：设定 <code>boost</code> 值，运行测试查询，如此反复。 <code>boost</code> 值比较合理的区间处于 <code>1</code> 到 <code>10</code> 之间，当然也有可能是 <code>15</code> 。如果为 <code>boost</code> 指定比这更高的值，将不会对最终的评分结果产生更大影响，因为评分是被 <a href="#boost-normalization">归一化的（normalized）</a> 。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_single_query_string">单字符串查询</h3>
<div class="paragraph">
<p><code>bool</code> 查询是多语句查询的主干。它的适用场景很多，特别是当需要将不同查询字符串映射到不同字段的时候。</p>
</div>
<div class="paragraph">
<p>问题在于，目前有些用户期望将所有的搜索项堆积到单个字段中，并期望应用程序能为他们提供正确的结果。有意思的是多字段搜索的表单通常被称为 <em>高级查询 （Advanced Search）</em> —— 只是因为它对用户而言是高级的，而多字段搜索的实现却非常简单。</p>
</div>
<div class="paragraph">
<p>对于多词（multiword）、多字段（multifield）查询来说，不存在简单的 <em>万能</em> 方案。为了获得最好结果，需要 <em>了解我们的数据</em> ，并了解如何使用合适的工具。</p>
</div>
<div class="sect3">
<h4 id="know-your-data">了解我们的数据</h4>
<div class="paragraph">
<p>当用户输入了单个字符串查询的时候，通常会遇到以下三种情形：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">最佳字段</dt>
<dd>
<p>当搜索词语具体概念的时候，比如 “brown fox” ，词组比各自独立的单词更有意义。像 <code>title</code> 和 <code>body</code> 这样的字段，尽管它们之间是相关的，但同时又彼此相互竞争。文档在 <em>相同字段</em> 中包含的词越多越好，评分也来自于 <em>最匹配字段</em> 。</p>
</dd>
<dt class="hdlist1">多数字段</dt>
<dd>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>为了对相关度进行微调，常用的一个技术就是将相同的数据索引到不同的字段，它们各自具有独立的分析链。</p>
</div>
<div class="paragraph">
<p>主字段可能包括它们的词源、同义词以及 <em>变音词</em> 或口音词，被用来匹配尽可能多的文档。</p>
</div>
<div class="paragraph">
<p>相同的文本被索引到其他字段，以提供更精确的匹配。一个字段可以包括未经词干提取过的原词，另一个字段包括其他词源、口音，还有一个字段可以提供 <a href="#proximity-matching">词语相似性</a> 信息的瓦片词（shingles）。</p>
</div>
<div class="paragraph">
<p>其他字段是作为匹配每个文档时提高相关度评分的 <em>信号</em> ， <em>匹配字段越多</em> 则越好。</p>
</div>
</div>
</div>
</dd>
<dt class="hdlist1">混合字段</dt>
<dd>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p>对于某些实体，我们需要在多个字段中确定其信息，单个字段都只能作为整体的一部分：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Person： <code>first_name</code> 和 <code>last_name</code> （人：名和姓）</p>
</li>
<li>
<p>Book： <code>title</code> 、 <code>author</code> 和 <code>description</code> （书：标题、作者、描述）</p>
</li>
<li>
<p>Address： <code>street</code> 、 <code>city</code> 、 <code>country</code> 和 <code>postcode</code> （地址：街道、市、国家和邮政编码）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>在这种情况下，我们希望在 <em>任何</em> 这些列出的字段中找到尽可能多的词，这有如在一个大字段中进行搜索，这个大字段包括了所有列出的字段。</p>
</div>
</div>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>上述所有都是多词、多字段查询，但每个具体查询都要求使用不同策略。本章后面的部分，我们会依次介绍每个策略。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_best_fields">最佳字段</h3>
<div class="paragraph">
<p>假设有个网站允许用户搜索博客的内容，以下面两篇博客内容文档为例：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index/my_type/1
{
    "title": "Quick brown rabbits",
    "body":  "Brown rabbits are commonly seen."
}

PUT /my_index/my_type/2
{
    "title": "Keeping pets healthy",
    "body":  "My quick brown fox eats rabbits on a regular basis."
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>用户输入词组 “Brown fox” 然后点击搜索按钮。事先，我们并不知道用户的搜索项是会在 <code>title</code> 还是在 <code>body</code> 字段中被找到，但是，用户很有可能是想搜索相关的词组。用肉眼判断，文档 2 的匹配度更高，因为它同时包括要查找的两个词：</p>
</div>
<div class="paragraph">
<p>现在运行以下 <code>bool</code> 查询：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "query": {
        "bool": {
            "should": [
                { "match": { "title": "Brown fox" }},
                { "match": { "body":  "Brown fox" }}
            ]
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>但是我们发现查询的结果是文档 1 的评分更高：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id":      "1",
        "_score":   0.14809652,
        "_source": {
           "title": "Quick brown rabbits",
           "body":  "Brown rabbits are commonly seen."
        }
     },
     {
        "_id":      "2",
        "_score":   0.09256032,
        "_source": {
           "title": "Keeping pets healthy",
           "body":  "My quick brown fox eats rabbits on a regular basis."
        }
     }
  ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>为了理解导致这样的原因，需要回想一下 <code>bool</code> 是如何计算评分的：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>它会执行 <code>should</code> 语句中的两个查询。</p>
</li>
<li>
<p>加和两个查询的评分。</p>
</li>
<li>
<p>乘以匹配语句的总数。</p>
</li>
<li>
<p>除以所有语句总数（这里为：2）。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>文档 1 的两个字段都包含 <code>brown</code> 这个词，所以两个 <code>match</code> 语句都能成功匹配并且有一个评分。文档 2 的 <code>body</code> 字段同时包含 <code>brown</code> 和 <code>fox</code> 这两个词，但 <code>title</code> 字段没有包含任何词。这样， <code>body</code> 查询结果中的高分，加上 <code>title</code> 查询中的 0 分，然后乘以二分之一，就得到比文档 1 更低的整体评分。</p>
</div>
<div class="paragraph">
<p>在本例中， <code>title</code> 和 <code>body</code> 字段是相互竞争的关系，所以就需要找到单个 <em>最佳匹配</em> 的字段。</p>
</div>
<div class="paragraph">
<p>如果不是简单将每个字段的评分结果加在一起，而是将 <em>最佳匹配</em> 字段的评分作为查询的整体评分，结果会怎样？这样返回的结果可能是： <em>同时</em> 包含 <code>brown</code> 和 <code>fox</code> 的单个字段比反复出现相同词语的多个不同字段有更高的相关度。</p>
</div>
<div class="sect3">
<h4 id="dis-max-query">dis_max 查询</h4>
<div class="paragraph">
<p>不使用 <code>bool</code> 查询，可以使用 <code>dis_max</code> 即分离 <em>最大化查询（Disjunction Max Query）</em> 。分离（Disjunction）的意思是 <em>或（or）</em> ，这与可以把结合（conjunction）理解成 <em>与（and）</em> 相对应。分离最大化查询（Disjunction Max Query）指的是： <em>将任何与任一查询匹配的文档作为结果返回，但只将最佳匹配的评分作为查询的评分结果返回</em> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "query": {
        "dis_max": {
            "queries": [
                { "match": { "title": "Brown fox" }},
                { "match": { "body":  "Brown fox" }}
            ]
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>得到我们想要的结果为：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id":      "2",
        "_score":   0.21509302,
        "_source": {
           "title": "Keeping pets healthy",
           "body":  "My quick brown fox eats rabbits on a regular basis."
        }
     },
     {
        "_id":      "1",
        "_score":   0.12713557,
        "_source": {
           "title": "Quick brown rabbits",
           "body":  "Brown rabbits are commonly seen."
        }
     }
  ]
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tuning_best_fields_queries">最佳字段查询调优</h3>
<div class="paragraph">
<p>当用户搜索 “quick pets” 时会发生什么呢？在前面的例子中，两个文档都包含词 <code>quick</code> ，但是只有文档 2 包含词 <code>pets</code> ，两个文档中都不具有同时包含 <em>两个词</em> 的 <em>相同字段</em> 。</p>
</div>
<div class="paragraph">
<p>如下，一个简单的 <code>dis_max</code> 查询会采用单个最佳匹配字段，而忽略其他的匹配：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "query": {
        "dis_max": {
            "queries": [
                { "match": { "title": "Quick pets" }},
                { "match": { "body":  "Quick pets" }}
            ]
        }
    }
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id": "1",
        "_score": 0.12713557, <b class="conum">(1)</b>
        "_source": {
           "title": "Quick brown rabbits",
           "body": "Brown rabbits are commonly seen."
        }
     },
     {
        "_id": "2",
        "_score": 0.12713557, <b class="conum">(1)</b>
        "_source": {
           "title": "Keeping pets healthy",
           "body": "My quick brown fox eats rabbits on a regular basis."
        }
     }
   ]
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>注意两个评分是完全相同的。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>我们可能期望同时匹配 <code>title</code> 和 <code>body</code> 字段的文档比只与一个字段匹配的文档的相关度更高，但事实并非如此，因为 <code>dis_max</code> 查询只会简单地使用 <em>单个</em> 最佳匹配语句的评分 <code>_score</code> 作为整体评分。</p>
</div>
<div class="sect3">
<h4 id="_tie_breaker_参数">tie_breaker 参数</h4>
<div class="paragraph">
<p>可以通过指定 <code>tie_breaker</code> 这个参数将其他匹配语句的评分也考虑其中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "query": {
        "dis_max": {
            "queries": [
                { "match": { "title": "Quick pets" }},
                { "match": { "body":  "Quick pets" }}
            ],
            "tie_breaker": 0.3
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>结果如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id": "2",
        "_score": 0.14757764, <b class="conum">(1)</b>
        "_source": {
           "title": "Keeping pets healthy",
           "body": "My quick brown fox eats rabbits on a regular basis."
        }
     },
     {
        "_id": "1",
        "_score": 0.124275915, <b class="conum">(1)</b>
        "_source": {
           "title": "Quick brown rabbits",
           "body": "Brown rabbits are commonly seen."
        }
     }
   ]
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>文档 2 的相关度比文档 1 略高。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><code>tie_breaker</code> 参数提供了一种 <code>dis_max</code> 和 <code>bool</code> 之间的折中选择，它的评分方式如下：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>获得最佳匹配语句的评分 <code>_score</code> 。</p>
</li>
<li>
<p>将其他匹配语句的评分结果与 <code>tie_breaker</code> 相乘。</p>
</li>
<li>
<p>对以上评分求和并规范化。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>有了 <code>tie_breaker</code> ，会考虑所有匹配语句，但最佳匹配语句依然占最终结果里的很大一部分。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p><code>tie_breaker</code> 可以是 <code>0</code> 到 <code>1</code> 之间的浮点数，其中 <code>0</code> 代表使用 <code>dis_max</code> 最佳匹配语句的普通逻辑， <code>1</code> 表示所有匹配语句同等重要。最佳的精确值需要根据数据与查询调试得出，但是合理值应该与零接近（处于 <code>0.1 - 0.4</code> 之间），这样就不会颠覆 <code>dis_max</code> 最佳匹配性质的根本。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="multi-match-query">multi_match 查询</h3>
<div class="paragraph">
<p><code>multi_match</code> 查询为能在多个字段上反复执行相同查询提供了一种便捷方式。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p><code>multi_match</code> 多匹配查询的类型有多种，其中的三种恰巧与 <a href="#know-your-data">了解我们的数据</a> 中介绍的三个场景对应，即： <code>best_fields</code> 、 <code>most_fields</code> 和 <code>cross_fields</code> （最佳字段、多数字段、跨字段）。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>默认情况下，查询的类型是 <code>best_fields</code> ，这表示它会为每个字段生成一个 <code>match</code> 查询，然后将它们组合到 <code>dis_max</code> 查询的内部，如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "dis_max": {
    "queries":  [
      {
        "match": {
          "title": {
            "query": "Quick brown fox",
            "minimum_should_match": "30%"
          }
        }
      },
      {
        "match": {
          "body": {
            "query": "Quick brown fox",
            "minimum_should_match": "30%"
          }
        }
      },
    ],
    "tie_breaker": 0.3
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>上面这个查询用 <code>multi_match</code> 重写成更简洁的形式：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "multi_match": {
        "query":                "Quick brown fox",
        "type":                 "best_fields", <b class="conum">(1)</b>
        "fields":               [ "title", "body" ],
        "tie_breaker":          0.3,
        "minimum_should_match": "30%" <b class="conum">(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>best_fields</code> 类型是默认值，可以不指定。</p>
</li>
<li>
<p>如 <code>minimum_should_match</code> 或 <code>operator</code> 这样的参数会被传递到生成的 <code>match</code> 查询中。</p>
</li>
</ol>
</div>
<div class="sect3">
<h4 id="_查询字段名称的模糊匹配">查询字段名称的模糊匹配</h4>
<div class="paragraph">
<p>字段名称可以用模糊匹配的方式给出：任何与模糊模式正则匹配的字段都会被包括在搜索条件中，例如可以使用以下方式同时匹配 <code>book_title</code> 、 <code>chapter_title</code> 和 <code>section_title</code> （书名、章名、节名）这三个字段：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "multi_match": {
        "query":  "Quick brown fox",
        "fields": "*_title"
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_提升单个字段的权重">提升单个字段的权重</h4>
<div class="paragraph">
<p>可以使用 <code>^</code> 字符语法为单个字段提升权重，在字段名称的末尾添加 <code>^boost</code> ，其中 <code>boost</code> 是一个浮点数：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "multi_match": {
        "query":  "Quick brown fox",
        "fields": [ "*_title", "chapter_title^2" ] <b class="conum">(1)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>chapter_title</code> 这个字段的 <code>boost</code> 值为 <code>2</code> ，而其他两个字段 <code>book_title</code> 和 <code>section_title</code> 字段的默认 boost 值为 <code>1</code> 。</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="most-fields">多数字段</h3>
<div class="paragraph">
<p>全文搜索被称作是 <em>召回率（Recall）</em> 与 <em>精确率（Precision）</em> 的战场： <em>召回率</em> ——返回所有的相关文档； <em>精确率</em> ——不返回无关文档。目的是在结果的第一页中为用户呈现最为相关的文档。</p>
</div>
<div class="paragraph">
<p>为了提高召回率的效果，我们扩大搜索范围——不仅返回与用户搜索词精确匹配的文档，还会返回我们认为与查询相关的所有文档。如果一个用户搜索 “quick brown box” ，一个包含词语 <code>fast foxes</code> 的文档被认为是非常合理的返回结果。</p>
</div>
<div class="paragraph">
<p>如果包含词语 <code>fast foxes</code> 的文档是能找到的唯一相关文档，那么它会出现在结果列表的最上面，但是，如果有 100 个文档都出现了词语 <code>quick brown fox</code> ，那么这个包含词语 <code>fast foxes</code> 的文档当然会被认为是次相关的，它可能处于返回结果列表更下面的某个地方。当包含了很多潜在匹配之后，我们需要将最匹配的几个置于结果列表的顶部。</p>
</div>
<div class="paragraph">
<p>提高全文相关性精度的常用方式是为同一文本建立多种方式的索引，每种方式都提供了一个不同的相关度信号 <em>signal</em> 。主字段会以尽可能多的形式的去匹配尽可能多的文档。举个例子，我们可以进行以下操作：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>使用词干提取来索引 <code>jumps</code> 、 <code>jumping</code> 和 <code>jumped</code> 样的词，将 <code>jump</code> 作为它们的词根形式。这样即使用户搜索 <code>jumped</code> ，也还是能找到包含 <code>jumping</code> 的匹配的文档。</p>
</li>
<li>
<p>将同义词包括其中，如 <code>jump</code> 、 <code>leap</code> 和 <code>hop</code> 。</p>
</li>
<li>
<p>移除变音或口音词：如 <code>ésta</code> 、 <code>está</code> 和 <code>esta</code> 都会以无变音形式 <code>esta</code> 来索引。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>尽管如此，如果我们有两个文档，其中一个包含词 <code>jumped</code> ，另一个包含词 <code>jumping</code> ，用户很可能期望前者能排的更高，因为它正好与输入的搜索条件一致。</p>
</div>
<div class="paragraph">
<p>为了达到目的，我们可以将相同的文本索引到其他字段从而提供更为精确的匹配。一个字段可能是为词干未提取过的版本，另一个字段可能是变音过的原始词，第三个可能使用 <em>shingles</em> 提供 <a href="#proximity-matching">词语相似性</a> 信息。这些附加的字段可以看成提高每个文档的相关度评分的信号 <em>signals</em> ，能匹配字段的越多越好。</p>
</div>
<div class="paragraph">
<p>一个文档如果与广度匹配的主字段相匹配，那么它会出现在结果列表中。如果文档同时又与 <em>signal</em> 信号字段匹配，那么它会获得额外加分，系统会提升它在结果列表中的位置。</p>
</div>
<div class="paragraph">
<p>我们会在本书稍后对同义词、词相似性、部分匹配以及其他潜在的信号进行讨论，但这里只使用词干已提取（stemmed）和未提取（unstemmed）的字段作为简单例子来说明这种技术。</p>
</div>
<div class="sect3">
<h4 id="_多字段映射">多字段映射</h4>
<div class="paragraph">
<p>首先要做的事情就是对我们的字段索引两次：一次使用词干模式以及一次非词干模式。为了做到这点，采用 <em>multifields</em> 来实现，已经在 <a href="#multi-fields">multifields</a> 有所介绍：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">DELETE /my_index

PUT /my_index
{
    "settings": { "number_of_shards": 1 }, <b class="conum">(1)</b>
    "mappings": {
        "my_type": {
            "properties": {
                "title": { <b class="conum">(2)</b>
                    "type":     "string",
                    "analyzer": "english",
                    "fields": {
                        "std":   { <b class="conum">(3)</b>
                            "type":     "string",
                            "analyzer": "standard"
                        }
                    }
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>参考 <a href="#relevance-is-broken">被破坏的相关度</a>.</p>
</li>
<li>
<p><code>title</code> 字段使用 <code>english</code> 英语分析器来提取词干。</p>
</li>
<li>
<p><code>title.std</code> 字段使用 <code>standard</code> 标准分析器，所以没有词干提取。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>接着索引一些文档：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index/my_type/1
{ "title": "My rabbit jumps" }

PUT /my_index/my_type/2
{ "title": "Jumping jack rabbits" }</code></pre>
</div>
</div>
<div class="paragraph">
<p>这里用一个简单 <code>match</code> 查询 <code>title</code> 标题字段是否包含 <code>jumping rabbits</code> （跳跃的兔子）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/_search
{
   "query": {
        "match": {
            "title": "jumping rabbits"
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>因为有了 <code>english</code> 分析器，这个查询是在查找以 <code>jump</code> 和 <code>rabbit</code> 这两个被提取词的文档。两个文档的 <code>title</code> 字段都同时包括这两个词，所以两个文档得到的评分也相同：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id": "1",
        "_score": 0.42039964,
        "_source": {
           "title": "My rabbit jumps"
        }
     },
     {
        "_id": "2",
        "_score": 0.42039964,
        "_source": {
           "title": "Jumping jack rabbits"
        }
     }
  ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果只是查询 <code>title.std</code> 字段，那么只有文档 2 是匹配的。尽管如此，如果同时查询两个字段，然后使用 <code>bool</code> 查询将评分结果 <em>合并</em> ，那么两个文档都是匹配的（ <code>title</code> 字段的作用），而且文档 2 的相关度评分更高（ <code>title.std</code> 字段的作用）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/_search
{
   "query": {
        "multi_match": {
            "query":  "jumping rabbits",
            "type":   "most_fields", <b class="conum">(1)</b>
            "fields": [ "title", "title.std" ]
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>我们希望将所有匹配字段的评分合并起来，所以使用 <code>most_fields</code> 类型。这让 <code>multi_match</code> 查询用 <code>bool</code> 查询将两个字段语句包在里面，而不是使用 <code>dis_max</code> 查询。</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id": "2",
        "_score": 0.8226396, <b class="conum">(1)</b>
        "_source": {
           "title": "Jumping jack rabbits"
        }
     },
     {
        "_id": "1",
        "_score": 0.10741998, <b class="conum">(1)</b>
        "_source": {
           "title": "My rabbit jumps"
        }
     }
  ]
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>文档 2 现在的评分要比文档 1 高。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>用广度匹配字段 <code>title</code> 包括尽可能多的文档——以提升召回率——同时又使用字段 <code>title.std</code> 作为 <em>信号</em> 将相关度更高的文档置于结果顶部。</p>
</div>
<div class="paragraph">
<p>每个字段对于最终评分的贡献可以通过自定义值 <code>boost</code> 来控制。比如，使 <code>title</code> 字段更为重要，这样同时也降低了其他信号字段的作用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/_search
{
   "query": {
        "multi_match": {
            "query":       "jumping rabbits",
            "type":        "most_fields",
            "fields":      [ "title^10", "title.std" ] <b class="conum">(1)</b>
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>title</code> 字段的 <code>boost</code> 的值为 <code>10</code> 使它比 <code>title.std</code> 更重要。</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_cross_fields_entity_search">跨字段实体搜索</h3>
<div class="paragraph">
<p>现在讨论一种普遍的搜索模式：跨字段实体搜索（cross-fields entity search）。在如 <code>person</code> 、 <code>product</code> 或 <code>address</code> （人、产品或地址）这样的实体中，需要使用多个字段来唯一标识它的信息。 <code>person</code> 实体可能是这样索引的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "firstname":  "Peter",
    "lastname":   "Smith"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>或地址：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "street":   "5 Poland Street",
    "city":     "London",
    "country":  "United Kingdom",
    "postcode": "W1V 3DG"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这与之前描述的 <a href="#multi-query-strings">多字符串查询</a> 很像，但这存在着巨大的区别。在 <a href="#multi-query-strings">多字符串查询</a> 中，我们为每个字段使用不同的字符串，在本例中，我们想使用 <em>单个</em> 字符串在多个字段中进行搜索。</p>
</div>
<div class="paragraph">
<p>我们的用户可能想搜索 “Peter Smith” 这个人，或 “Poland Street W1V” 这个地址，这些词出现在不同的字段中，所以如果使用 <code>dis_max</code> 或 <code>best_fields</code> 查询去查找 <em>单个</em> 最佳匹配字段显然是个错误的方式。</p>
</div>
<div class="sect3">
<h4 id="_简单的方式">简单的方式</h4>
<div class="paragraph">
<p>依次查询每个字段并将每个字段的匹配评分结果相加，听起来真像是 <code>bool</code> 查询：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "query": {
    "bool": {
      "should": [
        { "match": { "street":    "Poland Street W1V" }},
        { "match": { "city":      "Poland Street W1V" }},
        { "match": { "country":   "Poland Street W1V" }},
        { "match": { "postcode":  "Poland Street W1V" }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>为每个字段重复查询字符串会使查询瞬间变得冗长，可以采用 <code>multi_match</code> 查询，将 <code>type</code> 设置成 <code>most_fields</code> 然后告诉 Elasticsearch 合并所有匹配字段的评分：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "query": {
    "multi_match": {
      "query":       "Poland Street W1V",
      "type":        "most_fields",
      "fields":      [ "street", "city", "country", "postcode" ]
    }
  }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_most_fields_方式的问题">most_fields 方式的问题</h4>
<div class="paragraph">
<p>用 <code>most_fields</code> 这种方式搜索也存在某些问题，这些问题并不会马上显现：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>它是为多数字段匹配 <em>任意</em> 词设计的，而不是在 <em>所有字段</em> 中找到最匹配的。</p>
</li>
<li>
<p>它不能使用 <code>operator</code> 或 <code>minimum_should_match</code> 参数来降低次相关结果造成的长尾效应。</p>
</li>
<li>
<p>词频对于每个字段是不一样的，而且它们之间的相互影响会导致不好的排序结果。</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="field-centric">字段中心式查询</h3>
<div class="paragraph">
<p>以上三个源于 <code>most_fields</code> 的问题都因为它是 <em>字段中心式（field-centric）</em> 而不是 <em>词中心式（term-centric）</em> 的：当真正感兴趣的是匹配词的时候，它为我们查找的是最匹配的 <em>字段</em> 。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<code>best_fields</code> 类型也是字段中心式的，它也存在类似的问题。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>首先查看这些问题存在的原因，再想如何解决它们。</p>
</div>
<div class="sect3">
<h4 id="_问题_1_在多个字段中匹配相同的词">问题 1 ：在多个字段中匹配相同的词</h4>
<div class="paragraph">
<p>回想一下 <code>most_fields</code> 查询是如何执行的：Elasticsearch 为每个字段生成独立的 <code>match</code> 查询，再用 <code>bool</code> 查询将他们包起来。</p>
</div>
<div class="paragraph">
<p>可以通过 <code>validate-query</code> API 查看：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_validate/query?explain
{
  "query": {
    "multi_match": {
      "query":   "Poland Street W1V",
      "type":    "most_fields",
      "fields":  [ "street", "city", "country", "postcode" ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>生成 <code>explanation</code> 解释：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>(street:poland   street:street   street:w1v)
(city:poland     city:street     city:w1v)
(country:poland  country:street  country:w1v)
(postcode:poland postcode:street postcode:w1v)</pre>
</div>
</div>
<div class="paragraph">
<p>可以发现， <em>两个</em> 字段都与 <code>poland</code> 匹配的文档要比一个字段同时匹配 <code>poland</code> 与 <code>street</code> 文档的评分高。</p>
</div>
</div>
<div class="sect3">
<h4 id="_问题_2_剪掉长尾">问题 2 ：剪掉长尾</h4>
<div class="paragraph">
<p>在 <a href="#match-precision">匹配精度</a> 中，我们讨论过使用 <code>and</code> 操作符或设置 <code>minimum_should_match</code> 参数来消除结果中几乎不相关的长尾，或许可以尝试以下方式：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "query": {
        "multi_match": {
            "query":       "Poland Street W1V",
            "type":        "most_fields",
            "operator":    "and", <b class="conum">(1)</b>
            "fields":      [ "street", "city", "country", "postcode" ]
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>所有词必须呈现。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>但是对于 <code>best_fields</code> 或 <code>most_fields</code> 这些参数会在 <code>match</code> 查询生成时被传入，这个查询的 <code>explanation</code> 解释如下：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>(+street:poland   +street:street   +street:w1v)
(+city:poland     +city:street     +city:w1v)
(+country:poland  +country:street  +country:w1v)
(+postcode:poland +postcode:street +postcode:w1v)</pre>
</div>
</div>
<div class="paragraph">
<p>换句话说，使用 <code>and</code> 操作符要求所有词都必须存在于 <em>相同字段</em> ，这显然是不对的！可能就不存在能与这个查询匹配的文档。</p>
</div>
</div>
<div class="sect3">
<h4 id="_问题_3_词频">问题 3 ：词频</h4>
<div class="paragraph">
<p>在 <a href="#relevance-intro">什么是相关</a> 中，我们解释过每个词默认使用 TF/IDF 相似度算法计算相关度评分：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">词频</dt>
<dd>
<p>一个词在单个文档的某个字段中出现的频率越高，这个文档的相关度就越高。</p>
</dd>
<dt class="hdlist1">逆向文档频率</dt>
<dd>
<p>一个词在所有文档某个字段索引中出现的频率越高，这个词的相关度就越低。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>当搜索多个字段时，TF/IDF 会带来某些令人意外的结果。</p>
</div>
<div class="paragraph">
<p>想想用字段 <code>first_name</code> 和 <code>last_name</code> 查询 “Peter Smith” 的例子， Peter 是个平常的名 Smith 也是平常的姓，这两者都具有较低的 IDF 值。但当索引中有另外一个人的名字是 “Smith Williams” 时， Smith 作为名来说很不平常，以致它有一个较高的 IDF 值！</p>
</div>
<div class="paragraph">
<p>下面这个简单的查询可能会在结果中将 “Smith Williams” 置于 “Peter Smith” 之上，尽管事实上是第二个人比第一个人更为匹配。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "query": {
        "multi_match": {
            "query":       "Peter Smith",
            "type":        "most_fields",
            "fields":      [ "*_name" ]
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这里的问题是 <code>smith</code> 在名字段中具有高 IDF ，它会削弱 “Peter” 作为名和 “Smith” 作为姓时低 IDF 的所起作用。</p>
</div>
</div>
<div class="sect3">
<h4 id="_解决方案">解决方案</h4>
<div class="paragraph">
<p>存在这些问题仅仅是因为我们在处理着多个字段，如果将所有这些字段组合成单个字段，问题就会消失。可以为 <code>person</code> 文档添加 <code>full_name</code> 字段来解决这个问题：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "first_name":  "Peter",
    "last_name":   "Smith",
    "full_name":   "Peter Smith"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>当查询 <code>full_name</code> 字段时：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>具有更多匹配词的文档会比只有一个重复匹配词的文档更重要。</p>
</li>
<li>
<p><code>minimum_should_match</code> 和 <code>operator</code> 参数会像期望那样工作。</p>
</li>
<li>
<p>姓和名的逆向文档频率被合并，所以 Smith 到底是作为姓还是作为名出现，都会变得无关紧要。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>这么做当然是可行的，但我们并不太喜欢存储冗余数据。取而代之的是 Elasticsearch 可以提供两个解决方案——一个在索引时，而另一个是在搜索时——随后会讨论它们。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="custom-all">自定义 _all 字段</h3>
<div class="paragraph">
<p>在 <a href="#all-field">all-field</a> 字段中，我们解释过 <code>_all</code> 字段的索引方式是将所有其他字段的值作为一个大字符串索引的。然而这么做并不十分灵活，为了灵活我们可以给人名添加一个自定义 <code>_all</code> 字段，再为地址添加另一个 <code>_all</code> 字段。</p>
</div>
<div class="paragraph">
<p>Elasticsearch 在字段映射中为我们提供 <code>copy_to</code> 参数来实现这个功能：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index
{
    "mappings": {
        "person": {
            "properties": {
                "first_name": {
                    "type":     "string",
                    "copy_to":  "full_name" <b class="conum">(1)</b>
                },
                "last_name": {
                    "type":     "string",
                    "copy_to":  "full_name" <b class="conum">(1)</b>
                },
                "full_name": {
                    "type":     "string"
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>first_name</code> 和 <code>last_name</code> 字段中的值会被复制到 <code>full_name</code> 字段。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>有了这个映射，我们可以用 <code>first_name</code> 来查询名，用 <code>last_name</code> 来查询姓，或者直接使用 <code>full_name</code> 查询整个姓名。</p>
</div>
<div class="paragraph">
<p><code>first_name</code> 和 <code>last_name</code> 的映射并不影响 <code>full_name</code> 如何被索引， <code>full_name</code> 将两个字段的内容复制到本地，然后根据 <code>full_name</code> 的映射自行索引。</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
<div class="paragraph">
<p><code>copy_to</code> 设置对<a href="#multi-fields">multi-field</a>无效。如果尝试这样配置映射，Elasticsearch 会抛异常。</p>
</div>
<div class="paragraph">
<p>为什么呢？多字段只是以不同方式简单索引“主”字段；它们没有自己的数据源。也就是说没有可供 <code>copy_to</code> 到另一字段的数据源。</p>
</div>
<div class="paragraph">
<p>只要对“主”字段 <code>copy_to</code> 就能轻而易举的达到相同的效果：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index
{
    "mappings": {
        "person": {
            "properties": {
                "first_name": {
                    "type":     "string",
                    "copy_to":  "full_name", <b class="conum">(1)</b>
                    "fields": {
                        "raw": {
                            "type": "string",
                            "index": "not_analyzed"
                        }
                    }
                },
                "full_name": {
                    "type":     "string"
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>copy_to</code> 是针对“主”字段，而不是多字段的</p>
</li>
</ol>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_cross_fields_queries">cross-fields 跨字段查询</h3>
<div class="paragraph">
<p>自定义 <code><em>all</code> 的方式是一个好的解决方案，只需在索引文档前为其设置好映射。不过， Elasticsearch 还在搜索时提供了相应的解决方案：使用 <code>cross_fields</code> 类型进行 <code>multi_match</code> 查询。 <code>cross_fields</code> 使用词中心式（term-centric）的查询方式，这与 <code>best_fields</code> 和 <code>most_fields</code> 使用字段中心式（field-centric）的查询方式非常不同，它将所有字段当成一个大字段，并在 _每个字段</em> 中查找 <em>每个词</em> 。</p>
</div>
<div class="paragraph">
<p>为了说明字段中心式（field-centric）与词中心式（term-centric）这两种查询方式的不同，先看看以下字段中心式的 <code>most_fields</code> 查询的 <code>explanation</code> 解释：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_validate/query?explain
{
    "query": {
        "multi_match": {
            "query":       "peter smith",
            "type":        "most_fields",
            "operator":    "and", <b class="conum">(1)</b>
            "fields":      [ "first_name", "last_name" ]
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>所有词都是必须的。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>对于匹配的文档， <code>peter</code> 和 <code>smith</code> 都必须同时出现在相同字段中，要么是 <code>first_name</code> 字段，要么 <code>last_name</code> 字段：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>(+first_name:peter +first_name:smith)
(+last_name:peter  +last_name:smith)</pre>
</div>
</div>
<div class="paragraph">
<p><em>词中心式</em> 会使用以下逻辑：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>+(first_name:peter last_name:peter)
+(first_name:smith last_name:smith)</pre>
</div>
</div>
<div class="paragraph">
<p>换句话说，词 <code>peter</code> 和 <code>smith</code> 都必须出现，但是可以出现在任意字段中。</p>
</div>
<div class="paragraph">
<p><code>cross_fields</code> 类型首先分析查询字符串并生成一个词列表，然后它从所有字段中依次搜索每个词。这种不同的搜索方式很自然的解决了 <a href="#field-centric">字段中心式</a> 查询三个问题中的二个。剩下的问题是逆向文档频率不同。</p>
</div>
<div class="paragraph">
<p>幸运的是 <code>cross_fields</code> 类型也能解决这个问题，通过 <code>validate-query</code> 可以看到：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_validate/query?explain
{
    "query": {
        "multi_match": {
            "query":       "peter smith",
            "type":        "cross_fields", <b class="conum">(1)</b>
            "operator":    "and",
            "fields":      [ "first_name", "last_name" ]
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>用 <code>cross_fields</code> 词中心式匹配。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>它通过 <em>混合</em> 不同字段逆向索引文档频率的方式解决了词频的问题：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>+blended("peter", fields: [first_name, last_name])
+blended("smith", fields: [first_name, last_name])</pre>
</div>
</div>
<div class="paragraph">
<p>换句话说，它会同时在 <code>first_name</code> 和 <code>last_name</code> 两个字段中查找 <code>smith</code> 的 IDF ，然后用两者的最小值作为两个字段的 IDF 。结果实际上就是 <code>smith</code> 会被认为既是个平常的姓，也是平常的名。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>为了让 <code>cross_fields</code> 查询以最优方式工作，所有的字段都须使用相同的分析器，具有相同分析器的字段会被分组在一起作为混合字段使用。</p>
</div>
<div class="paragraph">
<p>如果包括了不同分析链的字段，它们会以 <code>best_fields</code> 的相同方式被加入到查询结果中。例如：我们将 <code>title</code> 字段加到之前的查询中（假设它们使用的是不同的分析器）， explanation 的解释结果如下：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>(+title:peter +title:smith)
(
  +blended("peter", fields: [first_name, last_name])
  +blended("smith", fields: [first_name, last_name])
)</pre>
</div>
</div>
<div class="paragraph">
<p>当在使用 <code>minimum_should_match</code> 和 <code>operator</code> 参数时，这点尤为重要。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_按字段提高权重">按字段提高权重</h4>
<div class="paragraph">
<p>采用 <code>cross_fields</code> 查询与 <a href="#custom-all">自定义 <code>_all</code> 字段</a> 相比，其中一个优势就是它可以在搜索时为单个字段提升权重。</p>
</div>
<div class="paragraph">
<p>这对像 <code>first_name</code> 和 <code>last_name</code> 具有相同值的字段并不是必须的，但如果要用 <code>title</code> 和 <code>description</code> 字段搜索图书，可能希望为 <code>title</code> 分配更多的权重，这同样可以使用前面介绍过的 <code>^</code> 符号语法来实现：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /books/_search
{
    "query": {
        "multi_match": {
            "query":       "peter smith",
            "type":        "cross_fields",
            "fields":      [ "title^2", "description" ] <b class="conum">(1)</b>
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>title</code> 字段的权重提升值为 <code>2</code> ， <code>description</code> 字段的权重提升值默认为 <code>1</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>自定义单字段查询是否能够优于多字段查询，取决于在多字段查询与单字段自定义 <code>_all</code> 之间代价的权衡，即哪种解决方案会带来更大的性能优化就选择哪一种。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_exact_value_fields">Exact-Value 精确值字段</h3>
<div class="paragraph">
<p>在结束多字段查询这个话题之前，我们最后要讨论的是精确值 <code>not_analyzed</code> 未分析字段。将 <code>not_analyzed</code> 字段与 <code>multi_match</code> 中 <code>analyzed</code> 字段混在一起没有多大用处。</p>
</div>
<div class="paragraph">
<p>原因可以通过查看查询的 explanation 解释得到，设想将 <code>title</code> 字段设置成 <code>not_analyzed</code> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_validate/query?explain
{
    "query": {
        "multi_match": {
            "query":       "peter smith",
            "type":        "cross_fields",
            "fields":      [ "title", "first_name", "last_name" ]
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>因为 <code>title</code> 字段是未分析过的，Elasticsearch 会将 “peter smith” 这个完整的字符串作为查询条件来搜索！</p>
</div>
<div class="literalblock">
<div class="content">
<pre>title:peter smith
(
    blended("peter", fields: [first_name, last_name])
    blended("smith", fields: [first_name, last_name])
)</pre>
</div>
</div>
<div class="paragraph">
<p>显然这个项不在 <code>title</code> 的倒排索引中，所以需要在 <code>multi_match</code> 查询中避免使用 <code>not_analyzed</code> 字段。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="proximity-matching">近似匹配</h2>
<div class="sectionbody">
<div class="paragraph">
<p>使用 TF/IDF 的标准全文检索将文档或者文档中的字段作一大袋的词语处理。 <code>match</code> 查询可以告知我们这大袋子中是否包含查询的词条，但却无法告知词语之间的关系。</p>
</div>
<div class="paragraph">
<p>思考下面这几个句子的不同：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Sue ate the alligator.</p>
</li>
<li>
<p>The alligator ate Sue.</p>
</li>
<li>
<p>Sue never goes anywhere without her alligator-skin purse.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>用 <code>match</code> 搜索 <code>sue alligator</code> 上面的三个文档都会得到匹配，但它却不能确定这两个词是否只来自于一种语境，甚至都不能确定是否来自于同一个段落。</p>
</div>
<div class="paragraph">
<p>理解分词之间的关系是一个复杂的难题，我们也无法通过换一种查询方式去解决。但我们至少可以通过出现在彼此附近或者仅仅是彼此相邻的分词来判断一些似乎相关的分词。</p>
</div>
<div class="paragraph">
<p>每个文档可能都比我们上面这个例子要长： <code>Sue</code> 和 <code>alligator</code> 这两个词可能会分散在其他的段落文字中，我们可能会希望得到尽可能包含这两个词的文档，但我们也同样需要这些文档与分词有很高的相关度。</p>
</div>
<div class="paragraph">
<p>这就是短语匹配或者近似匹配的所属领域。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>在这一章节，我们还是使用在<a href="#match-test-data"><code>match</code> 查询</a>中使用过的文档作为例子。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="phrase-matching">短语匹配</h3>
<div class="paragraph">
<p>就像 <code>match</code> 查询对于标准全文检索是一种最常用的查询一样，当你想找到彼此邻近搜索词的查询方法时，就会想到 <code>match_phrase</code> 查询。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
    "query": {
        "match_phrase": {
            "title": "quick brown fox"
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>类似 <code>match</code> 查询， <code>match_phrase</code> 查询首先将查询字符串解析成一个词项列表，然后对这些词项进行搜索，但只保留那些包含 <em>全部</em> 搜索词项，且 <em>位置</em> 与搜索词项相同的文档。
比如对于 <code>quick fox</code> 的短语搜索可能不会匹配到任何文档，因为没有文档包含的 <code>quick</code> 词之后紧跟着 <code>fox</code> 。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p><code>match_phrase</code> 查询同样可写成一种类型为 <code>phrase</code> 的 <code>match</code> 查询:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">"match": {
    "title": {
        "query": "quick brown fox",
        "type":  "phrase"
    }
}</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_词项的位置">词项的位置</h4>
<div class="paragraph">
<p>当一个字符串被分词后，这个分析器不但会返回一个词项列表，而且还会返回各词项在原始字符串中的 <em>位置</em> 或者顺序关系：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /_analyze?analyzer=standard
Quick brown fox</code></pre>
</div>
</div>
<div class="paragraph">
<p>返回信息如下：</p>
</div>
<div class="listingblock pagebreak-before">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
   "tokens": [
      {
         "token": "quick",
         "start_offset": 0,
         "end_offset": 5,
         "type": "&lt;ALPHANUM&gt;",
         "position": 1 <b class="conum">(1)</b>
      },
      {
         "token": "brown",
         "start_offset": 6,
         "end_offset": 11,
         "type": "&lt;ALPHANUM&gt;",
         "position": 2 <b class="conum">(1)</b>
      },
      {
         "token": "fox",
         "start_offset": 12,
         "end_offset": 15,
         "type": "&lt;ALPHANUM&gt;",
         "position": 3 <b class="conum">(1)</b>
      }
   ]
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>position</code> 代表各词项在原始字符串中的位置。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>位置信息可以被存储在倒排索引中，因此 <code>match_phrase</code> 查询这类对词语位置敏感的查询，
就可以利用位置信息去匹配包含所有查询词项，且各词项顺序也与我们搜索指定一致的文档，中间不夹杂其他词项。</p>
</div>
</div>
<div class="sect3">
<h4 id="_什么是短语">什么是短语</h4>
<div class="paragraph">
<p>一个被认定为和短语 <code>quick brown fox</code> 匹配的文档，必须满足以下这些要求：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>quick</code> 、 <code>brown</code> 和 <code>fox</code> 需要全部出现在域中。</p>
</li>
<li>
<p><code>brown</code> 的位置应该比 <code>quick</code> 的位置大 <code>1</code> 。</p>
</li>
<li>
<p><code>fox</code> 的位置应该比 <code>quick</code> 的位置大 <code>2</code> 。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>如果以上任何一个选项不成立，则该文档不能认定为匹配。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>本质上来讲，<code>match_phrase</code> 查询是利用一种低级别的 <code>span</code> 查询族（query family）去做词语位置敏感的匹配。

Span 查询是一种词项级别的查询，所以它们没有分词阶段；它们只对指定的词项进行精确搜索。</p>
</div>
<div class="paragraph">
<p>值得庆幸的是，<code>match_phrase</code> 查询已经足够优秀，大多数人是不会直接使用 <code>span</code> 查询。
然而，在一些专业领域，例如专利检索，还是会采用这种低级别查询去执行非常具体而又精心构造的位置搜索。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="slop">混合起来</h3>
<div class="paragraph">
<p>精确短语匹配  或许是过于严格了。也许我们想要包含 <code>quick brown fox'' 的文档也能够匹配 </code>quick fox,'' ， 尽管情形不完全相同。</p>
</div>
<div class="paragraph">
<p>我们能够通过使用 <code>slop</code> 参数将灵活度引入短语匹配中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
    "query": {
        "match_phrase": {
            "title": {
            	"query": "quick fox",
            	"slop":  1
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>slop</code> 参数告诉 <code>match_phrase</code> 查询词条相隔多远时仍然能将文档视为匹配  。 相隔多远的意思是为了让查询和文档匹配你需要移动词条多少次？</p>
</div>
<div class="paragraph">
<p>我们以一个简单的例子开始吧。 为了让查询 <code>quick fox</code> 能匹配一个包含 <code>quick brown fox</code> 的文档， 我们需要 <code>slop</code> 的值为 <code>1</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>            Pos 1         Pos 2         Pos 3
-----------------------------------------------
Doc:        quick         brown         fox
-----------------------------------------------
Query:      quick         fox
Slop 1:     quick                 ↳     fox</pre>
</div>
</div>
<div class="paragraph">
<p>尽管在使用了 <code>slop</code> 短语匹配中所有的单词都需要出现， 但是这些单词也不必为了匹配而按相同的序列排列。 有了足够大的 <code>slop</code> 值， 单词就能按照任意顺序排列了。</p>
</div>
<div class="paragraph">
<p>为了使查询 <code>fox quick</code> 匹配我们的文档， 我们需要 <code>slop</code> 的值为 <code>3</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>            Pos 1         Pos 2         Pos 3
-----------------------------------------------
Doc:        quick         brown         fox
-----------------------------------------------
Query:      fox           quick
Slop 1:     fox|quick  ↵  <b class="conum">(1)</b>
Slop 2:     quick      ↳  fox
Slop 3:     quick                 ↳     fox</pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>注意 <code>fox</code> 和 <code>quick</code> 在这步中占据同样的位置。 因此将 <code>fox quick</code> 转换顺序成 <code>quick fox</code> 需要两步， 或者值为 <code>2</code> 的 <code>slop</code> 。</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_multivalue_fields_2">多值字段</h3>
<div class="paragraph">
<p>对多值字段使用短语匹配时会发生奇怪的事。  想象一下你索引这个文档:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index/groups/1
{
    "names": [ "John Abraham", "Lincoln Smith"]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>然后运行一个对 <code>Abraham Lincoln</code> 的短语查询:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/groups/_search
{
    "query": {
        "match_phrase": {
            "names": "Abraham Lincoln"
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>令人惊讶的是， 即使 <code>Abraham</code> 和 <code>Lincoln</code> 在 <code>names</code> 数组里属于两个不同的人名， 我们的文档也匹配了查询。 这一切的原因在Elasticsearch数组的索引方式。</p>
</div>
<div class="paragraph">
<p>在分析 <code>John Abraham</code> 的时候， 产生了如下信息：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Position 1: <code>john</code></p>
</li>
<li>
<p>Position 2: <code>abraham</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>然后在分析 <code>Lincoln Smith</code> 的时候， 产生了：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Position 3: <code>lincoln</code></p>
</li>
<li>
<p>Position 4: <code>smith</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>换句话说， Elasticsearch对以上数组分析生成了与分析单个字符串 <code>John Abraham Lincoln Smith</code> 一样几乎完全相同的语汇单元。 我们的查询示例寻找相邻的 <code>lincoln</code> 和 <code>abraham</code> ，
而且这两个词条确实存在，并且它们俩正好相邻， 所以这个查询匹配了。</p>
</div>
<div class="paragraph">
<p>幸运的是， 在这样的情况下有一种叫做 <code>position_increment_gap</code> 的简单的解决方案， 它在字段映射中配置。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">DELETE /my_index/groups/ <b class="conum">(1)</b>

PUT /my_index/_mapping/groups <b class="conum">(2)</b>
{
    "properties": {
        "names": {
            "type":                "string",
            "position_increment_gap": 100
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>首先删除映射 <code>groups</code> 以及这个类型内的所有文档。</p>
</li>
<li>
<p>然后创建一个有正确值的新的映射 <code>groups</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><code>position_increment_gap</code> 设置告诉 Elasticsearch 应该为数组中每个新元素增加当前词条 <code>position</code> 的指定值。 所以现在当我们再索引 names 数组时，会产生如下的结果：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Position 1: <code>john</code></p>
</li>
<li>
<p>Position 2: <code>abraham</code></p>
</li>
<li>
<p>Position 103: <code>lincoln</code></p>
</li>
<li>
<p>Position 104: <code>smith</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>现在我们的短语查询可能无法匹配该文档因为 <code>abraham</code> 和 <code>lincoln</code> 之间的距离为 100 。 为了匹配这个文档你必须添加值为 100 的 <code>slop</code> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="_closer_is_better">越近越好</h3>
<div class="paragraph">
<p>鉴于一个短语查询仅仅排除了不包含确切查询短语的文档， 而 <em>邻近查询</em> &#x2014; 一个 
<code>slop</code> 大于 <code>0</code>&#x2014; 的短语查询将查询词条的邻近度考虑到最终相关度 <code>_score</code> 中。 通过设置一个像 <code>50</code> 或者 <code>100</code> 这样的高 <code>slop</code> 值, 你能够排除单词距离太远的文档， 但是也给予了那些单词临近的的文档更高的分数。</p>
</div>
<div class="paragraph">
<p>下列对 <code>quick dog</code> 的邻近查询匹配了同时包含 <code>quick</code> 和 <code>dog</code> 的文档， 但是也给了与 quick 和 dog 更加临近的文档更高的分数 ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">POST /my_index/my_type/_search
{
   "query": {
      "match_phrase": {
         "title": {
            "query": "quick dog",
            "slop":  50 <b class="conum">(1)</b>
         }
      }
   }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>注意高 <code>slop</code> 值。</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id":      "3",
        "_score":   0.75, <b class="conum">(1)</b>
        "_source": {
           "title": "The quick brown fox jumps over the quick dog"
        }
     },
     {
        "_id":      "2",
        "_score":   0.28347334, <b class="conum">(2)</b>
        "_source": {
           "title": "The quick brown fox jumps over the lazy dog"
        }
     }
  ]
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>分数较高因为 <code>quick</code> 和 <code>dog</code> 很接近</p>
</li>
<li>
<p>分数较低因为 <code>quick</code> 和 <code>dog</code> 分开较远</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="proximity-relevance">使用邻近度提高相关度</h3>
<div class="paragraph">
<p>虽然邻近查询很有用， 但是所有词条都出现在文档的要求过于严格了。
我们讨论 <a href="#full-text-search">全文搜索</a> 一章的 <a href="#match-precision">控制精度</a> 也是同样的问题： 如果七个词条中有六个匹配， 那么这个文档对用户而言就已经足够相关了， 但是 <code>match_phrase</code> 查询可能会将它排除在外。</p>
</div>
<div class="paragraph">
<p>相比将使用邻近匹配作为绝对要求， 我们可以将它作为  <em>信号</em>&#x2014; 使用， 作为许多潜在查询中的一个， 会对每个文档的最终分值做出贡献 (参考 <a href="#most-fields">多数字段</a>)。</p>
</div>
<div class="paragraph">
<p>实际上我们想将多个查询的分数累计起来意味着我们应该用 <code>bool</code> 查询将它们合并。</p>
</div>
<div class="paragraph">
<p>我们可以将一个简单的 <code>match</code> 查询作为一个 <code>must</code> 子句。 这个查询将决定哪些文档需要被包含到结果集中。 我们可以用 <code>minimum_should_match</code> 参数去除长尾。 然后我们可以以 <code>should</code> 子句的形式添加更多特定查询。 每一个匹配成功的都会增加匹配文档的相关度。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
  "query": {
    "bool": {
      "must": {
        "match": { <b class="conum">(1)</b>
          "title": {
            "query":                "quick brown fox",
            "minimum_should_match": "30%"
          }
        }
      },
      "should": {
        "match_phrase": { <b class="conum">(2)</b>
          "title": {
            "query": "quick brown fox",
            "slop":  50
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>must</code> 子句从结果集中包含或者排除文档。</p>
</li>
<li>
<p><code>should</code> 子句增加了匹配到文档的相关度评分。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>我们当然可以在 <code>should</code> 子句里面添加其它的查询， 其中每一个查询只针对某一特定方面的相关度。</p>
</div>
</div>
<div class="sect2 pagebreak-before">
<h3 id="_Improving_Performance">性能优化</h3>
<div class="paragraph">
<p>短语查询和邻近查询都比简单的 <code>query</code> 查询代价更高。
一个 <code>match</code> 查询仅仅是看词条是否存在于倒排索引中，而一个 <code>match_phrase</code> 查询是必须计算并比较多个可能重复词项的位置。</p>
</div>
<div class="paragraph">
<p><a href="http://people.apache.org/~mikemccand/lucenebench/">Lucene nightly benchmarks</a> 表明一个简单的 <code>term</code> 查询比一个短语查询大约快 10 倍，比邻近查询(有 <code>slop</code> 的短语
查询)大约快 20 倍。当然，这个代价指的是在搜索时而不是索引时。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>通常，短语查询的额外成本并不像这些数字所暗示的那么吓人。事实上，性能上的差距只是证明一个简单的 <code>term</code> 查询有多快。标准全文数据的短语查询通常在几毫秒内完成，因此实际上都是完全可用，即使是在一个繁忙的集群上。</p>
</div>
<div class="paragraph">
<p>在某些特定病理案例下，短语查询可能成本太高了，但比较少见。一个典型例子就是DNA序列，在序列里很多同样的词项在很多位置重复出现。在这里使用高 <code>slop</code> 值会到导致位置计算大量增加。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>那么我们应该如何限制短语查询和邻近近查询的性能消耗呢？一种有用的方法是减少需要通过短语查询检查的文档总数。</p>
</div>
<div class="sect3">
<h4 id="rescore-api">结果集重新评分</h4>
<div class="paragraph">
<p>在<a href="#proximity-relevance">先前的章节中</a> ，我们讨论了而使用邻近查询来调整相关度，而不是使用它将文档从结果列表中添加或者排除。一个查询可能会匹配成千上万的结果，但我们的用户很可能只对结果的前几页感兴趣。</p>
</div>
<div class="paragraph">
<p>一个简单的 <code>match</code> 查询已经通过排序把包含所有含有搜索词条的文档放在结果列表的前面了。事实上，我们只想对这些 <em>顶部文档</em> 重新排序，来给同时匹配了短语查询的文档一个额外的相关度升级。</p>
</div>
<div class="paragraph">
<p><code>search</code> API 通过 <em>重新评分</em> 明确支持该功能。重新评分阶段支持一个代价更高的评分算法&#8212;&#8203;比如 <code>phrase</code> 查询&#8212;&#8203;只是为了从每个分片中获得前 <code>K</code> 个结果。 然后会根据它们的最新评分
重新排序。</p>
</div>
<div class="paragraph">
<p>该请求如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
    "query": {
        "match": {  <b class="conum">(1)</b>
            "title": {
                "query":                "quick brown fox",
                "minimum_should_match": "30%"
            }
        }
    },
    "rescore": {
        "window_size": 50, <b class="conum">(2)</b>
        "query": {         <b class="conum">(3)</b>
            "rescore_query": {
                "match_phrase": {
                    "title": {
                        "query": "quick brown fox",
                        "slop":  50
                    }
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>match</code> 查询决定哪些文档将包含在最终结果集中，并通过 TF/IDF 排序。</p>
</li>
<li>
<p><code>window_size</code> 是每一分片进行重新评分的顶部文档数量。</p>
</li>
<li>
<p>目前唯一支持的重新打分算法就是另一个查询，但是以后会有计划增加更多的算法。</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="shingles">寻找相关词</h3>
<div class="paragraph">
<p>短语查询和邻近查询都很好用，但仍有一个缺点。它们过于严格了：为了匹配短语查询，所有词项都必须存在，即使使用了 <code>slop</code> 。
</p>
</div>
<div class="paragraph">
<p>用 <code>slop</code> 得到的单词顺序的灵活性也需要付出代价，因为失去了单词对之间的联系。即使可以识别 <code>sue</code> 、 <code>alligator</code> 和 <code>ate</code>
相邻出现的文档，但无法分辨是 <em>Sue ate</em> 还是  <em>alligator ate</em> 。</p>
</div>
<div class="paragraph">
<p>当单词相互结合使用的时候，表达的含义比单独使用更丰富。两个子句 <em>I&#8217;m not happy I&#8217;m working</em> 和 <em>I&#8217;m happy I&#8217;m not working</em> 包含相同
的单词，也拥有相同的邻近度，但含义截然不同。</p>
</div>
<div class="paragraph">
<p>如果索引单词对而不是索引独立的单词，就能对这些单词的上下文尽可能多的保留。</p>
</div>
<div class="paragraph">
<p>对句子 <code>Sue ate the alligator</code> ，不仅要将每一个单词（或者 <em>unigram</em> ）作为词项索引</p>
</div>
<div class="literalblock">
<div class="content">
<pre>["sue", "ate", "the", "alligator"]</pre>
</div>
</div>
<div class="paragraph">
<p>也要将每个单词 <em>以及它的邻近词</em> 作为单个词项索引：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>["sue ate", "ate the", "the alligator"]</pre>
</div>
</div>
<div class="paragraph">
<p>这些单词对（或者 <em>bigrams</em> ）被称为 <em>shingles</em> 。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>Shingles 不限于单词对；你也可以索引三个单词（ <em>trigrams</em> ）：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>["sue ate the", "ate the alligator"]</pre>
</div>
</div>
<div class="paragraph">
<p>Trigrams 提供了更高的精度，但是也大大增加了索引中唯一词项的数量。在大多数情况下，Bigrams 就够了。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>当然，只有当用户输入的查询内容和在原始文档中顺序相同时，shingles 才是有用的；对 <code>sue alligator</code> 的查询可能会匹配到单个单词，但是不会匹配任何 shingles 。</p>
</div>
<div class="paragraph">
<p>幸运的是，用户倾向于使用和搜索数据相似的构造来表达搜索意图。但这一点很重要：只是索引 bigrams 是不够的；我们仍然需要 unigrams ，但可以将匹配 bigrams 作为增加相关度评分的信号。</p>
</div>
<div class="sect3">
<h4 id="_生成_shingles">生成 Shingles</h4>
<div class="paragraph">
<p>Shingles 需要在索引时作为分析过程的一部分被创建。我们可以将 unigrams 和 bigrams 都索引到单个字段中，
但将它们分开保存在能被独立查询的字段会更清晰。unigrams 字段将构成我们搜索的基础部分，而 bigrams 字段用来提高相关度。</p>
</div>
<div class="paragraph">
<p>首先，我们需要在创建分析器时使用 <code>shingle</code> 语汇单元过滤器：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">DELETE /my_index

PUT /my_index
{
    "settings": {
        "number_of_shards": 1,  <b class="conum">(1)</b>
        "analysis": {
            "filter": {
                "my_shingle_filter": {
                    "type":             "shingle",
                    "min_shingle_size": 2, <b class="conum">(2)</b>
                    "max_shingle_size": 2, <b class="conum">(2)</b>
                    "output_unigrams":  false   <b class="conum">(3)</b>
                }
            },
            "analyzer": {
                "my_shingle_analyzer": {
                    "type":             "custom",
                    "tokenizer":        "standard",
                    "filter": [
                        "lowercase",
                        "my_shingle_filter" <b class="conum">(4)</b>
                    ]
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>参考 <a href="#relevance-is-broken">被破坏的相关度！</a> 。</p>
</li>
<li>
<p>默认最小/最大的 shingle 大小是 <code>2</code> ，所以实际上不需要设置。</p>
</li>
<li>
<p><code>shingle</code> 语汇单元过滤器默认输出 unigrams ，但是我们想让 unigrams 和 bigrams 分开。</p>
</li>
<li>
<p><code>my_shingle_analyzer</code> 使用我们常规的 <code>my_shingles_filter</code> 语汇单元过滤器。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>首先，用 <code>analyze</code> API 测试下分析器：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/_analyze?analyzer=my_shingle_analyzer
Sue ate the alligator</code></pre>
</div>
</div>
<div class="paragraph">
<p>果然， 我们得到了 3 个词项：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>sue ate</code></p>
</li>
<li>
<p><code>ate the</code></p>
</li>
<li>
<p><code>the alligator</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>现在我们可以继续创建一个使用新的分析器的字段。</p>
</div>
</div>
<div class="sect3">
<h4 id="_多字段">多字段</h4>
<div class="paragraph">
<p>我们曾谈到将 unigrams 和 bigrams 分开索引更清晰，所以 <code>title</code> 字段将创建成一个多字段（参考 <a href="#multi-fields">[multi-fields]</a> ）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index/_mapping/my_type
{
    "my_type": {
        "properties": {
            "title": {
                "type": "string",
                "fields": {
                    "shingles": {
                        "type":     "string",
                        "analyzer": "my_shingle_analyzer"
                    }
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>通过这个映射， JSON 文档中的 <code>title</code> 字段将会被以 unigrams (<code>title</code>)和 bigrams (<code>title.shingles</code>)被索引，这意味着可以独立地查询这些字段。</p>
</div>
<div class="paragraph">
<p>最后，我们可以索引以下示例文档:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">POST /my_index/my_type/_bulk
{ "index": { "_id": 1 }}
{ "title": "Sue ate the alligator" }
{ "index": { "_id": 2 }}
{ "title": "The alligator ate Sue" }
{ "index": { "_id": 3 }}
{ "title": "Sue never goes anywhere without her alligator skin purse" }</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_搜索_shingles">搜索 Shingles</h4>
<div class="paragraph">
<p>为了理解添加 <code>shingles</code> 字段的好处，让我们首先来看 <code>The hungry alligator ate Sue</code> 进行简单 <code>match</code> 查询的结果：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
   "query": {
        "match": {
           "title": "the hungry alligator ate sue"
        }
   }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个查询返回了所有的三个文档， 但是注意文档 1 和 2 有相同的相关度评分因为他们包含了相同的单词：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id": "1",
        "_score": 0.44273707, <b class="conum">(1)</b>
        "_source": {
           "title": "Sue ate the alligator"
        }
     },
     {
        "_id": "2",
        "_score": 0.44273707, <b class="conum">(1)</b>
        "_source": {
           "title": "The alligator ate Sue"
        }
     },
     {
        "_id": "3", <b class="conum">(2)</b>
        "_score": 0.046571054,
        "_source": {
           "title": "Sue never goes anywhere without her alligator skin purse"
        }
     }
  ]
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>两个文档都包含 <code>the</code> 、 <code>alligator</code> 和 <code>ate</code> ，所以获得相同的评分。</p>
</li>
<li>
<p>我们可以通过设置 <code>minimum_should_match</code> 参数排除文档 3 ，参考 <a href="#match-precision">控制精度</a> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>现在在查询里添加 <code>shingles</code> 字段。不要忘了在 <code>shingles</code> 字段上的匹配是充当一
种信号&#8212;&#8203;为了提高相关度评分&#8212;&#8203;所以我们仍然需要将基本 <code>title</code> 字段包含到查询中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
   "query": {
      "bool": {
         "must": {
            "match": {
               "title": "the hungry alligator ate sue"
            }
         },
         "should": {
            "match": {
               "title.shingles": "the hungry alligator ate sue"
            }
         }
      }
   }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>仍然匹配到了所有的 3 个文档， 但是文档 2 现在排到了第一名因为它匹配了 shingled 词项 <code>ate sue</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id": "2",
        "_score": 0.4883322,
        "_source": {
           "title": "The alligator ate Sue"
        }
     },
     {
        "_id": "1",
        "_score": 0.13422975,
        "_source": {
           "title": "Sue ate the alligator"
        }
     },
     {
        "_id": "3",
        "_score": 0.014119488,
        "_source": {
           "title": "Sue never goes anywhere without her alligator skin purse"
        }
     }
  ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>即使查询包含的单词 <code>hungry</code> 没有在任何文档中出现，我们仍然使用单词邻近度返回了最相关的文档。</p>
</div>
</div>
<div class="sect3">
<h4 id="_performance性能">Performance性能</h4>
<div class="paragraph">
<p>shingles 不仅比短语查询更灵活，而且性能也更好。
shingles 查询跟一个简单的 <code>match</code> 查询一样高效，而不用每次搜索花费短语查询的代价。只是在索引期间因为更多词项需要被索引会付出一些小的代价，
这也意味着有 shingles 的字段会占用更多的磁盘空间。
然而，大多数应用写入一次而读取多次，所以在索引期间优化我们的查询速度是有意义的。</p>
</div>
<div class="paragraph">
<p>这是一个在 Elasticsearch 里会经常碰到的话题：不需要任何前期进行过多的设置，就能够在搜索的时候有很好的效果。
一旦更清晰的理解了自己的需求，就能在索引时通过正确的为你的数据建模获得更好结果和性能。
</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="partial-matching">部分匹配</h2>
<div class="sectionbody">
<div class="paragraph">
<p>敏锐的读者会注意，目前为止本书介绍的所有查询都是针对整个词的操作。为了能匹配，只能查找倒排索引中存在的词，最小的单元为单个词。</p>
</div>
<div class="paragraph">
<p>但如果想匹配部分而不是全部的词该怎么办？ <em>部分匹配</em> 允许用户指定查找词的一部分并找出所有包含这部分片段的词。</p>
</div>
<div class="paragraph">
<p>与想象的不太一样，对词进行部分匹配的需求在全文搜索引擎领域并不常见，但是如果读者有 SQL 方面的背景，可能会在某个时候实现一个 <em>低效的全文搜索</em> 用下面的 SQL 语句对全文进行搜索：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">    WHERE text LIKE "%quick%"
      AND text LIKE "%brown%"
      AND text LIKE "%fox%" <b class="conum">(1)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code><strong>fox</strong></code> 会与 “fox” 和 “foxes” 匹配。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>当然， Elasticsearch 提供分析过程，倒排索引让我们不需要使用这种粗笨的技术。为了能应对同时匹配 “fox” 和 “foxes” 的情况，只需简单的将它们的词干作为索引形式，没有必要做部分匹配。</p>
</div>
<div class="paragraph">
<p>也就是说，在某些情况下部分匹配会比较有用，常见的应用如下：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>匹配邮编、产品序列号或其他 <code>not_analyzed</code> 未分析值，这些值可以是以某个特定前缀开始，也可以是与某种模式匹配的，甚至可以是与某个正则式相匹配的。</p>
</li>
<li>
<p><em>输入即搜索（search-as-you-type）</em> ——在用户键入搜索词过程的同时就呈现最可能的结果。</p>
</li>
<li>
<p>匹配如德语或荷兰语这样有长组合词的语言，如： <em>Weltgesundheitsorganisation</em> （世界卫生组织，英文 World Health Organization）。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>本章始于检验 <code>not_analyzed</code> 精确值字段的前缀匹配。</p>
</div>
<div class="sect2">
<h3 id="_postcodes_and_structured_data">邮编与结构化数据</h3>
<div class="paragraph">
<p>我们会使用美国目前使用的邮编形式（United Kingdom postcodes 标准）来说明如何用部分匹配查询结构化数据。这种邮编形式有很好的结构定义。例如，邮编 <code>W1V 3DG</code> 可以分解成如下形式：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>W1V</code> ：这是邮编的外部，它定义了邮件的区域和行政区：</p>
<div class="ulist">
<ul>
<li>
<p><code>W</code> 代表区域（ 1 或 2 个字母）</p>
</li>
<li>
<p><code>1V</code> 代表行政区（ 1 或 2 个数字，可能跟着一个字符）</p>
</li>
</ul>
</div>
</li>
<li>
<p><code>3DG</code> ：内部定义了街道或建筑：</p>
<div class="ulist">
<ul>
<li>
<p><code>3</code> 代表街区区块（ 1 个数字）</p>
</li>
<li>
<p><code>DG</code> 代表单元（ 2 个字母）</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>假设将邮编作为 <code>not_analyzed</code> 的精确值字段索引，所以可以为其创建索引，如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index
{
    "mappings": {
        "address": {
            "properties": {
                "postcode": {
                    "type":  "string",
                    "index": "not_analyzed"
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>然后索引一些邮编：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index/address/1
{ "postcode": "W1V 3DG" }

PUT /my_index/address/2
{ "postcode": "W2F 8HW" }

PUT /my_index/address/3
{ "postcode": "W1F 7HW" }

PUT /my_index/address/4
{ "postcode": "WC1N 1LZ" }

PUT /my_index/address/5
{ "postcode": "SW5 0BE" }</code></pre>
</div>
</div>
<div class="paragraph">
<p>现在这些数据已可查询。</p>
</div>
</div>
<div class="sect2">
<h3 id="prefix-query">prefix 前缀查询</h3>
<div class="paragraph">
<p>为了找到所有以 <code>W1</code> 开始的邮编，可以使用简单的 <code>prefix</code> 查询：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/address/_search
{
    "query": {
        "prefix": {
            "postcode": "W1"
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>prefix</code> 查询是一个词级别的底层的查询，它不会在搜索之前分析查询字符串，它假定传入前缀就正是要查找的前缀。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>默认状态下， <code>prefix</code> 查询不做相关度评分计算，它只是将所有匹配的文档返回，并为每条结果赋予评分值 <code>1</code> 。它的行为更像是过滤器而不是查询。 <code>prefix</code> 查询和 <code>prefix</code> 过滤器这两者实际的区别就是过滤器是可以被缓存的，而查询不行。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>之前已经提过：“只能在倒排索引中找到存在的词”，但我们并没有对这些邮编的索引进行特殊处理，每个邮编还是以它们精确值的方式存在于每个文档的索引中，那么 <code>prefix</code> 查询是如何工作的呢？</p>
</div>
<div class="paragraph pagebreak-after">
<p>回想倒排索引包含了一个有序的唯一词列表（本例是邮编）。对于每个词，倒排索引都会将包含词的文档 ID 列入 <em>倒排表（postings list）</em> 。与示例对应的倒排索引是：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>Term:          Doc IDs:
-------------------------
"SW5 0BE"    |  5
"W1F 7HW"    |  3
"W1V 3DG"    |  1
"W2F 8HW"    |  2
"WC1N 1LZ"   |  4
-------------------------</pre>
</div>
</div>
<div class="paragraph">
<p>为了支持前缀匹配，查询会做以下事情：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>扫描词列表并查找到第一个以 <code>W1</code> 开始的词。</p>
</li>
<li>
<p>搜集关联的文档 ID 。</p>
</li>
<li>
<p>移动到下一个词。</p>
</li>
<li>
<p>如果这个词也是以 <code>W1</code> 开头，查询跳回到第二步再重复执行，直到下一个词不以 <code>W1</code> 为止。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这对于小的例子当然可以正常工作，但是如果倒排索引中有数以百万的邮编都是以 <code>W1</code> 开头时，前缀查询则需要访问每个词然后计算结果！</p>
</div>
<div class="paragraph">
<p>前缀越短所需访问的词越多。如果我们要以 <code>W</code> 作为前缀而不是 <code>W1</code> ，那么就可能需要做千万次的匹配。</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<div class="title">Caution</div>
</td>
<td class="content">
<code>prefix</code> 查询或过滤对于一些特定的匹配是有效的，但使用方式还是应当注意。当字段中词的集合很小时，可以放心使用，但是它的伸缩性并不好，会对我们的集群带来很多压力。可以使用较长的前缀来限制这种影响，减少需要访问的量。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>本章后面会介绍另一个索引时的解决方案，这个方案能使前缀匹配更高效，不过在此之前，需要先看看两个相关的查询： <code>wildcard</code> 和 <code>regexp</code> （模糊和正则）。</p>
</div>
</div>
<div class="sect2">
<h3 id="_wildcard_and_regexp_queries">通配符与正则表达式查询</h3>
<div class="paragraph">
<p>与 <code>prefix</code> 前缀查询的特性类似， <code>wildcard</code> 通配符查询也是一种底层基于词的查询，与前缀查询不同的是它允许指定匹配的正则式。它使用标准的 shell 通配符查询： <code>?</code> 匹配任意字符， <code>*</code> 匹配 0 或多个字符。</p>
</div>
<div class="paragraph">
<p>这个查询会匹配包含 <code>W1F 7HW</code> 和 <code>W2F 8HW</code> 的文档：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/address/_search
{
    "query": {
        "wildcard": {
            "postcode": "W?F*HW" <b class="conum">(1)</b>
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>?</code> 匹配 <code>1</code> 和 <code>2</code> ， <code>*</code> 与空格及 <code>7</code> 和 <code>8</code> 匹配。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>设想如果现在只想匹配 <code>W</code> 区域的所有邮编，前缀匹配也会包括以 <code>WC</code> 开头的所有邮编，与通配符匹配碰到的问题类似，如果想匹配只以 <code>W</code> 开始并跟随一个数字的所有邮编， <code>regexp</code> 正则式查询允许写出这样更复杂的模式：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/address/_search
{
    "query": {
        "regexp": {
            "postcode": "W[0-9].+" <b class="conum">(1)</b>
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>这个正则表达式要求词必须以 <code>W</code> 开头，紧跟 0 至 9 之间的任何一个数字，然后接一或多个其他字符。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><code>wildcard</code> 和 <code>regexp</code> 查询的工作方式与 <code>prefix</code> 查询完全一样，它们也需要扫描倒排索引中的词列表才能找到所有匹配的词，然后依次获取每个词相关的文档 ID ，与 <code>prefix</code> 查询的唯一不同是：它们能支持更为复杂的匹配模式。</p>
</div>
<div class="paragraph">
<p>这也意味着需要同样注意前缀查询存在性能问题，对有很多唯一词的字段执行这些查询可能会消耗非常多的资源，所以要避免使用左通配这样的模式匹配（如： <code>*foo</code> 或 <code>.*foo</code> 这样的正则式）。</p>
</div>
<div class="paragraph">
<p>数据在索引时的预处理有助于提高前缀匹配的效率，而通配符和正则表达式查询只能在查询时完成，尽管这些查询有其应用场景，但使用仍需谨慎。</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<div class="title">Caution</div>
</td>
<td class="content">
<div class="paragraph">
<p><code>prefix</code> 、 <code>wildcard</code> 和 <code>regexp</code> 查询是基于词操作的，如果用它们来查询 <code>analyzed</code> 字段，它们会检查字段里面的每个词，而不是将字段作为整体来处理。</p>
</div>
<div class="paragraph">
<p>比方说包含 “Quick brown fox” （快速的棕色狐狸）的 <code>title</code> 字段会生成词： <code>quick</code> 、 <code>brown</code> 和 <code>fox</code> 。</p>
</div>
<div class="paragraph">
<p>会匹配以下这个查询：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">{ "regexp": { "title": "br.*" }}</code></pre>
</div>
</div>
<div class="paragraph">
<p>但是不会匹配以下两个查询：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">{ "regexp": { "title": "Qu.*" }} <b class="conum">(1)</b>
{ "regexp": { "title": "quick br*" }} <b class="conum">(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>在索引里的词是 <code>quick</code> 而不是 <code>Quick</code> 。</p>
</li>
<li>
<p><code>quick</code> 和 <code>brown</code> 在词表中是分开的。</p>
</li>
</ol>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_query_time_search_as_you_type">查询时输入即搜索</h3>
<div class="paragraph">
<p>把邮编的事情先放一边，让我们先看看前缀查询是如何在全文查询中起作用的。用户已经渐渐习惯在输完查询内容之前，就能为他们展现搜索结果，这就是所谓的 <em>即时搜索（instant search）</em> 或 <em>输入即搜索（search-as-you-type）</em> 。不仅用户能在更短的时间内得到搜索结果，我们也能引导用户搜索索引中真实存在的结果。</p>
</div>
<div class="paragraph">
<p>例如，如果用户输入 <code>johnnie walker bl</code> ，我们希望在它们完成输入搜索条件前就能得到：Johnnie Walker Black Label 和 Johnnie Walker Blue Label 。</p>
</div>
<div class="paragraph">
<p>生活总是这样，就像猫的花色远不只一种！我们希望能找到一种最简单的实现方式。并不需要对数据做任何准备，在查询时就能对任意的全文字段实现 <em>输入即搜索（search-as-you-type）</em> 的查询。</p>
</div>
<div class="paragraph">
<p>在 <a href="#phrase-matching">短语匹配</a> 中，我们引入了 <code>match_phrase</code> 短语匹配查询，它匹配相对顺序一致的所有指定词语，对于查询时的输入即搜索，可以使用 <code>match_phrase</code> 的一种特殊形式， <code>match_phrase_prefix</code> 查询：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "match_phrase_prefix" : {
        "brand" : "johnnie walker bl"
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这种查询的行为与 <code>match_phrase</code> 查询一致，不同的是它将查询字符串的最后一个词作为前缀使用，换句话说，可以将之前的例子看成如下这样：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>johnnie</code></p>
</li>
<li>
<p>跟着 <code>walker</code></p>
</li>
<li>
<p>跟着以 <code>bl</code> 开始的词</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>如果通过 <code>validate-query</code> API 运行这个查询查询，explanation 的解释结果为：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>"johnnie walker bl*"</pre>
</div>
</div>
<div class="paragraph">
<p>与 <code>match_phrase</code> 一样，它也可以接受 <code>slop</code> 参数（参照 <a href="#slop">slop</a> ）让相对词序位置不那么严格：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "match_phrase_prefix" : {
        "brand" : {
            "query": "walker johnnie bl", <b class="conum">(1)</b>
            "slop":  10
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>尽管词语的顺序不正确，查询仍然能匹配，因为我们为它设置了足够高的 <code>slop</code> 值使匹配时的词序有更大的灵活性。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>但是只有查询字符串的最后一个词才能当作前缀使用。</p>
</div>
<div class="paragraph">
<p>在之前的 <a href="#prefix-query">前缀查询</a> 中，我们警告过使用前缀的风险，即 <code>prefix</code> 查询存在严重的资源消耗问题，短语查询的这种方式也同样如此。前缀 <code>a</code> 可能会匹配成千上万的词，这不仅会消耗很多系统资源，而且结果的用处也不大。</p>
</div>
<div class="paragraph">
<p>可以通过设置 <code>max_expansions</code> 参数来限制前缀扩展的影响，一个合理的值是可能是 50 ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "match_phrase_prefix" : {
        "brand" : {
            "query":          "johnnie walker bl",
            "max_expansions": 50
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>参数 <code>max_expansions</code> 控制着可以与前缀匹配的词的数量，它会先查找第一个与前缀 <code>bl</code> 匹配的词，然后依次查找搜集与之匹配的词（按字母顺序），直到没有更多可匹配的词或当数量超过 <code>max_expansions</code> 时结束。</p>
</div>
<div class="paragraph">
<p>不要忘记，当用户每多输入一个字符时，这个查询又会执行一遍，所以查询需要快，如果第一个结果集不是用户想要的，他们会继续输入直到能搜出满意的结果为止。</p>
</div>
</div>
<div class="sect2">
<h3 id="_index_time_optimizations">索引时优化</h3>
<div class="paragraph">
<p>到目前为止，所有谈论过的解决方案都是在 <em>查询时（query time）</em> 实现的。这样做并不需要特殊的映射或特殊的索引模式，只是简单使用已经索引的数据。</p>
</div>
<div class="paragraph">
<p>查询时的灵活性通常会以牺牲搜索性能为代价，有时候将这些消耗从查询过程中转移到别的地方是有意义的。在实时 web 应用中， 100 毫秒可能是一个难以忍受的巨大延迟。</p>
</div>
<div class="paragraph">
<p>可以通过在索引时处理数据提高搜索的灵活性以及提升系统性能。为此仍然需要付出应有的代价：增加的索引空间与变慢的索引能力，但这与每次查询都需要付出代价不同，索引时的代价只用付出一次。</p>
</div>
<div class="paragraph">
<p>用户会感谢我们。</p>
</div>
</div>
<div class="sect2">
<h3 id="_ngrams_for_partial_matching">Ngrams 在部分匹配的应用</h3>
<div class="paragraph">
<p>之前提到：“只能在倒排索引中找到存在的词。” 尽管 <code>prefix</code> 、 <code>wildcard</code> 、 <code>regexp</code> 查询告诉我们这种说法并不完全正确，但单个词的查找 <em>确实</em> 要比在词列表中盲目挨个查找的效率要高得多。在搜索之前准备好供部分匹配的数据可以提高搜索的性能。</p>
</div>
<div class="paragraph">
<p>在索引时准备数据意味着要选择合适的分析链，这里部分匹配使用的工具是 <em>n-gram</em> 。可以将 <em>n-gram</em> 看成一个在词语上 <em>滑动窗口</em> ， <em>n</em> 代表这个 “窗口” 的长度。如果我们要 n-gram <code>quick</code> 这个词 —— 它的结果取决于 <em>n</em> 的选择长度：</p>
</div>
<div class="ulist horizontal">
<ul class="horizontal">
<li>
<p>长度 1（unigram）：    [ <code>q</code>, <code>u</code>, <code>i</code>, <code>c</code>, <code>k</code> ]</p>
</li>
<li>
<p>长度 2（bigram）：     [ <code>qu</code>, <code>ui</code>, <code>ic</code>, <code>ck</code> ]</p>
</li>
<li>
<p>长度 3（trigram）：    [ <code>qui</code>, <code>uic</code>, <code>ick</code> ]</p>
</li>
<li>
<p>长度 4（four-gram）：  [ <code>quic</code>, <code>uick</code> ]</p>
</li>
<li>
<p>长度 5（five-gram）：  [ <code>quick</code> ]</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>朴素的 n-gram 对 <em>词语内部的匹配</em> 非常有用，即在 <a href="#ngrams-compound-words">Ngram 匹配复合词</a> 介绍的那样。但对于输入即搜索（search-as-you-type）这种应用场景，我们会使用一种特殊的 n-gram 称为 <em>边界 n-grams</em> （edge n-grams）。所谓的边界 n-gram 是说它会固定词语开始的一边，以单词 <code>quick</code> 为例，它的边界 n-gram 的结果为：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>q</code></p>
</li>
<li>
<p><code>qu</code></p>
</li>
<li>
<p><code>qui</code></p>
</li>
<li>
<p><code>quic</code></p>
</li>
<li>
<p><code>quick</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>可能会注意到这与用户在搜索时输入 “quick” 的字母次序是一致的，换句话说，这种方式正好满足即时搜索（instant search）！</p>
</div>
</div>
<div class="sect2">
<h3 id="_index_time_search_as_you_type">索引时输入即搜索</h3>
<div class="paragraph">
<p>设置索引时输入即搜索的第一步是需要定义好分析链，我们已在 <a href="#configuring-analyzers">配置分析器</a> 中讨论过，这里会对这些步骤再次说明。</p>
</div>
<div class="sect3">
<h4 id="_准备索引">准备索引</h4>
<div class="paragraph">
<p>第一步需要配置一个自定义的 <code>edge_ngram</code> token 过滤器，称为 <code>autocomplete_filter</code> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "filter": {
        "autocomplete_filter": {
            "type":     "edge_ngram",
            "min_gram": 1,
            "max_gram": 20
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个配置的意思是：对于这个 token 过滤器接收的任意词项，过滤器会为之生成一个最小固定值为 1 ，最大为 20 的 n-gram 。</p>
</div>
<div class="paragraph">
<p>然后会在一个自定义分析器 <code>autocomplete</code> 中使用上面这个 token 过滤器：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "analyzer": {
        "autocomplete": {
            "type":      "custom",
            "tokenizer": "standard",
            "filter": [
                "lowercase",
                "autocomplete_filter" <b class="conum">(1)</b>
            ]
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>自定义的 edge-ngram token 过滤器。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这个分析器使用 <code>standard</code> 分词器将字符串拆分为独立的词，并且将它们都变成小写形式，然后为每个词生成一个边界 n-gram，这要感谢 <code>autocomplete_filter</code> 起的作用。</p>
</div>
<div class="paragraph">
<p>创建索引、实例化 token 过滤器和分析器的完整示例如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index
{
    "settings": {
        "number_of_shards": 1, <b class="conum">(1)</b>
        "analysis": {
            "filter": {
                "autocomplete_filter": { <b class="conum">(2)</b>
                    "type":     "edge_ngram",
                    "min_gram": 1,
                    "max_gram": 20
                }
            },
            "analyzer": {
                "autocomplete": {
                    "type":      "custom",
                    "tokenizer": "standard",
                    "filter": [
                        "lowercase",
                        "autocomplete_filter" <b class="conum">(3)</b>
                    ]
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>参考 <a href="#relevance-is-broken">被破坏的相关度</a> 。</p>
</li>
<li>
<p>首先自定义 token 过滤器。</p>
</li>
<li>
<p>然后在分析器中使用它。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>可以拿 <code>analyze</code> API 测试这个新的分析器确保它行为正确：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/_analyze?analyzer=autocomplete
quick brown</code></pre>
</div>
</div>
<div class="paragraph">
<p>结果表明分析器能正确工作，并返回以下词：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>q</code></p>
</li>
<li>
<p><code>qu</code></p>
</li>
<li>
<p><code>qui</code></p>
</li>
<li>
<p><code>quic</code></p>
</li>
<li>
<p><code>quick</code></p>
</li>
<li>
<p><code>b</code></p>
</li>
<li>
<p><code>br</code></p>
</li>
<li>
<p><code>bro</code></p>
</li>
<li>
<p><code>brow</code></p>
</li>
<li>
<p><code>brown</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>可以用 <code>update-mapping</code> API 将这个分析器应用到具体字段：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index/_mapping/my_type
{
    "my_type": {
        "properties": {
            "name": {
                "type":     "string",
                "analyzer": "autocomplete"
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>现在创建一些测试文档：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">POST /my_index/my_type/_bulk
{ "index": { "_id": 1            }}
{ "name": "Brown foxes"    }
{ "index": { "_id": 2            }}
{ "name": "Yellow furballs" }</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_查询字段">查询字段</h4>
<div class="paragraph">
<p>如果使用简单 <code>match</code> 查询测试查询 “brown fo” ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
    "query": {
        "match": {
            "name": "brown fo"
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>可以看到两个文档同时 <em>都能</em> 匹配，尽管 <code>Yellow furballs</code> 这个文档并不包含 <code>brown</code> 和 <code>fo</code> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{

  "hits": [
     {
        "_id": "1",
        "_score": 1.5753809,
        "_source": {
           "name": "Brown foxes"
        }
     },
     {
        "_id": "2",
        "_score": 0.012520773,
        "_source": {
           "name": "Yellow furballs"
        }
     }
  ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如往常一样， <code>validate-query</code> API 总能提供一些线索：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_validate/query?explain
{
    "query": {
        "match": {
            "name": "brown fo"
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>explanation</code> 表明查询会查找边界 n-grams 里的每个词：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>name:b name:br name:bro name:brow name:brown name:f name:fo</pre>
</div>
</div>
<div class="paragraph">
<p><code>name:f</code> 条件可以满足第二个文档，因为 <code>furballs</code> 是以 <code>f</code> 、 <code>fu</code> 、 <code>fur</code> 形式索引的。回过头看这并不令人惊讶，相同的 <code>autocomplete</code> 分析器同时被应用于索引时和搜索时，这在大多数情况下是正确的，只有在少数场景下才需要改变这种行为。</p>
</div>
<div class="paragraph">
<p>我们需要保证倒排索引表中包含边界 n-grams 的每个词，但是我们只想匹配用户输入的完整词组（ <code>brown</code> 和 <code>fo</code> ），可以通过在索引时使用 <code>autocomplete</code> 分析器，并在搜索时使用 <code>standard</code> 标准分析器来实现这种想法，只要改变查询使用的搜索分析器 <code>analyzer</code> 参数即可：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
    "query": {
        "match": {
            "name": {
                "query":    "brown fo",
                "analyzer": "standard" <b class="conum">(1)</b>
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>覆盖了 <code>name</code> 字段 <code>analyzer</code> 的设置。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>换种方式，我们可以在映射中，为 <code>name</code> 字段分别指定 <code>index_analyzer</code> 和 <code>search_analyzer</code> 。因为我们只想改变 <code>search_analyzer</code> ，这里只要更新现有的映射而不用对数据重新创建索引：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index/my_type/_mapping
{
    "my_type": {
        "properties": {
            "name": {
                "type":            "string",
                "index_analyzer":  "autocomplete", <b class="conum">(1)</b>
                "search_analyzer": "standard" <b class="conum">(2)</b>
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>在索引时，使用 <code>autocomplete</code> 分析器生成边界 n-grams 的每个词。</p>
</li>
<li>
<p>在搜索时，使用 <code>standard</code> 分析器只搜索用户输入的词。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>如果再次请求 <code>validate-query</code> API ，当前的解释为：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>name:brown name:fo</pre>
</div>
</div>
<div class="paragraph">
<p>再次执行查询就能正确返回 <code>Brown foxes</code> 这个文档。</p>
</div>
<div class="paragraph">
<p>因为大多数工作是在索引时完成的，所有的查询只要查找 <code>brown</code> 和 <code>fo</code> 这两个词，这比使用 <code>match_phrase_prefix</code> 查找所有以 <code>fo</code> 开始的词的方式要高效许多。</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">补全提示（Completion Suggester）</div>
<div class="paragraph">
<p>使用边界 n-grams 进行输入即搜索（search-as-you-type）的查询设置简单、灵活且快速，但有时候它并不够快，特别是当试图立刻获得反馈时，延迟的问题就会凸显，很多时候不搜索才是最快的搜索方式。</p>
</div>
<div class="paragraph">
<p>Elasticsearch 里的 {ref}/search-suggesters-completion.html[completion suggester] 采用与上面完全不同的方式，需要为搜索条件生成一个所有可能完成的词列表，然后将它们置入一个 <em>有限状态机（finite state transducer）</em> 内，这是个经优化的图结构。为了搜索建议提示，Elasticsearch 从图的开始处顺着匹配路径一个字符一个字符地进行匹配，一旦它处于用户输入的末尾，Elasticsearch 就会查找所有可能结束的当前路径，然后生成一个建议列表。</p>
</div>
<div class="paragraph">
<p>本数据结构存于内存中，能使前缀查找非常快，比任何一种基于词的查询都要快很多，这对名字或品牌的自动补全非常适用，因为这些词通常是以普通顺序组织的：用 “Johnny Rotten” 而不是 “Rotten Johnny” 。</p>
</div>
<div class="paragraph">
<p>当词序不是那么容易被预见时，边界 n-grams 比完成建议者（Completion Suggester）更合适。即使说不是所有猫都是一个花色，那这只猫的花色也是相当特殊的。</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_边界_n_grams_与邮编">边界 n-grams 与邮编</h4>
<div class="paragraph">
<p>边界 n-gram 的方式可以用来查询结构化的数据，比如 <a href="#prefix-query">本章之前示例</a> 中的邮编（postcode）。当然 <code>postcode</code> 字段需要 <code>analyzed</code> 而不是 <code>not_analyzed</code> ，不过可以用 <code>keyword</code> 分词器来处理它，就好像他们是 <code>not_analyzed</code> 的一样。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p><code>keyword</code> 分词器是一个非操作型分词器，这个分词器不做任何事情，它接收的任何字符串都会被原样发出，因此它可以用来处理 <code>not_analyzed</code> 的字段值，但这也需要其他的一些分析转换，如将字母转换成小写。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>下面示例使用 <code>keyword</code> 分词器将邮编转换成 token 流，这样就能使用边界 n-gram token 过滤器：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
    "analysis": {
        "filter": {
            "postcode_filter": {
                "type":     "edge_ngram",
                "min_gram": 1,
                "max_gram": 8
            }
        },
        "analyzer": {
            "postcode_index": { <b class="conum">(1)</b>
                "tokenizer": "keyword",
                "filter":    [ "postcode_filter" ]
            },
            "postcode_search": { <b class="conum">(2)</b>
                "tokenizer": "keyword"
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>postcode_index</code> 分析器使用 <code>postcode_filter</code> 将邮编转换成边界 n-gram 形式。</p>
</li>
<li>
<p><code>postcode_search</code> 分析器可以将搜索词看成 <code>not_analyzed</code> 未分析的。</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="ngrams-compound-words">Ngrams 在复合词的应用</h3>
<div class="paragraph">
<p>最后，来看看 n-gram 是如何应用于搜索复合词的语言中的。德语的特点是它可以将许多小词组合成一个庞大的复合词以表达它准确或复杂的意义。例如：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><em>Aussprachewörterbuch</em></dt>
<dd>
<p>发音字典（Pronunciation dictionary）</p>
</dd>
<dt class="hdlist1"><em>Militärgeschichte</em></dt>
<dd>
<p>战争史（Military history）</p>
</dd>
<dt class="hdlist1"><em>Weißkopfseeadler</em></dt>
<dd>
<p>秃鹰（White-headed sea eagle, or bald eagle）</p>
</dd>
<dt class="hdlist1"><em>Weltgesundheitsorganisation</em></dt>
<dd>
<p>世界卫生组织（World Health Organization）</p>
</dd>
<dt class="hdlist1"><em>Rindfleischetikettierungsüberwachungsaufgabenübertragungsgesetz</em></dt>
<dd>
<p>法案考虑代理监管牛和牛肉的标记的职责（The law concerning the delegation of duties for the supervision of cattle marking and the labeling of beef）</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>有些人希望在搜索 “Wörterbuch”（字典）的时候，能在结果中看到 “Aussprachewörtebuch”（发音字典）。同样，搜索 “Adler”（鹰）的时候，能将 “Weißkopfseeadler”（秃鹰）包括在结果中。</p>
</div>
<div class="paragraph">
<p>处理这种语言的一种方式可以用
{ref}/analysis-compound-word-tokenfilter.html[组合词 token 过滤器（compound word token filter）]
将复合词拆分成各自部分，但这种方式的结果质量依赖于组合词字典的质量。</p>
</div>
<div class="paragraph">
<p>另一种方式就是将所有的词用 n-gram 进行处理，然后搜索任何匹配的片段——能匹配的片段越多，文档的相关度越大。</p>
</div>
<div class="paragraph">
<p>假设某个 n-gram 是一个词上的滑动窗口，那么任何长度的 n-gram 都可以遍历这个词。我们既希望选择足够长的值让拆分的词项具有意义，又不至于因为太长而生成过多的唯一词。一个长度为 3 的 <em>trigram</em> 可能是一个不错的开始：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">PUT /my_index
{
    "settings": {
        "analysis": {
            "filter": {
                "trigrams_filter": {
                    "type":     "ngram",
                    "min_gram": 3,
                    "max_gram": 3
                }
            },
            "analyzer": {
                "trigrams": {
                    "type":      "custom",
                    "tokenizer": "standard",
                    "filter":   [
                        "lowercase",
                        "trigrams_filter"
                    ]
                }
            }
        }
    },
    "mappings": {
        "my_type": {
            "properties": {
                "text": {
                    "type":     "string",
                    "analyzer": "trigrams" <b class="conum">(1)</b>
                }
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>text</code> 字段用 <code>trigrams</code> 分析器索引它的内容，这里 n-gram 的长度是 3 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>使用 <code>analyze</code> API 测试 trigram 分析器：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/_analyze?analyzer=trigrams
Weißkopfseeadler</code></pre>
</div>
</div>
<div class="paragraph">
<p>返回以下词项：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>wei, eiß, ißk, ßko, kop, opf, pfs, fse, see, eea,ead, adl, dle, ler</pre>
</div>
</div>
<div class="paragraph">
<p>索引前述示例中的复合词来测试：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">POST /my_index/my_type/_bulk
{ "index": { "_id": 1 }}
{ "text": "Aussprachewörterbuch" }
{ "index": { "_id": 2 }}
{ "text": "Militärgeschichte" }
{ "index": { "_id": 3 }}
{ "text": "Weißkopfseeadler" }
{ "index": { "_id": 4 }}
{ "text": "Weltgesundheitsorganisation" }
{ "index": { "_id": 5 }}
{ "text": "Rindfleischetikettierungsüberwachungsaufgabenübertragungsgesetz" }</code></pre>
</div>
</div>
<div class="paragraph">
<p>“Adler”（鹰）的搜索转化为查询三个词 <code>adl</code> 、 <code>dle</code> 和 <code>ler</code> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
    "query": {
        "match": {
            "text": "Adler"
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>正好与 “Weißkopfsee-<em>adler</em>” 相匹配：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">{
  "hits": [
     {
        "_id": "3",
        "_score": 3.3191128,
        "_source": {
           "text": "Weißkopfseeadler"
        }
     }
  ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>类似查询 “Gesundheit”（健康）可以与 “Welt-gesundheit-sorganisation” 匹配，同时也能与 “Militär-<em>ges</em>-chichte” 和 “Rindfleischetikettierungsüberwachungsaufgabenübertragungs-<em>ges</em>-etz” 匹配，因为它们同时都有 trigram 生成的 <code>ges</code> ：</p>
</div>
<div class="paragraph">
<p>使用合适的 <code>minimum_should_match</code> 可以将这些奇怪的结果排除，只有当 trigram 最少匹配数满足要求时，文档才能被认为是匹配的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-js" data-lang="js">GET /my_index/my_type/_search
{
    "query": {
        "match": {
            "text": {
                "query":                "Gesundheit",
                "minimum_should_match": "80%"
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这有点像全文搜索中霰弹枪式的策略，可能会导致倒排索引内容变多，尽管如此，在索引具有很多复合词的语言，或词之间没有空格的语言（如：泰语）时，它仍不失为一种通用且有效的方法。</p>
</div>
<div class="paragraph">
<p>这种技术可以用来提升 <em>召回率</em> ——搜索结果中相关的文档数。它通常会与其他技术一起使用，例如 shingles（参见 <a href="#shingles">shingles 瓦片词</a> ），以提高精度和每个文档的相关度评分。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="controlling-relevance">控制相关度</h2>
<div class="sectionbody">
<div class="paragraph">
<p>处理结构化数据（比如：时间、数字、字符串、枚举）的数据库，只需检查文档（或关系数据库里的行）是否与查询匹配。</p>
</div>
<div class="paragraph">
<p>布尔的是/非匹配是全文搜索的基础，但不止如此，我们还要知道每个文档与查询的相关度，在全文搜索引擎中不仅需要找到匹配的文档，还需根据它们相关度的高低进行排序。</p>
</div>
<div class="paragraph">
<p>全文相关的公式或 <em>相似算法（similarity algorithms）</em> 会将多个因素合并起来，为每个文档生成一个相关度评分 <code>_score</code> 。本章中，我们会验证各种可变部分，然后讨论如何来控制它们。</p>
</div>
<div class="paragraph">
<p>当然，相关度不只与全文查询有关，也需要将结构化的数据考虑其中。可能我们正在找一个度假屋，需要一些的详细特征（空调、海景、免费 WiFi ），匹配的特征越多相关度越高。可能我们还希望有一些其他的考虑因素，如回头率、价格、受欢迎度或距离，当然也同时考虑全文查询的相关度。</p>
</div>
<div class="paragraph">
<p>所有的这些都可以通过 Elasticsearch 强大的评分基础来实现。</p>
</div>
<div class="paragraph">
<p>本章会先从理论上介绍 Lucene 是如何计算相关度的，然后通过实际例子说明如何控制相关度的计算过程。</p>
</div>
<div class="sect2">
<h3 id="scoring-theory">相关度评分背后的理论</h3>
<div class="paragraph">
<p>Lucene（或 Elasticsearch）使用 <a href="http://en.wikipedia.org/wiki/Standard_Boolean_model"><em>布尔模型（Boolean model）</em></a> 查找匹配文档，并用一个名为 <a href="#practical-scoring-function"><em>实用评分函数（practical scoring function）</em></a> 的公式来计算相关度。这个公式借鉴了 <a href="http://en.wikipedia.org/wiki/Tfidf"><em>词频/逆向文档频率（term frequency/inverse document frequency）</em></a> 和 <a href="http://en.wikipedia.org/wiki/Vector_space_model"><em>向量空间模型（vector space model）</em></a>，同时也加入了一些现代的新特性，如协调因子（coordination factor），字段长度归一化（field length normalization），以及词或查询语句权重提升。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>不要紧张！这些概念并没有像它们字面看起来那么复杂，尽管本小节提到了算法、公式和数学模型，但内容还是让人容易理解的，与理解算法本身相比，了解这些因素如何影响结果更为重要。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="boolean-model">布尔模型</h4>
<div class="paragraph">
<p><em>布尔模型（Boolean Model）</em> 只是在查询中使用 <code>AND</code> 、 <code>OR</code> 和 <code>NOT</code> （与、或和非）这样的条件来查找匹配的文档，以下查询：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>full AND text AND search AND (elasticsearch OR lucene)</pre>
</div>
</div>
<div class="paragraph">
<p>会将所有包括词 <code>full</code> 、 <code>text</code> 和 <code>search</code> ，以及 <code>elasticsearch</code> 或 <code>lucene</code> 的文档作为结果集。</p>
</div>
<div class="paragraph">
<p>这个过程简单且快速，它将所有可能不匹配的文档排除在外。</p>
</div>
</div>
<div class="sect3">
<h4 id="tfidf">词频/逆向文档频率（TF/IDF）</h4>
<div class="paragraph">
<p>当匹配到一组文档后，需要根据相关度排序这些文档，不是所有的文档都包含所有词，有些词比其他的词更重要。一个文档的相关度评分部分取决于每个查询词在文档中的 <em>权重</em> 。</p>
</div>
<div class="paragraph">
<p>词的权重由三个因素决定，在 <a href="#relevance-intro">什么是相关</a> 中已经有所介绍，有兴趣可以了解下面的公式，但并不要求记住。</p>
</div>
<div class="sect4">
<h5 id="tf">词频</h5>
<div class="paragraph">
<p>词在文档中出现的频度是多少？频度越高，权重 <em>越高</em> 。 5 次提到同一词的字段比只提到 1 次的更相关。词频的计算方式如下：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>tf(t in d) = √frequency <b class="conum">(1)</b></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>词 <code>t</code> 在文档 <code>d</code> 的词频（ <code>tf</code> ）是该词在文档中出现次数的平方根。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>如果不在意词在某个字段中出现的频次，而只在意是否出现过，则可以在字段映射中禁用词频统计：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">PUT /my_index
{
  "mappings": {
    "doc": {
      "properties": {
        "text": {
          "type":          "string",
          "index_options": "docs" <b class="conum">(1)</b>
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>将参数 <code>index_options</code> 设置为 <code>docs</code> 可以禁用词频统计及词频位置，这个映射的字段不会计算词的出现次数，对于短语或近似查询也不可用。要求精确查询的 <code>not_analyzed</code> 字符串字段会默认使用该设置。</p>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="idf">逆向文档频率</h5>
<div class="paragraph">
<p>词在集合所有文档里出现的频率是多少？频次越高，权重 <em>越低</em> 。常用词如 <code>and</code> 或 <code>the</code> 对相关度贡献很少，因为它们在多数文档中都会出现，一些不常见词如 <code>elastic</code> 或 <code>hippopotamus</code> 可以帮助我们快速缩小范围找到感兴趣的文档。逆向文档频率的计算公式如下：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>idf(t) = 1 + log ( numDocs / (docFreq + 1)) <b class="conum">(1)</b></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>词 <code>t</code> 的逆向文档频率（ <code>idf</code> ）是：索引中文档数量除以所有包含该词的文档数，然后求其对数。</p>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="field-norm">字段长度归一值</h5>
<div class="paragraph">
<p>字段的长度是多少？字段越短，字段的权重 <em>越高</em> 。如果词出现在类似标题 <code>title</code> 这样的字段，要比它出现在内容 <code>body</code> 这样的字段中的相关度更高。字段长度的归一值公式如下：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>norm(d) = 1 / √numTerms <b class="conum">(1)</b></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>字段长度归一值（ <code>norm</code> ）是字段中词数平方根的倒数。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>字段长度的归一值对全文搜索非常重要，许多其他字段不需要有归一值。无论文档是否包括这个字段，索引中每个文档的每个 <code>string</code> 字段都大约占用 1 个 byte 的空间。对于 <code>not_analyzed</code> 字符串字段的归一值默认是禁用的，而对于 <code>analyzed</code> 字段也可以通过修改字段映射禁用归一值：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">PUT /my_index
{
  "mappings": {
    "doc": {
      "properties": {
        "text": {
          "type": "string",
          "norms": { "enabled": false } <b class="conum">(1)</b>
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>这个字段不会将字段长度归一值考虑在内，长字段和短字段会以相同长度计算评分。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>对于有些应用场景如日志，归一值不是很有用，要关心的只是字段是否包含特殊的错误码或者特定的浏览器唯一标识符。字段的长度对结果没有影响，禁用归一值可以节省大量内存空间。</p>
</div>
</div>
<div class="sect4">
<h5 id="_结合使用">结合使用</h5>
<div class="paragraph">
<p>以下三个因素——词频（term frequency）、逆向文档频率（inverse document frequency）和字段长度归一值（field-length norm）——是在索引时计算并存储的。最后将它们结合在一起计算单个词在特定文档中的 <em>权重</em> 。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>前面公式中提到的 <em>文档</em> 实际上是指文档里的某个字段，每个字段都有它自己的倒排索引，因此字段的 TF/IDF 值就是文档的 TF/IDF 值。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>当用 <code>explain</code> 查看一个简单的 <code>term</code> 查询时（参见 <a href="#explain">explain</a> ），可以发现与计算相关度评分的因子就是前面章节介绍的这些：</p>
</div>
<div class="listingblock pagebreak-before">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">PUT /my_index/doc/1
{ "text" : "quick brown fox" }

GET /my_index/doc/_search?explain
{
  "query": {
    "term": {
      "text": "fox"
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>以上请求（简化）的 <code>explanation</code> 解释如下：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>weight(text:fox in 0) [PerFieldSimilarity]:  0.15342641 <b class="conum">(1)</b>
result of:
    fieldWeight in 0                         0.15342641
    product of:
        tf(freq=1.0), with freq of 1:        1.0 <b class="conum">(2)</b>
        idf(docFreq=1, maxDocs=1):           0.30685282 <b class="conum">(3)</b>
        fieldNorm(doc=0):                    0.5 <b class="conum">(4)</b></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>词 <code>fox</code> 在文档的内部 Lucene doc ID 为 <code>0</code> ，字段是 <code>text</code> 里的最终评分。</p>
</li>
<li>
<p>词 <code>fox</code> 在该文档 <code>text</code> 字段中只出现了一次。</p>
</li>
<li>
<p><code>fox</code> 在所有文档 <code>text</code> 字段索引的逆向文档频率。</p>
</li>
<li>
<p>该字段的字段长度归一值。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>当然，查询通常不止一个词，所以需要一种合并多词权重的方式——向量空间模型（vector space model）。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="vector-space-model">向量空间模型</h4>
<div class="paragraph">
<p><em>向量空间模型（vector space model）</em> 提供一种比较多词查询的方式，单个评分代表文档与查询的匹配程度，为了做到这点，这个模型将文档和查询都以 <em>向量（vectors）</em> 的形式表示：</p>
</div>
<div class="paragraph">
<p>向量实际上就是包含多个数的一维数组，例如：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>[1,2,5,22,3,8]</pre>
</div>
</div>
<div class="paragraph">
<p>在向量空间模型里，向量空间模型里的每个数字都代表一个词的 <em>权重</em> ，与 <a href="#tfidf">词频/逆向文档频率（term frequency/inverse document frequency）</a> 计算方式类似。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>尽管 TF/IDF 是向量空间模型计算词权重的默认方式，但不是唯一方式。Elasticsearch 还有其他模型如 Okapi-BM25 。TF/IDF 是默认的因为它是个经检验过的简单又高效的算法，可以提供高质量的搜索结果。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>设想如果查询 “happy hippopotamus” ，常见词 <code>happy</code> 的权重较低，不常见词 <code>hippopotamus</code> 权重较高，假设 <code>happy</code> 的权重是 2 ， <code>hippopotamus</code> 的权重是 5 ，可以将这个二维向量—— <code>[2,5]</code> ——在坐标系下作条直线，线的起点是 (0,0) 终点是 (2,5) ，如图 <a href="#img-vector-query">表示 “happy hippopotamus” 的二维查询向量</a> 。</p>
</div>
<div id="img-vector-query" class="imageblock">
<div class="content">
<img src="images/elas_17in01.png" alt="查询向量绘点图">
</div>
<div class="title">Figure 1. 表示 “happy hippopotamus” 的二维查询向量</div>
</div>
<div class="paragraph">
<p>现在，设想我们有三个文档：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>I am <em>happy</em> in summer 。</p>
</li>
<li>
<p>After Christmas I&#8217;m a <em>hippopotamus</em> 。</p>
</li>
<li>
<p>The <em>happy hippopotamus</em> helped Harry 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>可以为每个文档都创建包括每个查询词—— <code>happy</code> 和 <code>hippopotamus</code> ——权重的向量，然后将这些向量置入同一个坐标系中，如图 <a href="#img-vector-docs">“happy hippopotamus” 查询及文档向量</a> ：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>文档 1： <code>(happy,<em><em></em><em></em></em>__)</code> —— <code>[2,0]</code></p>
</li>
<li>
<p>文档 2： <code>( <em>_</em> ,hippopotamus)</code> —— <code>[0,5]</code></p>
</li>
<li>
<p>文档 3： <code>(happy,hippopotamus)</code> —— <code>[2,5]</code></p>
</li>
</ul>
</div>
<div id="img-vector-docs" class="imageblock">
<div class="content">
<img src="images/elas_17in02.png" alt="查询及文档向量绘点图">
</div>
<div class="title">Figure 2. “happy hippopotamus” 查询及文档向量</div>
</div>
<div class="paragraph">
<p>向量之间是可以比较的，只要测量查询向量和文档向量之间的角度就可以得到每个文档的相关度，文档 1 与查询之间的角度最大，所以相关度低；文档 2 与查询间的角度较小，所以更相关；文档 3 与查询的角度正好吻合，完全匹配。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>在实际中，只有二维向量（两个词的查询）可以在平面上表示，幸运的是， <em>线性代数</em> ——作为数学中处理向量的一个分支——为我们提供了计算两个多维向量间角度工具，这意味着可以使用如上同样的方式来解释多个词的查询。</p>
</div>
<div class="paragraph">
<p>关于比较两个向量的更多信息可以参考 <a href="http://en.wikipedia.org/wiki/Cosine_similarity"><em>余弦近似度（cosine similarity）</em></a>。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>现在已经讲完评分计算的基本理论，我们可以继续了解 Lucene 是如何实现评分计算的。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="practical-scoring-function">Lucene 的实用评分函数</h3>
<div class="paragraph">
<p>对于多词查询， Lucene 使用 <a href="#boolean-model">布尔模型（Boolean model）</a> 、 <a href="#tfidf">TF/IDF</a> 以及 <a href="#vector-space-model">向量空间模型（vector space model）</a> ，然后将它们组合到单个高效的包里以收集匹配文档并进行评分计算。</p>
</div>
<div class="paragraph">
<p>一个多词查询</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /my_index/doc/_search
{
  "query": {
    "match": {
      "text": "quick fox"
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>会在内部被重写为：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /my_index/doc/_search
{
  "query": {
    "bool": {
      "should": [
        {"term": { "text": "quick" }},
        {"term": { "text": "fox"   }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>bool</code> 查询实现了布尔模型，在这个例子中，它会将包括词 <code>quick</code> 和 <code>fox</code> 或两者兼有的文档作为查询结果。</p>
</div>
<div class="paragraph">
<p>只要一个文档与查询匹配，Lucene 就会为查询计算评分，然后合并每个匹配词的评分结果。这里使用的评分计算公式叫做 <em>实用评分函数（practical scoring function）</em> 。看似很高大上，但是别被吓到——多数的组件都已经介绍过，下一步会讨论它引入的一些新元素。</p>
</div>
<div class="literalblock">
<div class="content">
<pre>score(q,d)  =  <b class="conum">(1)</b>
            queryNorm(q)  <b class="conum">(2)</b>
          · coord(q,d)    <b class="conum">(3)</b>
          · ∑ (           <b class="conum">(4)</b>
                tf(t in d)   <b class="conum">(5)</b>
              · idf(t)²      <b class="conum">(6)</b>
              · t.getBoost() <b class="conum">(7)</b>
              · norm(t,d)    <b class="conum">(8)</b>
            ) (t in q)    <b class="conum">(4)</b></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>score(q,d)</code> 是文档 <code>d</code> 与查询 <code>q</code> 的相关度评分。</p>
</li>
<li>
<p><code>queryNorm(q)</code> 是 <a href="#query-norm"><em>查询归一化</em> 因子</a> （新）。</p>
</li>
<li>
<p><code>coord(q,d)</code> 是 <a href="#coord"><em>协调</em> 因子</a> （新）。</p>
</li>
<li>
<p>查询 <code>q</code> 中每个词 <code>t</code> 对于文档 <code>d</code> 的权重和。</p>
</li>
<li>
<p><code>tf(t in d)</code> 是词 <code>t</code> 在文档 <code>d</code> 中的 <a href="#tf">词频</a> 。</p>
</li>
<li>
<p><code>idf(t)</code> 是词 <code>t</code> 的 <a href="#idf">逆向文档频率</a> 。</p>
</li>
<li>
<p><code>t.getBoost()</code> 是查询中使用的 <a href="#query-time-boosting"><em>boost</em></a>（新）。</p>
</li>
<li>
<p><code>norm(t,d)</code> 是 <a href="#field-norm">字段长度归一值</a> ，与 <a href="#index-boost">索引时字段层 boost</a> （如果存在）的和（新）。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>上节已介绍过 <code>score</code> 、 <code>tf</code> 和 <code>idf</code> 。现在来介绍 <code>queryNorm</code> 、 <code>coord</code> 、 <code>t.getBoost</code> 和 <code>norm</code> 。</p>
</div>
<div class="paragraph">
<p>我们会在本章后面继续探讨 <a href="#query-time-boosting">查询时的权重提升</a> 的问题，但是首先需要了解查询归一化、协调和索引时字段层面的权重提升等概念。</p>
</div>
<div class="sect3">
<h4 id="query-norm">查询归一因子</h4>
<div class="paragraph">
<p><em>查询归一因子</em> （ <code>queryNorm</code> ）试图将查询 <em>归一化</em> ，这样就能将两个不同的查询结果相比较。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>尽管查询归一值的目的是为了使查询结果之间能够相互比较，但是它并不十分有效，因为相关度评分 <code>_score</code> 的目的是为了将当前查询的结果进行排序，比较不同查询结果的相关度评分没有太大意义。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>这个因子是在查询过程的最前面计算的，具体的计算依赖于具体查询，一个典型的实现如下：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>queryNorm = 1 / √sumOfSquaredWeights <b class="conum">(1)</b></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>sumOfSquaredWeights</code> 是查询里每个词的 IDF 的平方和。</p>
</li>
</ol>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
相同查询归一化因子会被应用到每个文档，不能被更改，总而言之，可以被忽略。
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="coord">查询协调</h4>
<div class="paragraph">
<p><em>协调因子</em> （ <code>coord</code> ）可以为那些查询词包含度高的文档提供奖励，文档里出现的查询词越多，它越有机会成为好的匹配结果。</p>
</div>
<div class="paragraph">
<p>设想查询 <code>quick brown fox</code> ，每个词的权重都是 1.5 。如果没有协调因子，最终评分会是文档里所有词权重的总和。例如：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>文档里有 <code>fox</code> &#8594; 评分： 1.5</p>
</li>
<li>
<p>文档里有 <code>quick fox</code> &#8594; 评分： 3.0</p>
</li>
<li>
<p>文档里有 <code>quick brown fox</code> &#8594; 评分： 4.5</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>协调因子将评分与文档里匹配词的数量相乘，然后除以查询里所有词的数量，如果使用协调因子，评分会变成：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>文档里有 <code>fox</code> &#8594; 评分： <code>1.5 * 1 / 3</code> = 0.5</p>
</li>
<li>
<p>文档里有 <code>quick fox</code> &#8594; 评分： <code>3.0 * 2 / 3</code> = 2.0</p>
</li>
<li>
<p>文档里有 <code>quick brown fox</code> &#8594; 评分： <code>4.5 * 3 / 3</code> = 4.5</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>协调因子能使包含所有三个词的文档比只包含两个词的文档评分要高出很多。</p>
</div>
<div class="paragraph">
<p>回想将查询 <code>quick brown fox</code> 重写成 <code>bool</code> 查询的形式：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "term": { "text": "quick" }},
        { "term": { "text": "brown" }},
        { "term": { "text": "fox"   }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>bool</code> 查询默认会对所有 <code>should</code> 语句使用协调功能，不过也可以将其禁用。为什么要这样做？通常的回答是——无须这样。查询协调通常是件好事，当使用 <code>bool</code> 查询将多个高级查询如 <code>match</code> 查询包裹的时候，让协调功能开启是有意义的，匹配的语句越多，查询请求与返回文档间的重叠度就越高。</p>
</div>
<div class="paragraph">
<p>但在某些高级应用中，将协调功能关闭可能更好。设想正在查找同义词 <code>jump</code> 、 <code>leap</code> 和 <code>hop</code> 时，并不关心会出现多少个同义词，因为它们都表示相同的意思，实际上，只有其中一个同义词会出现，这是不使用协调因子的一个好例子：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "bool": {
      "disable_coord": true,
      "should": [
        { "term": { "text": "jump" }},
        { "term": { "text": "hop"  }},
        { "term": { "text": "leap" }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>当使用同义词的时候（参照： <a href="#synonyms">同义词</a> ），Lucene 内部是这样的：重写的查询会禁用同义词的协调功能。大多数禁用操作的应用场景是自动处理的，无须为此担心。</p>
</div>
</div>
<div class="sect3">
<h4 id="index-boost">索引时字段层权重提升</h4>
<div class="paragraph">
<p>我们会讨论 <a href="#query-time-boosting">查询时的权重提升</a>，让字段 <em>权重提升</em> 就是让某个字段比其他字段更重要。当然在索引时也能做到如此。实际上，权重的提升会被应用到字段的每个词，而不是字段本身。</p>
</div>
<div class="paragraph">
<p>将提升值存储在索引中无须更多空间，这个字段层索引时的提升值与字段长度归一值（参见 <a href="#field-norm">字段长度归一值</a> ）一起作为单个字节存于索引， <code>norm(t,d)</code> 是前面公式的返回值。</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
<div class="paragraph">
<p>我们不建议在建立索引时对字段提升权重，有以下原因：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>将提升值与字段长度归一值合在单个字节中存储会丢失字段长度归一值的精度，这样会导致 Elasticsearch 不知如何区分包含三个词的字段和包含五个词的字段。</p>
</li>
<li>
<p>要想改变索引时的提升值，就必须重新为所有文档建立索引，与此不同的是，查询时的提升值可以随着每次查询的不同而更改。</p>
</li>
<li>
<p>如果一个索引时权重提升的字段有多个值，提升值会按照每个值来自乘，这会导致该字段的权重急剧上升。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><a href="#query-time-boosting">查询时赋予权重</a> 是更为简单、清楚、灵活的选择。</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>了解了查询归一化、协同和索引时权重提升这些方式后，可以进一步了解相关度计算最有用的工具：查询时的权重提升。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="query-time-boosting">查询时权重提升</h3>
<div class="paragraph">
<p>在 <a href="#prioritising-clauses">语句优先级（Prioritizing Clauses）</a> 中，我们解释过如何在搜索时使用 <code>boost</code> 参数让一个查询语句比其他语句更重要。例如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "bool": {
      "should": [
        {
          "match": {
            "title": {
              "query": "quick brown fox",
              "boost": 2 <b class="conum">(1)</b>
            }
          }
        },
        {
          "match": { <b class="conum">(2)</b>
            "content": "quick brown fox"
          }
        }
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>title</code> 查询语句的重要性是 <code>content</code> 查询的 2 倍，因为它的权重提升值为 <code>2</code> 。</p>
</li>
<li>
<p>没有设置 <code>boost</code> 的查询语句的值为 <code>1</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><em>查询时的权重提升</em> 是可以用来影响相关度的主要工具，任意类型的查询都能接受 <code>boost</code> 参数。将 <code>boost</code> 设置为 <code>2</code> ，并不代表最终的评分 <code>_score</code> 是原值的两倍；实际的权重值会经过归一化和一些其他内部优化过程。尽管如此，它确实想要表明一个提升值为 <code>2</code> 的句子的重要性是提升值为 <code>1</code> 语句的两倍。</p>
</div>
<div class="paragraph">
<p>在实际应用中，无法通过简单的公式得出某个特定查询语句的 <code>正确'' 权重提升值，只能通过不断尝试获得。需要记住的是 <code>boost</code> 只是影响相关度评分的其中一个因子；它还需要与其他因子相互竞争。在前例中， <code>title</code> 字段相对 <code>content</code> 字段可能已经有一个 </code>缺省的'' 权重提升值，这因为在 <a href="#field-norm">字段长度归一值</a> 中，标题往往比相关内容要短，所以不要想当然的去盲目提升一些字段的权重。选择权重，检查结果，如此反复。</p>
</div>
<div class="sect3">
<h4 id="_提升索引权重">提升索引权重</h4>
<div class="paragraph">
<p>当在多个索引中搜索时，可以使用参数 <code>indices_boost</code> 来提升整个索引的权重，在下面例子中，当要为最近索引的文档分配更高权重时，可以这么做：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /docs_2014_*/_search <b class="conum">(1)</b>
{
  "indices_boost": { <b class="conum">(2)</b>
    "docs_2014_10": 3,
    "docs_2014_09": 2
  },
  "query": {
    "match": {
      "text": "quick brown fox"
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>这个多索引查询涵盖了所有以字符串 <code>docs_2014_</code> 开始的索引。</p>
</li>
<li>
<p>其中，索引 <code>docs_2014_10</code> 中的所有文件的权重是 <code>3</code> ，索引 <code>docs_2014_09</code> 中是 <code>2</code> ，其他所有匹配的索引权重为默认值 <code>1</code> 。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_t_getboost">t.getBoost()</h4>
<div class="paragraph">
<p>这些提升值在 Lucene 的 <a href="#practical-scoring-function">实用评分函数</a> 中可以通过 <code>t.getBoost()</code> 获得。权重提升不会被应用于它在查询表达式中出现的层，而是会被合并下转至每个词中。 <code>t.getBoost()</code> 始终返回当前词的权重或当前分析链上查询的权重。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p>实际上，要想解读 <a href="#explain"><code>explain</code></a> 的输出是相当复杂的，在 <code>explanation</code> 里面完全看不到 <code>boost</code> 值，也完全无法访问上面提到的 <code>t.getBoost()</code> 方法，权重值融合在 <a href="#query-norm"><code>queryNorm</code></a> 中并应用到每个词。尽管说， <code>queryNorm</code> 对于每个词都是相同的，还是会发现一个权重提升过的词的 <code>queryNorm</code> 值要高于一个没有提升过的。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="query-scoring">使用查询结构修改相关度</h3>
<div class="paragraph">
<p>Elasticsearch 的查询表达式相当灵活，可以通过调整查询结构中查询语句的所处层次，从而或多或少改变其重要性，比如，设想下面这个查询：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>quick OR brown OR red OR fox</pre>
</div>
</div>
<div class="paragraph">
<p>可以将所有词都放在 <code>bool</code> 查询的同一层中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "term": { "text": "quick" }},
        { "term": { "text": "brown" }},
        { "term": { "text": "red"   }},
        { "term": { "text": "fox"   }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个查询可能最终给包含 <code>quick</code> 、 <code>red</code> 和 <code>brown</code> 的文档评分与包含 <code>quick</code> 、 <code>red</code> 、 <code>fox</code> 文档的评分相同，这里 <em>Red</em> 和 <em>brown</em> 是同义词，可能只需要保留其中一个，而我们真正要表达的意思是想做以下查询：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>quick OR (brown OR red) OR fox</pre>
</div>
</div>
<div class="paragraph">
<p>根据标准的布尔逻辑，这与原始的查询是完全一样的，但是我们已经在 <a href="#bool-query">组合查询（Combining Queries）</a> 中看到， <code>bool</code> 查询不关心文档匹配的 <em>程度</em> ，只关心是否能匹配。</p>
</div>
<div class="paragraph">
<p>上述查询有个更好的方式：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "term": { "text": "quick" }},
        { "term": { "text": "fox"   }},
        {
          "bool": {
            "should": [
              { "term": { "text": "brown" }},
              { "term": { "text": "red"   }}
            ]
          }
        }
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>现在， <code>red</code> 和 <code>brown</code> 处于相互竞争的层次， <code>quick</code> 、 <code>fox</code> 以及 <code>red OR brown</code> 则是处于顶层且相互竞争的词。</p>
</div>
<div class="paragraph">
<p>我们已经讨论过如何使用 <a href="#match-query"><code>match</code></a> 、<a href="#multi-match-query"><code>multi_match</code></a> 、<a href="#term-vs-full-text"><code>term</code></a> 、<a href="#bool-query"><code>bool</code></a> 和 <a href="#dis-max-query"><code>dis_max</code></a> 查询修改相关度评分。本章后面的内容会介绍另外三个与相关度评分有关的查询： <code>boosting</code> 查询、 <code>constant_score</code> 查询和 <code>function_score</code> 查询。</p>
</div>
</div>
<div class="sect2">
<h3 id="not-quite-not">Not Quite Not</h3>
<div class="paragraph">
<p>在互联网上搜索 “Apple”，返回的结果很可能是一个公司、水果和各种食谱。我们可以在 <code>bool</code> 查询中用 <code>must_not</code> 语句来排除像 <code>pie</code> 、 <code>tart</code> 、 <code>crumble</code> 和 <code>tree</code> 这样的词，从而将查询结果的范围缩小至只返回与 “Apple” （苹果）公司相关的结果：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "bool": {
      "must": {
        "match": {
          "text": "apple"
        }
      },
      "must_not": {
        "match": {
          "text": "pie tart fruit crumble tree"
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>但谁又敢保证在排除 <code>tree</code> 或 <code>crumble</code> 这种词后，不会错失一个与苹果公司特别相关的文档呢？有时， <code>must_not</code> 条件会过于严格。</p>
</div>
<div class="sect3">
<h4 id="boosting-query">权重提升查询</h4>
<div class="paragraph">
<p>{ref}/query-dsl-boosting-query.html[<code>boosting</code> 查询]
恰恰能解决这个问题。它仍然允许我们将关于水果或甜点的结果包括到结果中，但是使它们降级——即降低它们原来可能应有的排名：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "boosting": {
      "positive": {
        "match": {
          "text": "apple"
        }
      },
      "negative": {
        "match": {
          "text": "pie tart fruit crumble tree"
        }
      },
      "negative_boost": 0.5
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>它接受 <code>positive</code> 和 <code>negative</code> 查询。只有那些匹配 <code>positive</code> 查询的文档罗列出来，对于那些同时还匹配 <code>negative</code> 查询的文档将通过文档的原始 <code>_score</code> 与 <code>negative_boost</code> 相乘的方式降级后的结果。</p>
</div>
<div class="paragraph">
<p>为了达到效果， <code>negative_boost</code> 的值必须小于 <code>1.0</code> 。在这个示例中，所有包含负向词的文档评分 <code>_score</code> 都会减半。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="ignoring-tfidf">忽略 TF/IDF</h3>
<div class="paragraph">
<p>有时候我们根本不关心 TF/IDF ，只想知道一个词是否在某个字段中出现过。可能搜索一个度假屋并希望它能尽可能有以下设施：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>WiFi</p>
</li>
<li>
<p>Garden（花园）</p>
</li>
<li>
<p>Pool（游泳池）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>这个度假屋的文档如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">{ "description": "A delightful four-bedroomed house with ... " }</code></pre>
</div>
</div>
<div class="paragraph">
<p>可以用简单的 <code>match</code> 查询进行匹配：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "match": {
      "description": "wifi garden pool"
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>但这并不是真正的 <em>全文搜索</em> ，此种情况下，TF/IDF 并无用处。我们既不关心 <code>wifi</code> 是否为一个普通词，也不关心它在文档中出现是否频繁，关心的只是它是否曾出现过。实际上，我们希望根据房屋不同设施的数量对其排名——设施越多越好。如果设施出现，则记 <code>1</code> 分，不出现记 <code>0</code> 分。</p>
</div>
<div class="sect3">
<h4 id="constant-score-query">constant_score 查询</h4>
<div class="paragraph">
<p>在 {ref}/query-dsl-constant-score-query.html[<code>constant_score</code>]
查询中，它可以包含查询或过滤，为任意一个匹配的文档指定评分 <code>1</code> ，忽略 TF/IDF 信息：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "constant_score": {
          "query": { "match": { "description": "wifi" }}
        }},
        { "constant_score": {
          "query": { "match": { "description": "garden" }}
        }},
        { "constant_score": {
          "query": { "match": { "description": "pool" }}
        }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>或许不是所有的设施都同等重要——对某些用户来说有些设施更有价值。如果最重要的设施是游泳池，那我们可以为更重要的设施增加权重：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "constant_score": {
          "query": { "match": { "description": "wifi" }}
        }},
        { "constant_score": {
          "query": { "match": { "description": "garden" }}
        }},
        { "constant_score": {
          "boost":   2 <b class="conum">(1)</b>
          "query": { "match": { "description": "pool" }}
        }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>pool</code> 语句的权重提升值为 <code>2</code> ，而其他的语句为 <code>1</code> 。</p>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
最终的评分并不是所有匹配语句的简单求和， <a href="#coord">协调因子（coordination factor）</a> 和 <a href="#query-norm">查询归一化因子（query normalization factor）</a> 仍然会被考虑在内。
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>我们可以给 <code>features</code> 字段加上 <code>not_analyzed</code> 类型来提升度假屋文档的匹配能力：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">{ "features": [ "wifi", "pool", "garden" ] }</code></pre>
</div>
</div>
<div class="paragraph">
<p>默认情况下，一个 <code>not_analyzed</code> 字段会禁用 <a href="#field-norm">字段长度归一值（field-length norms）</a> 的功能，并将 <code>index_options</code> 设为 <code>docs</code> 选项，禁用 <a href="#tf">词频</a> ，但还是存在问题：每个词的 <a href="#idf">倒排文档频率</a> 仍然会被考虑。</p>
</div>
<div class="paragraph">
<p>可以采用与之前相同的方法 <code>constant_score</code> 查询来解决这个问题：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "constant_score": {
          "query": { "match": { "features": "wifi" }}
        }},
        { "constant_score": {
          "query": { "match": { "features": "garden" }}
        }},
        { "constant_score": {
          "boost":   2
          "query": { "match": { "features": "pool" }}
        }}
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>实际上，每个设施都应该看成一个过滤器，对于度假屋来说要么具有某个设施要么没有——过滤器因为其性质天然合适。而且，如果使用过滤器，我们还可以利用缓存。</p>
</div>
<div class="paragraph">
<p>这里的问题是：过滤器无法计算评分。这样就需要寻求一种方式将过滤器和查询间的差异抹平。 <code>function_score</code> 查询不仅正好可以扮演这个角色，而且有更强大的功能。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="function-score-query">function_score 查询</h3>
<div class="paragraph">
<p>{ref}/query-dsl-function-score-query.html[<code>function_score</code> 查询]
是用来控制评分过程的终极武器，它允许为每个与主查询匹配的文档应用一个函数，以达到改变甚至完全替换原始查询评分 <code>_score</code> 的目的。</p>
</div>
<div class="paragraph">
<p>实际上，也能用过滤器对结果的 <em>子集</em> 应用不同的函数，这样一箭双雕：既能高效评分，又能利用过滤器缓存。</p>
</div>
<div class="paragraph">
<p>Elasticsearch 预定义了一些函数：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>weight</code></dt>
<dd>
<p>为每个文档应用一个简单而不被规范化的权重提升值：当 <code>weight</code> 为 <code>2</code> 时，最终结果为 <code>2 * _score</code> 。</p>
</dd>
<dt class="hdlist1"><code>field_value_factor</code></dt>
<dd>
<p>使用这个值来修改 <code>_score</code> ，如将 <code>popularity</code> 或 <code>votes</code> （受欢迎或赞）作为考虑因素。</p>
</dd>
<dt class="hdlist1"><code>random_score</code></dt>
<dd>
<p>为每个用户都使用一个不同的随机评分对结果排序，但对某一具体用户来说，看到的顺序始终是一致的。</p>
</dd>
<dt class="hdlist1"><em>衰减函数</em> —— <code>linear</code> 、 <code>exp</code> 、 <code>gauss</code></dt>
<dd>
<p>将浮动值结合到评分 <code>_score</code> 中，例如结合 <code>publish_date</code> 获得最近发布的文档，结合 <code>geo_location</code> 获得更接近某个具体经纬度（lat/lon）地点的文档，结合 <code>price</code> 获得更接近某个特定价格的文档。</p>
</dd>
<dt class="hdlist1"><code>script_score</code></dt>
<dd>
<p>如果需求超出以上范围时，用自定义脚本可以完全控制评分计算，实现所需逻辑。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>如果没有 <code>function_score</code> 查询，就不能将全文查询与最新发生这种因子结合在一起评分，而不得不根据评分 <code>_score</code> 或时间 <code>date</code> 进行排序；这会相互影响抵消两种排序各自的效果。这个查询可以使两个效果融合：可以仍然根据全文相关度进行排序，但也会同时考虑最新发布文档、流行文档、或接近用户希望价格的产品。正如所设想的，查询要考虑所有这些因素会非常复杂，让我们先从简单的例子开始，然后顺着梯子慢慢向上爬，增加复杂度。</p>
</div>
</div>
<div class="sect2">
<h3 id="boosting-by-popularity">按受欢迎度提升权重</h3>
<div class="paragraph">
<p>设想有个网站供用户发布博客并且可以让他们为自己喜欢的博客点赞，我们希望将更受欢迎的博客放在搜索结果列表中相对较上的位置，同时全文搜索的评分仍然作为相关度的主要排序依据，可以简单的通过存储每个博客的点赞数来实现它：</p>
</div>
<div class="listingblock pagebreak-before">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">PUT /blogposts/post/1
{
  "title":   "About popularity",
  "content": "In this post we will talk about...",
  "votes":   6
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>在搜索时，可以将 <code>function_score</code> 查询与 <code>field_value_factor</code> 结合使用，即将点赞数与全文相关度评分结合：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /blogposts/post/_search
{
  "query": {
    "function_score": { <b class="conum">(1)</b>
      "query": { <b class="conum">(2)</b>
        "multi_match": {
          "query":    "popularity",
          "fields": [ "title", "content" ]
        }
      },
      "field_value_factor": { <b class="conum">(3)</b>
        "field": "votes" <b class="conum">(4)</b>
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>function_score</code> 查询将主查询和函数包括在内。</p>
</li>
<li>
<p>主查询优先执行。</p>
</li>
<li>
<p><code>field_value_factor</code> 函数会被应用到每个与主 <code>query</code> 匹配的文档。</p>
</li>
<li>
<p>每个文档的 <code>votes</code> 字段都 <em>必须</em> 有值供 <code>function_score</code> 计算。如果 <em>没有</em> 文档的 <code>votes</code> 字段有值，那么就 <em>必须</em> 使用
{ref}/query-dsl-function-score-query.html#function-field-value-factor[<code>missing</code> 属性] 提供的默认值来进行评分计算。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>在前面示例中，每个文档的最终评分 <code>_score</code> 都做了如下修改：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>new_score = old_score * number_of_votes</pre>
</div>
</div>
<div class="paragraph">
<p>然而这并不会带来出人意料的好结果，全文评分 <code>_score</code> 通常处于 0 到 10 之间，如下图 <a href="#img-popularity-linear">受欢迎度的线性关系基于 <code>_score</code> 的原始值 <code>2.0</code></a> 中，有 10 个赞的博客会掩盖掉全文评分，而 0 个赞的博客的评分会被置为 0 。</p>
</div>
<div id="img-popularity-linear" class="imageblock">
<div class="content">
<img src="images/elas_1701.png" alt="Linear popularity based on an original `_score` of `2.0`">
</div>
<div class="title">Figure 3. 受欢迎度的线性关系基于 <code>_score</code> 的原始值 <code>2.0</code></div>
</div>
<div class="sect3">
<h4 id="_modifier">modifier</h4>
<div class="paragraph">
<p>一种融入受欢迎度更好方式是用 <code>modifier</code> 平滑 <code>votes</code> 的值。换句话说，我们希望最开始的一些赞更重要，但是其重要性会随着数字的增加而降低。 0 个赞与 1 个赞的区别应该比 10 个赞与 11 个赞的区别大很多。</p>
</div>
<div class="paragraph">
<p>对于上述情况，典型的 <code>modifier</code> 应用是使用 <code>log1p</code> 参数值，公式如下：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>new_score = old_score * log(1 + number_of_votes)</pre>
</div>
</div>
<div class="paragraph">
<p><code>log</code> 对数函数使 <code>votes</code> 赞字段的评分曲线更平滑，如图 <a href="#img-popularity-log">受欢迎度的对数关系基于 <code>_score</code> 的原始值 <code>2.0</code></a> ：</p>
</div>
<div id="img-popularity-log" class="imageblock">
<div class="content">
<img src="images/elas_1702.png" alt="Logarithmic popularity based on an original `_score` of `2.0`">
</div>
<div class="title">Figure 4. 受欢迎度的对数关系基于 <code>_score</code> 的原始值 <code>2.0</code></div>
</div>
<div class="paragraph">
<p>带 <code>modifier</code> 参数的请求如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /blogposts/post/_search
{
  "query": {
    "function_score": {
      "query": {
        "multi_match": {
          "query":    "popularity",
          "fields": [ "title", "content" ]
        }
      },
      "field_value_factor": {
        "field":    "votes",
        "modifier": "log1p" <b class="conum">(1)</b>
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>modifier</code> 为 <code>log1p</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph pagebreak-before">
<p>修饰语 modifier 的值可以为： <code>none</code> （默认状态）、 <code>log</code> 、 <code>log1p</code> 、 <code>log2p</code> 、 <code>ln</code> 、 <code>ln1p</code> 、 <code>ln2p</code> 、 <code>square</code> 、 <code>sqrt</code> 以及 <code>reciprocal</code> 。想要了解更多信息请参照：
{ref}/query-dsl-function-score-query.html#function-field-value-factor[<code>field_value_factor</code> 文档].</p>
</div>
</div>
<div class="sect3">
<h4 id="_factor">factor</h4>
<div class="paragraph">
<p>可以通过将 <code>votes</code> 字段与 <code>factor</code> 的积来调节受欢迎程度效果的高低：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /blogposts/post/_search
{
  "query": {
    "function_score": {
      "query": {
        "multi_match": {
          "query":    "popularity",
          "fields": [ "title", "content" ]
        }
      },
      "field_value_factor": {
        "field":    "votes",
        "modifier": "log1p",
        "factor":   2 <b class="conum">(1)</b>
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>双倍效果。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>添加了 <code>factor</code> 会使公式变成这样：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>new_score = old_score * log(1 + factor * number_of_votes)</pre>
</div>
</div>
<div class="paragraph">
<p><code>factor</code> 值大于 <code>1</code> 会提升效果， <code>factor</code> 值小于 <code>1</code> 会降低效果，如图 <a href="#img-popularity-factor">受欢迎度的对数关系基于多个不同因子</a> 。</p>
</div>
<div id="img-popularity-factor" class="imageblock">
<div class="content">
<img src="images/elas_1703.png" alt="Logarithmic popularity with different factors">
</div>
<div class="title">Figure 5. 受欢迎度的对数关系基于多个不同因子</div>
</div>
</div>
<div class="sect3">
<h4 id="_boost_mode">boost_mode</h4>
<div class="paragraph">
<p>或许将全文评分与 <code>field_value_factor</code> 函数值乘积的效果仍然可能太大，我们可以通过参数 <code>boost_mode</code> 来控制函数与查询评分 <code>_score</code> 合并后的结果，参数接受的值为：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>multiply</code></dt>
<dd>
<p>评分 <code>_score</code> 与函数值的积（默认）</p>
</dd>
<dt class="hdlist1"><code>sum</code></dt>
<dd>
<p>评分 <code>_score</code> 与函数值的和</p>
</dd>
<dt class="hdlist1"><code>min</code></dt>
<dd>
<p>评分 <code>_score</code> 与函数值间的较小值</p>
</dd>
<dt class="hdlist1"><code>max</code></dt>
<dd>
<p>评分 <code>_score</code> 与函数值间的较大值</p>
</dd>
<dt class="hdlist1"><code>replace</code></dt>
<dd>
<p>函数值替代评分 <code>_score</code></p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>与使用乘积的方式相比，使用评分 <code>_score</code> 与函数值求和的方式可以弱化最终效果，特别是使用一个较小 <code>factor</code> 因子时：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /blogposts/post/_search
{
  "query": {
    "function_score": {
      "query": {
        "multi_match": {
          "query":    "popularity",
          "fields": [ "title", "content" ]
        }
      },
      "field_value_factor": {
        "field":    "votes",
        "modifier": "log1p",
        "factor":   0.1
      },
      "boost_mode": "sum" <b class="conum">(1)</b>
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>将函数计算结果值累加到评分 <code>_score</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>之前请求的公式现在变成下面这样（参见 <a href="#img-popularity-sum">使用 <code>sum</code> 结合受欢迎程度</a> ）：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>new_score = old_score + log(1 + 0.1 * number_of_votes)</pre>
</div>
</div>
<div id="img-popularity-sum" class="imageblock">
<div class="content">
<img src="images/elas_1704.png" alt="Combining popularity with `sum`">
</div>
<div class="title">Figure 6. 使用 <code>sum</code> 结合受欢迎程度</div>
</div>
</div>
<div class="sect3">
<h4 id="_max_boost">max_boost</h4>
<div class="paragraph">
<p>最后，可以使用 <code>max_boost</code> 参数限制一个函数的最大效果：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /blogposts/post/_search
{
  "query": {
    "function_score": {
      "query": {
        "multi_match": {
          "query":    "popularity",
          "fields": [ "title", "content" ]
        }
      },
      "field_value_factor": {
        "field":    "votes",
        "modifier": "log1p",
        "factor":   0.1
      },
      "boost_mode": "sum",
      "max_boost":  1.5 <b class="conum">(1)</b>
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>无论 <code>field_value_factor</code> 函数的结果如何，最终结果都不会大于 <code>1.5</code> 。</p>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<code>max_boost</code> 只对函数的结果进行限制，不会对最终评分 <code>_score</code> 产生直接影响。
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="function-score-filters">过滤集提升权重</h3>
<div class="paragraph">
<p>回到 <a href="#ignoring-tfidf">忽略 TF/IDF</a> 里处理过的问题，我们希望根据每个度假屋的特性数量来评分，当时我们希望能用缓存的过滤器来影响评分，现在 <code>function_score</code> 查询正好可以完成这件事情。</p>
</div>
<div class="paragraph">
<p>到目前为止，我们展现的都是为所有文档应用单个函数的使用方式，现在会用过滤器将结果划分为多个子集（每个特性一个过滤器），并为每个子集使用不同的函数。</p>
</div>
<div class="paragraph">
<p>在下面例子中，我们会使用 <code>weight</code> 函数，它与 <code>boost</code> 参数类似可以用于任何查询。有一点区别是 <code>weight</code> 没有被 Luence 归一化成难以理解的浮点数，而是直接被应用。</p>
</div>
<div class="paragraph">
<p>查询的结构需要做相应变更以整合多个函数：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "function_score": {
      "filter": { <b class="conum">(1)</b>
        "term": { "city": "Barcelona" }
      },
      "functions": [ <b class="conum">(2)</b>
        {
          "filter": { "term": { "features": "wifi" }}, <b class="conum">(3)</b>
          "weight": 1
        },
        {
          "filter": { "term": { "features": "garden" }}, <b class="conum">(3)</b>
          "weight": 1
        },
        {
          "filter": { "term": { "features": "pool" }}, <b class="conum">(3)</b>
          "weight": 2 <b class="conum">(4)</b>
        }
      ],
      "score_mode": "sum", <b class="conum">(5)</b>
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>function_score</code> 查询有个 <code>filter</code> 过滤器而不是 <code>query</code> 查询。</p>
</li>
<li>
<p><code>functions</code> 关键字存储着一个将被应用的函数列表。</p>
</li>
<li>
<p>函数会被应用于和 <code>filter</code> 过滤器（可选的）匹配的文档。</p>
</li>
<li>
<p><code>pool</code> 比其他特性更重要，所以它有更高 <code>weight</code> 。</p>
</li>
<li>
<p><code>score_mode</code> 指定各个函数的值进行组合运算的方式。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这个新特性需要注意的地方会在以下小节介绍。</p>
</div>
<div class="sect3">
<h4 id="_过滤_vs_查询">过滤 vs. 查询</h4>
<div class="paragraph">
<p>首先要注意的是 <code>filter</code> 过滤器代替了 <code>query</code> 查询，在本例中，我们无须使用全文搜索，只想找到 <code>city</code> 字段中包含 <code>Barcelona</code> 的所有文档，逻辑用过滤比用查询表达更清晰。过滤器返回的所有文档的评分 <code>_score</code> 的值为 <code>1</code> 。 <code>function_score</code> 查询接受 <code>query</code> 或 <code>filter</code> ，如果没有特别指定，则默认使用 <code>match_all</code> 查询。</p>
</div>
</div>
<div class="sect3">
<h4 id="_函数_functions">函数 functions</h4>
<div class="paragraph">
<p><code>functions</code> 关键字保持着一个将要被使用的函数列表。可以为列表里的每个函数都指定一个 <code>filter</code> 过滤器，在这种情况下，函数只会被应用到那些与过滤器匹配的文档，例子中，我们为与过滤器匹配的文档指定权重值 <code>weight</code> 为 <code>1</code> （为与 <code>pool</code> 匹配的文档指定权重值为 <code>2</code> ）。</p>
</div>
</div>
<div class="sect3">
<h4 id="_评分模式_score_mode">评分模式 score_mode</h4>
<div class="paragraph">
<p>每个函数返回一个结果，所以需要一种将多个结果缩减到单个值的方式，然后才能将其与原始评分 <code>_score</code> 合并。评分模式 <code>score_mode</code> 参数正好扮演这样的角色，它接受以下值：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>multiply</code></dt>
<dd>
<p>函数结果求积（默认）。</p>
</dd>
<dt class="hdlist1"><code>sum</code></dt>
<dd>
<p>函数结果求和。</p>
</dd>
<dt class="hdlist1"><code>avg</code></dt>
<dd>
<p>函数结果的平均值。</p>
</dd>
<dt class="hdlist1"><code>max</code></dt>
<dd>
<p>函数结果的最大值。</p>
</dd>
<dt class="hdlist1"><code>min</code></dt>
<dd>
<p>函数结果的最小值。</p>
</dd>
<dt class="hdlist1"><code>first</code></dt>
<dd>
<p>使用首个函数（可以有过滤器，也可能没有）的结果作为最终结果</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>在本例中，我们将每个过滤器匹配结果的权重 <code>weight</code> 求和，并将其作为最终评分结果，所以会使用 <code>sum</code> 评分模式。</p>
</div>
<div class="paragraph">
<p>不与任何过滤器匹配的文档会保有其原始评分， <code>_score</code> 值的为 <code>1</code> 。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="random-scoring">随机评分</h3>
<div class="paragraph">
<p>你可能会想知道 <em>一致随机评分（consistently random scoring）</em> 是什么，又为什么会使用它。之前的例子是个很好的应用场景，前例中所有的结果都会返回 1 、 2 、 3 、 4 或 5 这样的最终评分 <code>_score</code> ，可能只有少数房子的评分是 5 分，而有大量房子的评分是 2 或 3 。</p>
</div>
<div class="paragraph">
<p>作为网站的所有者，总会希望让广告有更高的展现率。在当前查询下，有相同评分 <code>_score</code> 的文档会每次都以相同次序出现，为了提高展现率，在此引入一些随机性可能会是个好主意，这能保证有相同评分的文档都能有均等相似的展现机率。</p>
</div>
<div class="paragraph">
<p>我们想让每个用户看到不同的随机次序，但也同时希望如果是同一用户翻页浏览时，结果的相对次序能始终保持一致。这种行为被称为 <em>一致随机（consistently random）</em> 。</p>
</div>
<div class="paragraph">
<p><code>random_score</code> 函数会输出一个 0 到 1 之间的数，当种子 <code>seed</code> 值相同时，生成的随机结果是一致的，例如，将用户的会话 ID 作为 seed ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "function_score": {
      "filter": {
        "term": { "city": "Barcelona" }
      },
      "functions": [
        {
          "filter": { "term": { "features": "wifi" }},
          "weight": 1
        },
        {
          "filter": { "term": { "features": "garden" }},
          "weight": 1
        },
        {
          "filter": { "term": { "features": "pool" }},
          "weight": 2
        },
        {
          "random_score": { <b class="conum">(1)</b>
            "seed":  "the users session id" <b class="conum">(2)</b>
          }
        }
      ],
      "score_mode": "sum"
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>random_score</code> 语句没有任何过滤器 <code>filter</code> ，所以会被应用到所有文档。</p>
</li>
<li>
<p>将用户的会话 ID 作为种子 <code>seed</code> ，让该用户的随机始终保持一致，相同的种子 <code>seed</code> 会产生相同的随机结果。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>当然，如果增加了与查询匹配的新文档，无论是否使用一致随机，其结果顺序都会发生变化。</p>
</div>
</div>
<div class="sect2">
<h3 id="decay-functions">越近越好</h3>
<div class="paragraph">
<p>很多变量都可以影响用户对于度假屋的选择，也许用户希望离市中心近点，但如果价格足够便宜，也有可能选择一个更远的住处，也有可能反过来是正确的：愿意为最好的位置付更多的价钱。</p>
</div>
<div class="paragraph">
<p>如果我们添加过滤器排除所有市中心方圆 1 千米以外的度假屋，或排除所有每晚价格超过 £100 英镑的，我们可能会将用户愿意考虑妥协的那些选择排除在外。</p>
</div>
<div class="paragraph">
<p><code>function_score</code> 查询会提供一组 <em>衰减函数（decay functions）</em> ，让我们有能力在两个滑动标准，如地点和价格，之间权衡。</p>
</div>
<div class="paragraph">
<p>有三种衰减函数—— <code>linear</code> 、 <code>exp</code> 和 <code>gauss</code> （线性、指数和高斯函数），它们可以操作数值、时间以及经纬度地理坐标点这样的字段。所有三个函数都能接受以下参数：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>origin</code></dt>
<dd>
<p><em>中心点</em> 或字段可能的最佳值，落在原点 <code>origin</code> 上的文档评分 <code>_score</code> 为满分 <code>1.0</code> 。</p>
</dd>
<dt class="hdlist1"><code>scale</code></dt>
<dd>
<p>衰减率，即一个文档从原点 <code>origin</code> 下落时，评分 <code>_score</code> 改变的速度。（例如，每 £10 欧元或每 100 米）。</p>
</dd>
<dt class="hdlist1"><code>decay</code></dt>
<dd>
<p>从原点 <code>origin</code> 衰减到 <code>scale</code> 所得的评分 <code>_score</code> ，默认值为 <code>0.5</code> 。</p>
</dd>
<dt class="hdlist1"><code>offset</code></dt>
<dd>
<p>以原点 <code>origin</code> 为中心点，为其设置一个非零的偏移量 <code>offset</code> 覆盖一个范围，而不只是单个原点。在范围 <code>-offset &#8656; origin &#8656; +offset</code> 内的所有评分 <code>_score</code> 都是 <code>1.0</code> 。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>这三个函数的唯一区别就是它们衰减曲线的形状，用图来说明会更为直观（参见 <a href="#img-decay-functions">衰减函数曲线</a> ）。</p>
</div>
<div id="img-decay-functions" class="imageblock">
<div class="content">
<img src="images/elas_1705.png" alt="衰减函数曲线">
</div>
<div class="title">Figure 7. 衰减函数曲线</div>
</div>
<div class="paragraph">
<p>图 <a href="#img-decay-functions">衰减函数曲线</a> 中所有曲线的原点 <code>origin</code> （即中心点）的值都是 <code>40</code> ， <code>offset</code> 是 <code>5</code> ，也就是在范围 <code>40 - 5 &#8656; value &#8656; 40 + 5</code> 内的所有值都会被当作原点 <code>origin</code> 处理——所有这些点的评分都是满分 <code>1.0</code> 。</p>
</div>
<div class="paragraph">
<p>在此范围之外，评分开始衰减，衰减率由 <code>scale</code> 值（此例中的值为 <code>5</code> ）和 衰减值 <code>decay</code> （此例中为默认值 <code>0.5</code> ）共同决定。结果是所有三个曲线在 <code>origin +/- (offset + scale)</code> 处的评分都是 <code>0.5</code> ，即点 <code>30</code> 和 <code>50</code> 处。</p>
</div>
<div class="paragraph">
<p><code>linear</code> 、 <code>exp</code> 和 <code>gauss</code> （线性、指数和高斯）函数三者之间的区别在于范围（ <code>origin +/- (offset + scale)</code> ）之外的曲线形状：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>linear</code> 线性函数是条直线，一旦直线与横轴 0 相交，所有其他值的评分都是 <code>0.0</code> 。</p>
</li>
<li>
<p><code>exp</code> 指数函数是先剧烈衰减然后变缓。</p>
</li>
<li>
<p><code>gauss</code> 高斯函数是钟形的——它的衰减速率是先缓慢，然后变快，最后又放缓。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>选择曲线的依据完全由期望评分 <code>_score</code> 的衰减速率来决定，即距原点 <code>origin</code> 的值。</p>
</div>
<div class="paragraph">
<p>回到我们的例子：用户希望租一个离伦敦市中心近（ <code>{ "lat": 51.50, "lon": 0.12}</code> ）且每晚不超过 £100 英镑的度假屋，而且与距离相比，我们的用户对价格更为敏感，这样查询可以写成：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "query": {
    "function_score": {
      "functions": [
        {
          "gauss": {
            "location": { <b class="conum">(1)</b>
              "origin": { "lat": 51.5, "lon": 0.12 },
              "offset": "2km",
              "scale":  "3km"
            }
          }
        },
        {
          "gauss": {
            "price": { <b class="conum">(2)</b>
              "origin": "50", <b class="conum">(3)</b>
              "offset": "50",
              "scale":  "20"
            }
          },
          "weight": 2 <b class="conum">(4)</b>
        }
      ]
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>location</code> 字段以地理坐标点 <code>geo_point</code> 映射。</p>
</li>
<li>
<p><code>price</code> 字段是数值。</p>
</li>
<li>
<p>参见 <a href="#Understanding-the-price-Clause">理解价格语句</a> ，理解 <code>origin</code> 为什么是 <code>50</code> 而不是 <code>100</code> 。</p>
</li>
<li>
<p><code>price</code> 语句是 <code>location</code> 语句权重的两倍。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><code>location</code> 语句可以简单理解为：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>以伦敦市中作为原点 <code>origin</code> 。</p>
</li>
<li>
<p>所有距原点 <code>origin</code> <code>2km</code> 范围内的位置的评分是 <code>1.0</code> 。</p>
</li>
<li>
<p>距中心 <code>5km</code> （ <code>offset + scale</code> ）的位置的评分是 <code>0.5</code> 。</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="Understanding-the-price-Clause">理解 price 价格语句</h3>
<div class="paragraph">
<p><code>price</code> 语句使用了一个小技巧：用户希望选择 £100 英镑以下的度假屋，但是例子中的原点被设置成 £50 英镑，价格不能为负，但肯定是越低越好，所以 £0 到 £100 英镑内的所有价格都认为是比较好的。</p>
</div>
<div class="paragraph">
<p>如果我们将原点 <code>origin</code> 被设置成 £100 英镑，那么低于 £100 英镑的度假屋的评分会变低，与其这样不如将原点 <code>origin</code> 和偏移量 <code>offset</code> 同时设置成 £50 英镑，这样就能使只有在价格高于 £100 英镑（ <code>origin + offset</code> ）时评分才会变低。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p><code>weight</code> 参数可以被用来调整每个语句的贡献度，权重 <code>weight</code> 的默认值是 <code>1.0</code> 。这个值会先与每个句子的评分相乘，然后再通过 <code>score_mode</code> 的设置方式合并。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="script-score">脚本评分</h3>
<div class="paragraph">
<p>最后，如果所有 <code>function_score</code> 内置的函数都无法满足应用场景，可以使用 <code>script_score</code> 函数自行实现逻辑。</p>
</div>
<div class="paragraph">
<p>举个例子，想将利润空间作为因子加入到相关度评分计算，在业务中，利润空间和以下三点相关：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>price</code> 度假屋每晚的价格。</p>
</li>
<li>
<p>会员用户的级别——某些等级的用户可以在每晚房价高于某个 <code>threshold</code> 阀值价格的时候享受折扣 <code>discount</code> 。</p>
</li>
<li>
<p>用户享受折扣后，经过议价的每晚房价的利润 <code>margin</code> 。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>计算每个度假屋利润的算法如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">if (price &lt; threshold) {
  profit = price * margin
} else {
  profit = price * (1 - discount) * margin;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>我们很可能不想用绝对利润作为评分，这会弱化其他如地点、受欢迎度和特性等因子的作用，而是将利润用目标利润 <code>target</code> 的百分比来表示，高于
目标的利润空间会有一个正向评分（大于 <code>1.0</code> ），低于目标的利润空间会有一个负向分数（小于 <code>1.0</code> ）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">if (price &lt; threshold) {
  profit = price * margin
} else {
  profit = price * (1 - discount) * margin
}
return profit / target</code></pre>
</div>
</div>
<div class="paragraph">
<p>Elasticsearch 里使用 <a href="http://groovy.codehaus.org/">Groovy</a> 作为默认的脚本语言，它与JavaScript很像，上面这个算法用 Groovy 脚本表示如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-groovy" data-lang="groovy">price  = doc['price'].value <b class="conum">(1)</b>
margin = doc['margin'].value <b class="conum">(1)</b>

if (price &lt; threshold) { <b class="conum">(2)</b>
  return price * margin / target
}
return price * (1 - discount) * margin / target <b class="conum">(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>price</code> 和 <code>margin</code> 变量可以分别从文档的 <code>price</code> 和 <code>margin</code> 字段提取。</p>
</li>
<li>
<p><code>threshold</code> 、 <code>discount</code> 和 <code>target</code> 是作为参数 <code>params</code> 传入的。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>最终我们将 <code>script_score</code> 函数与其他函数一起使用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">GET /_search
{
  "function_score": {
    "functions": [
      { ...location clause... }, <b class="conum">(1)</b>
      { ...price clause... }, <b class="conum">(1)</b>
      {
        "script_score": {
          "params": { <b class="conum">(2)</b>
            "threshold": 80,
            "discount": 0.1,
            "target": 10
          },
          "script": "price  = doc['price'].value; margin = doc['margin'].value;
          if (price &lt; threshold) { return price * margin / target };
          return price * (1 - discount) * margin / target;" <b class="conum">(3)</b>
        }
      }
    ]
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>location</code> 和 <code>price</code> 语句在 <a href="#decay-functions">衰减函数</a> 中解释过。</p>
</li>
<li>
<p>将这些变量作为参数 <code>params</code> 传递，我们可以查询时动态改变脚本无须重新编译。</p>
</li>
<li>
<p>JSON 不能接受内嵌的换行符，脚本中的换行符可以用 <code>\n</code> 或 <code>;</code> 符号替代。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这个查询根据用户对地点和价格的需求，返回用户最满意的文档，同时也考虑到我们对于盈利的要求。</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
<div class="paragraph">
<p><code>script_score</code> 函数提供了巨大的灵活性，可以通过脚本访问文档里的所有字段、当前评分 <code>_score</code> 甚至词频、逆向文档频率和字段长度规范值这样的信息（参见 see {ref}/modules-advanced-scripting.html[脚本对文本评分]）。</p>
</div>
<div class="paragraph">
<p>有人说使用脚本对性能会有影响，如果确实发现脚本执行较慢，可以有以下三种选择：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>尽可能多的提前计算各种信息并将结果存入每个文档中。</p>
</li>
<li>
<p>Groovy 很快，但没 Java 快。可以将脚本用原生的 Java 脚本重新实现。（参见
{ref}/modules-scripting-native.html[原生 Java 脚本]）。</p>
</li>
<li>
<p>仅对那些最佳评分的文档应用脚本，使用 <a href="#rescore-api">重新评分</a> 中提到的 <code>rescore</code> 功能。</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="pluggable-similarites">可插拔的相似度算法</h3>
<div class="paragraph">
<p>在进一步讨论相关度和评分之前，我们会以一个更高级的话题结束本章节的内容：可插拔的相似度算法（Pluggable Similarity Algorithms）。 Elasticsearch 将 <a href="#practical-scoring-function">实用评分算法</a> 作为默认相似度算法，它也能够支持其他的一些算法，这些算法可以参考
{ref}/index-modules-similarity.html#configuration[相似度模块] 文档。</p>
</div>
<div class="sect3">
<h4 id="bm25">Okapi BM25</h4>
<div class="paragraph">
<p>能与 TF/IDF 和向量空间模型媲美的就是 <a href="http://en.wikipedia.org/wiki/Okapi_BM25"><em>Okapi BM25</em></a> ，它被认为是 <em>当今最先进的</em> 排序函数。 BM25 源自 <a href="http://en.wikipedia.org/wiki/Probabilistic_relevance_model">概率相关模型（probabilistic relevance model）</a> ，而不是向量空间模型，但这个算法也和 Lucene 的实用评分函数有很多共通之处。</p>
</div>
<div class="paragraph">
<p>BM25 同样使用词频、逆向文档频率以及字段长归一化，但是每个因子的定义都有细微区别。与其详细解释 BM25 公式，倒不如将关注点放在 BM25 所能带来的实际好处上。</p>
</div>
<div class="sect4">
<h5 id="bm25-saturation">词频饱和度</h5>
<div class="paragraph">
<p>TF/IDF 和 BM25 同样使用 <a href="#idf">逆向文档频率</a> 来区分普通词（不重要）和非普通词（重要），同样认为（参见 <a href="#tf">词频</a> ）文档里的某个词出现次数越频繁，文档与这个词就越相关。</p>
</div>
<div class="paragraph">
<p>不幸的是，普通词随处可见，实际上一个普通词在同一个文档中大量出现的作用会由于该词在 <em>所有</em> 文档中的大量出现而被抵消掉。</p>
</div>
<div class="paragraph">
<p>曾经有个时期，将 <em>最</em> 普通的词（或 <em>停用词</em> ，参见 <a href="#stopwords">停用词</a>）从索引中移除被认为是一种标准实践，TF/IDF 正是在这种背景下诞生的。TF/IDF 没有考虑词频上限的问题，因为高频停用词已经被移除了。</p>
</div>
<div class="paragraph">
<p>Elasticsearch 的 <code>standard</code> 标准分析器（ <code>string</code> 字段默认使用）不会移除停用词，因为尽管这些词的重要性很低，但也不是毫无用处。这导致：在一个相当长的文档中，像 <code>the</code> 和 <code>and</code> 这样词出现的数量会高得离谱，以致它们的权重被人为放大。</p>
</div>
<div class="paragraph">
<p>另一方面，BM25 有一个上限，文档里出现 5 到 10 次的词会比那些只出现一两次的对相关度有着显著影响。但是如图 <a href="#img-bm25-saturation">TF/IDF 与 BM25 的词频饱和度</a> 所见，文档中出现 20 次的词几乎与那些出现上千次的词有着相同的影响。</p>
</div>
<div class="paragraph">
<p>这就是 <em>非线性词频饱和度（nonlinear term-frequency saturation）</em> 。</p>
</div>
<div id="img-bm25-saturation" class="imageblock">
<div class="content">
<img src="images/elas_1706.png" alt="TF/IDF 与 BM25 的词频饱和度">
</div>
<div class="title">Figure 8. TF/IDF 与 BM25 的词频饱和度</div>
</div>
</div>
<div class="sect4">
<h5 id="bm25-normalization">字段长度归一化（Field-length normalization）</h5>
<div class="paragraph">
<p>在 <a href="#field-norm">字段长归一化</a> 中，我们提到过 Lucene 会认为较短字段比较长字段更重要：字段某个词的频度所带来的重要性会被这个字段长度抵消，但是实际的评分函数会将所有字段以同等方式对待。它认为所有较短的 <code>title</code> 字段比所有较长的 <code>body</code> 字段更重要。</p>
</div>
<div class="paragraph">
<p>BM25 当然也认为较短字段应该有更多的权重，但是它会分别考虑每个字段内容的平均长度，这样就能区分短 <code>title</code> 字段和 <code>长</code> title 字段。</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<div class="title">Caution</div>
</td>
<td class="content">
在 <a href="#query-time-boosting">查询时权重提升</a> 中，已经说过 <code>title</code> 字段因为其长度比 <code>body</code> 字段 <em>自然</em> 有更高的权重提升值。由于字段长度的差异只能应用于单字段，这种自然的权重提升会在使用 BM25 时消失。
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="bm25-tunability">BM25 调优</h5>
<div class="paragraph">
<p>不像 TF/IDF ，BM25 有一个比较好的特性就是它提供了两个可调参数：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>k1</code></dt>
<dd>
<p>这个参数控制着词频结果在词频饱和度中的上升速度。默认值为 <code>1.2</code> 。值越小饱和度变化越快，值越大饱和度变化越慢。</p>
</dd>
<dt class="hdlist1"><code>b</code></dt>
<dd>
<p>这个参数控制着字段长归一值所起的作用， <code>0.0</code> 会禁用归一化， <code>1.0</code> 会启用完全归一化。默认值为 <code>0.75</code> 。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>在实践中，调试 BM25 是另外一回事， <code>k1</code> 和 <code>b</code> 的默认值适用于绝大多数文档集合，但最优值还是会因为文档集不同而有所区别，为了找到文档集合的最优值，就必须对参数进行反复修改验证。</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="changing-similarities">更改相似度</h3>
<div class="paragraph">
<p>相似度算法可以按字段指定，只需在映射中为不同字段选定即可：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">PUT /my_index
{
  "mappings": {
    "doc": {
      "properties": {
        "title": {
          "type":       "string",
          "similarity": "BM25" <b class="conum">(1)</b>
        },
        "body": {
          "type":       "string",
          "similarity": "default" <b class="conum">(2)</b>
        }
      }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>title</code> 字段使用 BM25 相似度算法。</p>
</li>
<li>
<p><code>body</code> 字段用默认相似度算法（参见 <a href="#practical-scoring-function">实用评分函数</a>）。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>目前，Elasticsearch 不支持更改已有字段的相似度算法 <code>similarity</code> 映射，只能通过为数据重新建立索引来达到目的。</p>
</div>
<div class="sect3">
<h4 id="_配置_bm25">配置 BM25</h4>
<div class="paragraph">
<p>配置相似度算法和配置分析器很相似，自定义相似度算法可以在创建索引时指定，例如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-json" data-lang="json">PUT /my_index
{
  "settings": {
    "similarity": {
      "my_bm25": { <b class="conum">(1)</b>
        "type": "BM25",
        "b":    0 <b class="conum">(2)</b>
      }
    }
  },
  "mappings": {
    "doc": {
      "properties": {
        "title": {
          "type":       "string",
          "similarity": "my_bm25" <b class="conum">(3)</b>
        },
        "body": {
          "type":       "string",
          "similarity": "BM25" <b class="conum">(4)</b>
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>创建一个基于内置 <code>BM25</code> ，名为 <code>my_bm25</code> 的自定义相似度算法。</p>
</li>
<li>
<p>禁用字段长度规范化（field-length normalization）。参见 <a href="#bm25-tunability">调试 BM25</a> 。</p>
</li>
<li>
<p><code>title</code> 字段使用自定义相似度算法 <code>my_bm25</code> 。</p>
</li>
<li>
<p>字段 <code>body</code> 使用内置相似度算法 <code>BM25</code> 。</p>
</li>
</ol>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
自定义的相似度算法可以通过关闭索引，更新索引设置，开启索引这个过程进行更新。这样可以无须重建索引又能试验不同的相似度算法配置。
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="relevance-conclusion">调试相关度是最后 10% 要做的事情</h3>
<div class="paragraph">
<p>本章介绍了 Lucene 是如何基于 TF/IDF 生成评分的。理解评分过程是非常重要的，这样就可以根据具体的业务对评分结果进行调试、调节、减弱和定制。</p>
</div>
<div class="paragraph">
<p>实践中，简单的查询组合就能提供很好的搜索结果，但是为了获得 <em>具有成效</em> 的搜索结果，就必须反复推敲修改前面介绍的这些调试方法。</p>
</div>
<div class="paragraph">
<p>通常，经过对策略字段应用权重提升，或通过对查询语句结构的调整来强调某个句子的重要性这些方法，就足以获得良好的结果。有时，如果 Lucene 基于词的 TF/IDF 模型不再满足评分需求（例如希望基于时间或距离来评分），则需要更具侵略性的调整。</p>
</div>
<div class="paragraph">
<p>除此之外，相关度的调试就有如兔子洞，一旦跳进去就很难再出来。 <em>最相关</em> 这个概念是一个难以触及的模糊目标，通常不同人对文档排序又有着不同的想法，这很容易使人陷入持续反复调整而没有明显进展的怪圈。</p>
</div>
<div class="paragraph">
<p>我们强烈建议不要陷入这种怪圈，而要监控测量搜索结果。监控用户点击最顶端结果的频次，这可以是前 10 个文档，也可以是第一页的；用户不查看首次搜索的结果而直接执行第二次查询的频次；用户来回点击并查看搜索结果的频次，等等诸如此类的信息。</p>
</div>
<div class="paragraph">
<p>这些都是用来评价搜索结果与用户之间相关程度的指标。如果查询能返回高相关的文档，用户会选择前五中的一个，得到想要的结果，然后离开。不相关的结果会让用户来回点击并尝试新的搜索条件。</p>
</div>
<div class="paragraph">
<p>一旦有了这些监控手段，想要调试查询就并不复杂，稍作调整，监控用户的行为改变并做适当反复尝试。本章介绍的一些工具就只是工具而已，要想物尽其用并将搜索结果提高到 <em>极高的</em> 水平，唯一途径就是需要具备能评价度量用户行为的强大能力。</p>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2018-05-17 22:26:24 CST
</div>
</div>
</body>
</html>